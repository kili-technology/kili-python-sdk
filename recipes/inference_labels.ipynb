{
   "cells": [
      {
         "cell_type": "markdown",
         "metadata": {},
         "source": [
            "# Kili Tutorial: Importing inference labels\n",
            "\n",
            "In this tutorial, we will walk through the process of using Kili to evaluate the performance of a machine learning model in production. The goal of this tutorial is to illustrate how to push such labels, and how to visualize the quality of those predicted labels.\n",
            "\n",
            "Additionally:\n",
            "\n",
            "For an overview of Kili, visit https://kili-technology.com. You can also check out the Kili documentation https://docs.kili-technology.com/docs.\n",
            "\n",
            "The tutorial is divided into two parts:\n",
            "\n",
            "1. Giving a bit of context\n",
            "2. How to make use of inference labels in practice\n",
            "\n",
            "This next cell connects the notebook to the Kili API. You need to update the credentials `api_key` before."
         ]
      },
      {
         "cell_type": "code",
         "execution_count": 8,
         "metadata": {},
         "outputs": [],
         "source": [
            "import os\n",
            "#!pip install kili\n",
            "from kili.client import Kili\n",
            "\n",
            "api_endpoint = os.getenv('KILI_API_ENDPOINT_STAGING')\n",
            "api_key = os.getenv('KILI_ADMIN_API_KEY_STAGING')\n",
            "# If you use Kili SaaS, use the url 'https://cloud.kili-technology.com/api/label/v2/graphql'\n",
            "\n",
            "kili = Kili(api_endpoint=api_endpoint, api_key=api_key)"
         ]
      },
      {
         "cell_type": "markdown",
         "metadata": {},
         "source": [
            "## 1 - Context"
         ]
      },
      {
         "cell_type": "markdown",
         "metadata": {},
         "source": [
            "## 1.1 Agreement"
         ]
      },
      {
         "cell_type": "markdown",
         "metadata": {},
         "source": [
            "Let's say you have a trained machine learning model $m$, which can, given a data $x$, output a prediction (ie, an inference label) $l^i = m(x)$.\n",
            "\n",
            "What you will probably want to do is monitor the quality of such predictions, as the model evolves. Kili allows you to better monitor and iterate on your model, thanks to the concept of agreement. An agreement is a quantitative measure of similarity between two different labels. In Kili, there are three main features derived from agreement : \n",
            "\n",
            "- [Consensus](https://docs.kili-technology.com/docs/consensus-overview), which is the agreement between two labelers.\n",
            "- [Honeypot](https://docs.kili-technology.com/docs/honeypot-overview) which is the agreement between a \"super human annotator\" and a labeler.\n",
            "- **Inference**, which is the agreement between a machine learning inference label and a human.\n",
            "\n",
            "Those number can be monitored from the [queue page](https://docs.kili-technology.com/docs/queue-page) or the [analytics page](https://docs.kili-technology.com/docs/analytics-page). You can find how the agreement is computed [here](https://docs.kili-technology.com/docs/calculation-rules-for-quality-metrics)\n",
            "\n",
            "In this tutorial, we will put an emphasis on **Inference**."
         ]
      },
      {
         "cell_type": "markdown",
         "metadata": {},
         "source": [
            "## 1.2 Use cases "
         ]
      },
      {
         "cell_type": "markdown",
         "metadata": {},
         "source": [
            "We identify two main use cases for the use of **inference** :\n",
            "\n",
            "1. **You have a model in production**. When it receives assets, it automatically feeds a Kili project with both the asset and the predicted label. **You also have human workforce, whose job is to monitor the quality of the model**. They regularly manually label some data seen by the model.\n",
            "    - When a human submits a label, the inference score for that label is automatically computed using the predicted label.\n",
            "    - Low inference scores can indicate either a model performing badly on some kind of data, or a disagreement between humans and the model. This can help you to :\n",
            "    \n",
            "        - `Detect data drift`\n",
            "        - `Identify data on which the model needs improvement`\n",
            "       \n",
            "       \n",
            "2. **You used Kili to label data**, and you have **the first iteration of your model**. You can use **a part of the dataset as testing data**, and quickly get **test scores**. You could of course use your own metrics (rather than our own definition of agreement), but using Kili allows you to quickly filter and indentify the assets where your model is most different from the ground truth.\n",
            "    - When you push an inference label on an asset, the inference score is automatically computed for all most recent labels of the different people who labeled this asset.\n",
            "    - You can filter on low inference score, to understand why your model is failing, and how to fix it (getting more data, splitting or merging categories, etc...)\n",
            "\n",
            "\n",
            "Using Kili for monitoring or developing your model allows you to quickly iterate on the data used to train your model, allowing to get a better model faster."
         ]
      },
      {
         "cell_type": "markdown",
         "metadata": {},
         "source": [
            "# 2 - In practice"
         ]
      },
      {
         "cell_type": "markdown",
         "metadata": {},
         "source": [
            "## 2.1 Use case 1"
         ]
      },
      {
         "cell_type": "markdown",
         "metadata": {},
         "source": [
            "We start by creating a project and defining a model which, given an asset input x, returns a category (random in our example)"
         ]
      },
      {
         "cell_type": "code",
         "execution_count": 9,
         "metadata": {},
         "outputs": [],
         "source": [
            "json_interface ={\n",
            "    \"jobs\": {\n",
            "        \"CLASSIFICATION_JOB\": {\n",
            "            \"mlTask\": \"CLASSIFICATION\",\n",
            "            \"content\": {\n",
            "                \"categories\": {\n",
            "                    \"RED\": {\"name\": \"Red\"},\n",
            "                    \"BLACK\": {\"name\": \"Black\"},\n",
            "                    \"WHITE\": {\"name\": \"White\"},\n",
            "                    \"GREY\": {\"name\": \"Grey\"}\n",
            "                },\n",
            "                \"input\": \"radio\"\n",
            "            },\n",
            "            \"required\": 0,\n",
            "            \"isChild\": False,\n",
            "            \"instruction\": \"Color\"\n",
            "        }\n",
            "    }\n",
            "}\n",
            "\n",
            "project_id = kili.create_project(\n",
            "    title='Project demo inference',\n",
            "    input_type='IMAGE',\n",
            "    json_interface=json_interface\n",
            ")['id']\n"
         ]
      },
      {
         "cell_type": "markdown",
         "metadata": {},
         "source": [
            "Then we can simulate that our model is in production. Each time it receives an asset, it pushes it as well as the label it predicted to the project."
         ]
      },
      {
         "cell_type": "code",
         "execution_count": 10,
         "metadata": {},
         "outputs": [],
         "source": [
            "stream_of_assets = [\n",
            "    {\n",
            "        'url': \"https://storage.googleapis.com/label-public-staging/recipes/inference/black_car.jpg\",\n",
            "        'external_id': 'black_car.jpg'\n",
            "    },\n",
            "    {\n",
            "        'url': \"https://storage.googleapis.com/label-public-staging/recipes/inference/grey_car.jpg\",\n",
            "        'external_id': 'grey_car.jpg'\n",
            "    },\n",
            "    {\n",
            "        'url': \"https://storage.googleapis.com/label-public-staging/recipes/inference/white_car.jpg\",\n",
            "        'external_id': 'white_car.jpg'\n",
            "    },\n",
            "    {\n",
            "        'url': \"https://storage.googleapis.com/label-public-staging/recipes/inference/red_car.jpg\",\n",
            "        'external_id': 'red_car.jpg'\n",
            "    }\n",
            "]"
         ]
      },
      {
         "cell_type": "code",
         "execution_count": 11,
         "metadata": {},
         "outputs": [
            {
               "name": "stderr",
               "output_type": "stream",
               "text": [
                  "100%|██████████| 4/4 [00:00<00:00,  6.20it/s]\n"
               ]
            },
            {
               "ename": "NonExistingFieldError",
               "evalue": "Cannot query field id, externalId on object Asset. Admissible fields are: \n- id\n- consensusMark\n- consensusMarkCompute\n- consensusMarkPerCategory\n- content\n- contentJson\n- contentJsonCompute\n- createdAt\n- duration\n- durationCompute\n- externalId\n- honeypotMark\n- honeypotMarkCompute\n- inferenceMark\n- inferenceMarkCompute\n- isHoneypot\n- isToBeLabeledBy\n- issues\n- isUsedForConsensus\n- jsonContent\n- jsonMetadata\n- labels\n- latestLabel\n- latestLabelCompute\n- locks\n- metadataCompute\n- metadata\n- numberOfValidLocks\n- numberOfValidLocksCompute\n- ocrMetadata\n- priority\n- project\n- projectId\n- projectIdCompute\n- readPermissionsFromLabels\n- skipped\n- status\n- statusCompute\n- thumbnail\n- thumbnailCompute\n- toBeLabeledBy\n- updatedAt",
               "output_type": "error",
               "traceback": [
                  "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
                  "\u001b[0;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
                  "File \u001b[0;32m~/kili-python-sdk/src/kili/helpers.py:160\u001b[0m, in \u001b[0;36mfragment_builder\u001b[0;34m(fields, typed_dict_class)\u001b[0m\n\u001b[1;32m    159\u001b[0m \u001b[39mtry\u001b[39;00m:\n\u001b[0;32m--> 160\u001b[0m     type_of_fields[field]\n\u001b[1;32m    161\u001b[0m \u001b[39mexcept\u001b[39;00m \u001b[39mKeyError\u001b[39;00m \u001b[39mas\u001b[39;00m exception:\n",
                  "\u001b[0;31mKeyError\u001b[0m: 'id, externalId'",
                  "\nThe above exception was the direct cause of the following exception:\n",
                  "\u001b[0;31mNonExistingFieldError\u001b[0m                     Traceback (most recent call last)",
                  "Cell \u001b[0;32mIn [11], line 13\u001b[0m\n\u001b[1;32m      1\u001b[0m predictions \u001b[39m=\u001b[39m {\n\u001b[1;32m      2\u001b[0m     \u001b[39m'\u001b[39m\u001b[39mblack_car.jpg\u001b[39m\u001b[39m'\u001b[39m: \u001b[39m'\u001b[39m\u001b[39mWHITE\u001b[39m\u001b[39m'\u001b[39m,\n\u001b[1;32m      3\u001b[0m     \u001b[39m'\u001b[39m\u001b[39mgrey_car.jpg\u001b[39m\u001b[39m'\u001b[39m: \u001b[39m'\u001b[39m\u001b[39mGREY\u001b[39m\u001b[39m'\u001b[39m,\n\u001b[1;32m      4\u001b[0m     \u001b[39m'\u001b[39m\u001b[39mwhite_car.jpg\u001b[39m\u001b[39m'\u001b[39m: \u001b[39m'\u001b[39m\u001b[39mRED\u001b[39m\u001b[39m'\u001b[39m,\n\u001b[1;32m      5\u001b[0m     \u001b[39m'\u001b[39m\u001b[39mred_car.jpg\u001b[39m\u001b[39m'\u001b[39m: \u001b[39m'\u001b[39m\u001b[39mBLACK\u001b[39m\u001b[39m'\u001b[39m,\n\u001b[1;32m      6\u001b[0m }\n\u001b[1;32m      8\u001b[0m kili\u001b[39m.\u001b[39mappend_many_to_dataset(\n\u001b[1;32m      9\u001b[0m     project_id\u001b[39m=\u001b[39mproject_id,\n\u001b[1;32m     10\u001b[0m     content_array\u001b[39m=\u001b[39m[asset[\u001b[39m'\u001b[39m\u001b[39murl\u001b[39m\u001b[39m'\u001b[39m] \u001b[39mfor\u001b[39;00m asset \u001b[39min\u001b[39;00m stream_of_assets],\n\u001b[1;32m     11\u001b[0m     external_id_array\u001b[39m=\u001b[39m[asset[\u001b[39m'\u001b[39m\u001b[39mexternal_id\u001b[39m\u001b[39m'\u001b[39m] \u001b[39mfor\u001b[39;00m asset \u001b[39min\u001b[39;00m stream_of_assets]\n\u001b[1;32m     12\u001b[0m )\n\u001b[0;32m---> 13\u001b[0m assets \u001b[39m=\u001b[39m \u001b[39mlist\u001b[39m(kili\u001b[39m.\u001b[39massets(project_id\u001b[39m=\u001b[39mproject_id, fields\u001b[39m=\u001b[39m[\u001b[39m\"\u001b[39m\u001b[39mid, externalId\u001b[39m\u001b[39m\"\u001b[39m], disable_tqdm\u001b[39m=\u001b[39m\u001b[39mTrue\u001b[39;00m))\n\u001b[1;32m     14\u001b[0m assets_ids \u001b[39m=\u001b[39m [asset[\u001b[39m'\u001b[39m\u001b[39mid\u001b[39m\u001b[39m'\u001b[39m] \u001b[39mfor\u001b[39;00m asset \u001b[39min\u001b[39;00m assets]\n\u001b[1;32m     15\u001b[0m predicted_categories \u001b[39m=\u001b[39m [predictions[asset[\u001b[39m'\u001b[39m\u001b[39mexternalId\u001b[39m\u001b[39m'\u001b[39m]] \u001b[39mfor\u001b[39;00m asset \u001b[39min\u001b[39;00m assets]\n",
                  "File \u001b[0;32m~/kili-python-sdk/src/kili/queries/asset/__init__.py:242\u001b[0m, in \u001b[0;36mQueriesAsset.assets\u001b[0;34m(self, project_id, asset_id, skip, fields, asset_id_in, consensus_mark_gt, consensus_mark_lt, disable_tqdm, external_id_contains, first, format, honeypot_mark_gt, honeypot_mark_lt, label_author_in, label_consensus_mark_gt, label_consensus_mark_lt, label_created_at, label_created_at_gt, label_created_at_lt, label_honeypot_mark_gt, label_honeypot_mark_lt, label_type_in, metadata_where, skipped, status_in, updated_at_gte, updated_at_lte, as_generator, label_category_search, download_media, local_media_dir)\u001b[0m\n\u001b[1;32m    240\u001b[0m \u001b[39mif\u001b[39;00m as_generator:\n\u001b[1;32m    241\u001b[0m     \u001b[39mreturn\u001b[39;00m asset_generator\n\u001b[0;32m--> 242\u001b[0m \u001b[39mreturn\u001b[39;00m \u001b[39mlist\u001b[39;49m(asset_generator)\n",
                  "File \u001b[0;32m~/kili-python-sdk/src/kili/utils/pagination.py:57\u001b[0m, in \u001b[0;36mrow_generator_from_paginated_calls\u001b[0;34m(skip, first, count_method, count_kwargs, paged_call_method, paged_call_payload, fields, disable_tqdm, post_call_process)\u001b[0m\n\u001b[1;32m     55\u001b[0m \u001b[39mwith\u001b[39;00m tqdm(total\u001b[39m=\u001b[39mcount_rows_queried_total, disable\u001b[39m=\u001b[39mdisable_tqdm) \u001b[39mas\u001b[39;00m pbar:\n\u001b[1;32m     56\u001b[0m     \u001b[39mwhile\u001b[39;00m \u001b[39mTrue\u001b[39;00m:\n\u001b[0;32m---> 57\u001b[0m         rows \u001b[39m=\u001b[39m api_throttle(paged_call_method)(\n\u001b[1;32m     58\u001b[0m             count_rows_retrieved \u001b[39m+\u001b[39;49m skip,\n\u001b[1;32m     59\u001b[0m             count_rows_query_default,\n\u001b[1;32m     60\u001b[0m             paged_call_payload,\n\u001b[1;32m     61\u001b[0m             fields,\n\u001b[1;32m     62\u001b[0m         )\n\u001b[1;32m     64\u001b[0m         \u001b[39mif\u001b[39;00m rows \u001b[39mis\u001b[39;00m \u001b[39mNone\u001b[39;00m \u001b[39mor\u001b[39;00m \u001b[39mlen\u001b[39m(rows) \u001b[39m==\u001b[39m \u001b[39m0\u001b[39m:\n\u001b[1;32m     65\u001b[0m             \u001b[39mbreak\u001b[39;00m\n",
                  "File \u001b[0;32m~/kili-python-sdk/src/kili/utils/pagination.py:127\u001b[0m, in \u001b[0;36mapi_throttle.<locals>.throttled_wrapper\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    124\u001b[0m \u001b[39m@functools\u001b[39m\u001b[39m.\u001b[39mwraps(func)\n\u001b[1;32m    125\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mthrottled_wrapper\u001b[39m(\u001b[39m*\u001b[39margs, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwargs):\n\u001b[1;32m    126\u001b[0m     call_start \u001b[39m=\u001b[39m time\u001b[39m.\u001b[39mtime()\n\u001b[0;32m--> 127\u001b[0m     result \u001b[39m=\u001b[39m func(\u001b[39m*\u001b[39;49margs, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n\u001b[1;32m    128\u001b[0m     call_duration \u001b[39m=\u001b[39m time\u001b[39m.\u001b[39mtime() \u001b[39m-\u001b[39m call_start\n\u001b[1;32m    129\u001b[0m     \u001b[39mif\u001b[39;00m call_duration \u001b[39m<\u001b[39m THROTTLING_DELAY:\n",
                  "File \u001b[0;32m~/kili-python-sdk/src/kili/queries/asset/__init__.py:246\u001b[0m, in \u001b[0;36mQueriesAsset._query_assets\u001b[0;34m(self, skip, first, payload, fields)\u001b[0m\n\u001b[1;32m    244\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39m_query_assets\u001b[39m(\u001b[39mself\u001b[39m, skip: \u001b[39mint\u001b[39m, first: \u001b[39mint\u001b[39m, payload: \u001b[39mdict\u001b[39m, fields: List[\u001b[39mstr\u001b[39m]):\n\u001b[1;32m    245\u001b[0m     payload\u001b[39m.\u001b[39mupdate({\u001b[39m\"\u001b[39m\u001b[39mskip\u001b[39m\u001b[39m\"\u001b[39m: skip, \u001b[39m\"\u001b[39m\u001b[39mfirst\u001b[39m\u001b[39m\"\u001b[39m: first})\n\u001b[0;32m--> 246\u001b[0m     _gql_assets \u001b[39m=\u001b[39m gql_assets(fragment_builder(fields, AssetType))\n\u001b[1;32m    247\u001b[0m     result \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mauth\u001b[39m.\u001b[39mclient\u001b[39m.\u001b[39mexecute(_gql_assets, payload)\n\u001b[1;32m    248\u001b[0m     assets \u001b[39m=\u001b[39m format_result(\u001b[39m\"\u001b[39m\u001b[39mdata\u001b[39m\u001b[39m\"\u001b[39m, result, _object\u001b[39m=\u001b[39mList[Asset])\n",
                  "File \u001b[0;32m~/kili-python-sdk/src/kili/helpers.py:162\u001b[0m, in \u001b[0;36mfragment_builder\u001b[0;34m(fields, typed_dict_class)\u001b[0m\n\u001b[1;32m    160\u001b[0m     type_of_fields[field]\n\u001b[1;32m    161\u001b[0m \u001b[39mexcept\u001b[39;00m \u001b[39mKeyError\u001b[39;00m \u001b[39mas\u001b[39;00m exception:\n\u001b[0;32m--> 162\u001b[0m     \u001b[39mraise\u001b[39;00m NonExistingFieldError(\n\u001b[1;32m    163\u001b[0m         \u001b[39mf\u001b[39m\u001b[39m\"\u001b[39m\u001b[39mCannot query field \u001b[39m\u001b[39m{\u001b[39;00mfield\u001b[39m}\u001b[39;00m\u001b[39m on object \u001b[39m\u001b[39m{\u001b[39;00mtyped_dict_class\u001b[39m.\u001b[39m\u001b[39m__name__\u001b[39m\u001b[39m}\u001b[39;00m\u001b[39m. Admissible\u001b[39m\u001b[39m\"\u001b[39m\n\u001b[1;32m    164\u001b[0m         \u001b[39m\"\u001b[39m\u001b[39m fields are: \u001b[39m\u001b[39m\\n\u001b[39;00m\u001b[39m- \u001b[39m\u001b[39m\"\u001b[39m \u001b[39m+\u001b[39m \u001b[39m\"\u001b[39m\u001b[39m\\n\u001b[39;00m\u001b[39m- \u001b[39m\u001b[39m\"\u001b[39m\u001b[39m.\u001b[39mjoin(type_of_fields\u001b[39m.\u001b[39mkeys())\n\u001b[1;32m    165\u001b[0m     ) \u001b[39mfrom\u001b[39;00m \u001b[39mexception\u001b[39;00m\n\u001b[1;32m    166\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39misinstance\u001b[39m(field, \u001b[39mstr\u001b[39m):\n\u001b[1;32m    167\u001b[0m     fragment \u001b[39m+\u001b[39m\u001b[39m=\u001b[39m \u001b[39mf\u001b[39m\u001b[39m\"\u001b[39m\u001b[39m \u001b[39m\u001b[39m{\u001b[39;00mfield\u001b[39m}\u001b[39;00m\u001b[39m\"\u001b[39m\n",
                  "\u001b[0;31mNonExistingFieldError\u001b[0m: Cannot query field id, externalId on object Asset. Admissible fields are: \n- id\n- consensusMark\n- consensusMarkCompute\n- consensusMarkPerCategory\n- content\n- contentJson\n- contentJsonCompute\n- createdAt\n- duration\n- durationCompute\n- externalId\n- honeypotMark\n- honeypotMarkCompute\n- inferenceMark\n- inferenceMarkCompute\n- isHoneypot\n- isToBeLabeledBy\n- issues\n- isUsedForConsensus\n- jsonContent\n- jsonMetadata\n- labels\n- latestLabel\n- latestLabelCompute\n- locks\n- metadataCompute\n- metadata\n- numberOfValidLocks\n- numberOfValidLocksCompute\n- ocrMetadata\n- priority\n- project\n- projectId\n- projectIdCompute\n- readPermissionsFromLabels\n- skipped\n- status\n- statusCompute\n- thumbnail\n- thumbnailCompute\n- toBeLabeledBy\n- updatedAt"
               ]
            }
         ],
         "source": [
            "predictions = {\n",
            "    'black_car.jpg': 'WHITE',\n",
            "    'grey_car.jpg': 'GREY',\n",
            "    'white_car.jpg': 'RED',\n",
            "    'red_car.jpg': 'BLACK',\n",
            "}\n",
            "\n",
            "kili.append_many_to_dataset(\n",
            "    project_id=project_id,\n",
            "    content_array=[asset['url'] for asset in stream_of_assets],\n",
            "    external_id_array=[asset['external_id'] for asset in stream_of_assets]\n",
            ")\n",
            "assets = list(kili.assets(project_id=project_id, fields=[\"id\", \"externalId\"], disable_tqdm=True))\n",
            "assets_ids = [asset['id'] for asset in assets]\n",
            "predicted_categories = [predictions[asset['externalId']] for asset in assets]\n",
            "inference_labels = [{\n",
            "    \"CLASSIFICATION_JOB\": {\n",
            "        \"categories\": [{\"name\": predicted_category}]\n",
            "    }\n",
            "} for predicted_category in predicted_categories]\n",
            "kili.append_labels(\n",
            "    json_response_array=inference_labels,\n",
            "    asset_id_array=assets_ids,\n",
            "    label_type='INFERENCE',\n",
            ")"
         ]
      },
      {
         "cell_type": "markdown",
         "metadata": {},
         "source": [
            "Then, human labelers can annotate a subsample of the assets pushed to Kili. \n",
            "\n",
            "Note : you can even automatically [prioritize assets](https://docs.kili-technology.com/docs/queue-prioritization) to be reviewed by a human by using the model's uncertainty. When the model is unsure of its predictions, it may indicate wrong labels."
         ]
      },
      {
         "cell_type": "code",
         "execution_count": null,
         "metadata": {},
         "outputs": [],
         "source": [
            "ground_truths = {\n",
            "    'black_car.jpg': 'BLACK',\n",
            "    'grey_car.jpg': 'GREY',\n",
            "    'white_car.jpg': 'WHITE',\n",
            "    'red_car.jpg': 'RED'\n",
            "}\n",
            "\n",
            "human_labels = [{\n",
            "    \"CLASSIFICATION_JOB\": {\n",
            "        \"categories\": [{\"name\": ground_truths[asset[\"externalId\"]]}]\n",
            "    }\n",
            "} for asset in assets]\n",
            "kili.append_labels(\n",
            "    json_response_array=human_labels,\n",
            "    asset_id_array=assets_ids,\n",
            "    label_type='DEFAULT',\n",
            ")"
         ]
      },
      {
         "cell_type": "markdown",
         "metadata": {},
         "source": [
            "You can now fetch the agreement between the human and the model, for human labels :"
         ]
      },
      {
         "cell_type": "code",
         "execution_count": null,
         "metadata": {
            "scrolled": true
         },
         "outputs": [],
         "source": [
            "labels = kili.labels(project_id=project_id,\n",
            "            fields=['inferenceMark', 'id', 'labelOf.id'], type_in=['DEFAULT'])\n",
            "labels"
         ]
      },
      {
         "cell_type": "code",
         "execution_count": null,
         "metadata": {},
         "outputs": [],
         "source": [
            "# For testing\n",
            "\n",
            "for label in labels:\n",
            "    external_id = id_to_external_id[label[\"labelOf\"][\"id\"]]\n",
            "    if predictions[external_id] == ground_truths[external_id]:\n",
            "        assert label['inferenceMark'] == 1\n",
            "    else:\n",
            "        assert label['inferenceMark'] < 1"
         ]
      },
      {
         "cell_type": "markdown",
         "metadata": {},
         "source": [
            "This allows you to identify problems :"
         ]
      },
      {
         "cell_type": "code",
         "execution_count": null,
         "metadata": {},
         "outputs": [],
         "source": [
            "for label in labels:\n",
            "    if label['inferenceMark'] < 1:\n",
            "        inference_label = kili.labels(project_id=project_id, asset_id=label['labelOf']['id'], type_in=['INFERENCE'], disable_tqdm=True)[0]\n",
            "        human_label = kili.labels(project_id=project_id, label_id=label['id'], disable_tqdm=True)[0]\n",
            "        inference_category = inference_label['jsonResponse']['CLASSIFICATION_JOB']['categories'][0]['name']\n",
            "        human_category = human_label['jsonResponse']['CLASSIFICATION_JOB']['categories'][0]['name']\n",
            "        print(f'The model predicted {inference_category} but the human predicted {human_category}')"
         ]
      },
      {
         "cell_type": "markdown",
         "metadata": {},
         "source": [
            "You can also find the assets with most disagreement directly from the interface with the filter \"Human/Model IOU\". Low IOU indicates low agreement : \n",
            "\n",
            "![inference](https://storage.googleapis.com/label-public-staging/recipes/inference/inference_filter.png)"
         ]
      },
      {
         "cell_type": "markdown",
         "metadata": {},
         "source": [
            "## 2.2 Use case 2"
         ]
      },
      {
         "cell_type": "markdown",
         "metadata": {},
         "source": [
            "We can invert the previous use case. We start by having a human labeled dataset, and we insert model predictions, to simulate testing our model on test data."
         ]
      },
      {
         "cell_type": "code",
         "execution_count": null,
         "metadata": {},
         "outputs": [],
         "source": [
            "project_id = kili.create_project(\n",
            "    title='Project demo inference 2',\n",
            "    input_type='IMAGE',\n",
            "    json_interface=json_interface\n",
            ")['id']"
         ]
      },
      {
         "cell_type": "code",
         "execution_count": null,
         "metadata": {},
         "outputs": [],
         "source": [
            "labeled_assets = [\n",
            "    {\n",
            "        'url': \"https://storage.googleapis.com/label-public-staging/recipes/inference/black_car.jpg\",\n",
            "        'external_id': 'black_car.jpg'\n",
            "    },\n",
            "    {\n",
            "        'url': \"https://storage.googleapis.com/label-public-staging/recipes/inference/grey_car.jpg\",\n",
            "        'external_id': 'grey_car.jpg'\n",
            "    },\n",
            "    {\n",
            "        'url': \"https://storage.googleapis.com/label-public-staging/recipes/inference/white_car.jpg\",\n",
            "        'external_id': 'white_car.jpg'\n",
            "    },\n",
            "    {\n",
            "        'url': \"https://storage.googleapis.com/label-public-staging/recipes/inference/red_car.jpg\",\n",
            "        'external_id': 'red_car.jpg'\n",
            "    }\n",
            "]\n",
            "ground_truths = {\n",
            "    'black_car.jpg': 'BLACK',\n",
            "    'grey_car.jpg': 'GREY',\n",
            "    'white_car.jpg': 'WHITE',\n",
            "    'red_car.jpg': 'RED'\n",
            "}"
         ]
      },
      {
         "cell_type": "code",
         "execution_count": null,
         "metadata": {},
         "outputs": [],
         "source": [
            "\n",
            "kili.append_many_to_dataset(\n",
            "    project_id=project_id,\n",
            "    content_array=[asset['url'] for asset in labeled_assets],\n",
            "    external_id_array=[asset['external_id'] for asset in labeled_assets]\n",
            ")\n",
            "assets = list(kili.assets(project_id=project_id, fields=['id', 'externalId']))\n",
            "assets_ids = [asset['id'] for asset in assets]\n",
            "human_labels = [{\n",
            "    \"CLASSIFICATION_JOB\": {\n",
            "        \"categories\": [{\"name\": ground_truths[asset['external_id']]}]\n",
            "    }\n",
            "} for asset in assets]\n",
            "kili.append_labels(\n",
            "    json_response_array=human_labels,\n",
            "    asset_id_array=assets_ids,\n",
            "    label_type='DEFAULT',\n",
            ")"
         ]
      },
      {
         "cell_type": "markdown",
         "metadata": {},
         "source": [
            "Then our model is fit using maybe 80% of the training data. We can then run it against the remaining 20%, and upload its predictions to Kili :"
         ]
      },
      {
         "cell_type": "code",
         "execution_count": null,
         "metadata": {},
         "outputs": [],
         "source": [
            "test_labels = [{\n",
            "    \"CLASSIFICATION_JOB\": {\n",
            "        \"categories\": [{\"name\": predictions[asset[\"externalId\"]]}]\n",
            "    }\n",
            "} for asset in assets]\n",
            "kili.append_labels(\n",
            "    json_response_array=test_labels,\n",
            "    asset_id_array=assets_ids,\n",
            "    label_type='INFERENCE',\n",
            ")"
         ]
      },
      {
         "cell_type": "code",
         "execution_count": null,
         "metadata": {},
         "outputs": [],
         "source": [
            "labels = kili.labels(project_id=project_id,\n",
            "            fields=['inferenceMark', 'id', 'labelOf.id'], type_in=['DEFAULT'])\n",
            "labels"
         ]
      },
      {
         "cell_type": "code",
         "execution_count": null,
         "metadata": {},
         "outputs": [],
         "source": [
            "# For testing\n",
            "for label in labels:\n",
            "    external_id = id_to_external_id[label[\"labelOf\"][\"id\"]]\n",
            "    if predictions[external_id] == ground_truths[external_id]:\n",
            "        assert label['inferenceMark'] == 1\n",
            "    else:\n",
            "        assert label['inferenceMark'] < 1"
         ]
      },
      {
         "cell_type": "code",
         "execution_count": null,
         "metadata": {},
         "outputs": [],
         "source": [
            "for label in labels:\n",
            "    if label['inferenceMark'] < 1:\n",
            "        inference_label = list(kili.labels(project_id=project_id, asset_id=label['labelOf']['id'], type_in=['INFERENCE'], disable_tqdm=True))[0]\n",
            "        human_label = list(kili.labels(project_id=project_id, label_id=label['id'], disable_tqdm=True))[0]\n",
            "        inference_category = inference_label['jsonResponse']['CLASSIFICATION_JOB']['categories'][0]['name']\n",
            "        human_category = human_label['jsonResponse']['CLASSIFICATION_JOB']['categories'][0]['name']\n",
            "        print(f'The human predicted {human_category} but the model predicted {inference_category}')"
         ]
      },
      {
         "cell_type": "markdown",
         "metadata": {},
         "source": [
            "You can also find the assets where the prediction and the human disagree most directly from the interface with the filter \"Human/Model IOU\" : \n",
            "\n",
            "![inference](https://storage.googleapis.com/label-public-staging/recipes/inference/inference_test_filter.png)"
         ]
      },
      {
         "cell_type": "markdown",
         "metadata": {},
         "source": [
            "In this tutorial, we accomplished the following:\n",
            "\n",
            "We introduced the concept of Kili inference labels. We showed how to make use of such labels, in two practical use cases.\n",
            "\n",
            "You can also visit the Kili website or Kili documentation for more info!"
         ]
      }
   ],
   "metadata": {
      "kernelspec": {
         "display_name": "kili-python-sdk",
         "language": "python",
         "name": "kili-python-sdk"
      },
      "language_info": {
         "codemirror_mode": {
            "name": "ipython",
            "version": 3
         },
         "file_extension": ".py",
         "mimetype": "text/x-python",
         "name": "python",
         "nbconvert_exporter": "python",
         "pygments_lexer": "ipython3",
         "version": "3.10.4"
      },
      "vscode": {
         "interpreter": {
            "hash": "de396e6bb0ca1b0abec04a877b6eb6711952a215fc7f5dc02d30f83999f7a5a6"
         }
      }
   },
   "nbformat": 4,
   "nbformat_minor": 4
}
