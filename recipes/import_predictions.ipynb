{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Kili Tutorial: Importing predictions\n",
    "In this tutorial, we will show how to import predictions (pre-annotations) into Kili in order to help annotators and accelerate the whole annotation process. The goal of this tutorial is to illustrate some basic components and concepts of Kili in a simple way, but also to dive into the actual process of iteratively developing real applications in Kili.\n",
    "\n",
    "Additionally:\n",
    "\n",
    "For an overview of Kili, visit https://kili-technology.com You can also check out the Kili documentation https://cloud.kili-technology.com/docs. Our goal is to export labels that can predict whether an image contains a Porsche or a Tesla.\n",
    "\n",
    "The tutorial is divided into four parts:\n",
    "\n",
    "1. Understanding the different types of labels\n",
    "2. Understanding the data model of a label\n",
    "3. Pushing predictions to Kili\n",
    "4. Visualizing predictions in Kili\n",
    "\n",
    "## 1. Understanding the different types of labels\n",
    "A label is the annotation or combination of all annotations created on an asset. For example, all houses identified on the satellite image, or all the information annotated text on the document.\n",
    "\n",
    "There are four categories of labels:\n",
    "\n",
    "- **default**: an ordinary label, made by an annotator\n",
    "- **prediction**: a pre-annotation, made by a model\n",
    "- **autosave**: a temporary label, made by the app every minute while annotating\n",
    "- **review**: a check, carried out by a reviewer\n",
    "\n",
    "When you export data (see [How to export labels](https://github.com/kili-technology/kili-playground/blob/master/recipes/export_labels.ipynb)), you can find out which category a label belongs to by looking at the field `labelType`. It can take the following values: `PREDICTION`, `DEFAULT`, `AUTOSAVE`, `REVIEW`.\n",
    "\n",
    "## 2. Understanding the data model of a label\n",
    "Predictions are pushed in Kili using Python dictionaries. The format of the dictionary to be pushed depends on the type of data (text, image, audio ...), the machine learning task(s) (e.g. simple, multiple classification, transcription, named entity recognition, object detection, etc ...) and their order. In summary, it depends on the JSON format that describes the interface of your annotation project.\n",
    "\n",
    "The following cells will show you how to view this JSON. You need to update `api_key` and `api_endpoint` before, or to have set those as global environment variables."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Authentication\n",
    "import os\n",
    "\n",
    "#!pip install kili # uncomment if you don't have kili installed already\n",
    "from kili.client import Kili\n",
    "\n",
    "api_key = os.getenv('KILI_USER_API_KEY')\n",
    "api_endpoint = os.getenv('KILI_API_ENDPOINT') # If you use Kili SaaS, use the url 'https://cloud.kili-technology.com/api/label/v2/graphql'\n",
    "\n",
    "kili = Kili(api_key=api_key, api_endpoint=api_endpoint)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let us create a new image classification project and try to retrieve the label of one asset, to understand the **data model**."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "title = 'Example'\n",
    "input_type = 'IMAGE'\n",
    "json_interface = {\n",
    "\t\"jobs\": {\n",
    "\t\t\"JOB_0\": {\n",
    "\t\t\t\"mlTask\": \"CLASSIFICATION\",\n",
    "\t\t\t\"required\": 1,\n",
    "\t\t\t\"content\": {\n",
    "\t\t\t\t\"categories\": {\n",
    "\t\t\t\t\t\"OBJECT_A\": {\n",
    "\t\t\t\t\t\t\"name\": \"Object A\",\n",
    "\t\t\t\t\t\t\"children\": []\n",
    "\t\t\t\t\t},\n",
    "\t\t\t\t\t\"OBJECT_B\": {\n",
    "\t\t\t\t\t\t\"name\": \"Object B\",\n",
    "\t\t\t\t\t\t\"children\": []\n",
    "\t\t\t\t\t}\n",
    "\t\t\t\t},\n",
    "\t\t\t\t\"input\": \"radio\"\n",
    "\t\t\t}\n",
    "\t\t}\n",
    "\t}\n",
    "}\n",
    "project = kili.create_project(input_type=input_type, json_interface=json_interface, title=title)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Then, make sure the project created has assets already uploaded. You can upload some using the `append_many_to_dataset` function as we use in this notebook. To help you, you can also check out the recipe [Create a project](https://github.com/kili-technology/kili-playground/blob/master/recipes/create_project.ipynb).\n",
    "On Kili platform, label the first asset and execute the following code to retrieve it."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "assets = kili.assets(project_id=project['id'])\n",
    "if assets:\n",
    "    label = assets[0]['labels']\n",
    "    print(label)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Taking the previous example of image classification task, here are the fields you will have for the data model of a label :\n",
    "\n",
    "- `author`: User that created the Label.\n",
    "  - `email`: Email of the user\n",
    "  - `id`: Unique identifier of the User in the Kili database\n",
    "- `createdAt`: Date of creation of the Label.\n",
    "- `id`: Unique identifier of the Label in the Kili database.\n",
    "- `jsonResponse`: List of label annotations. See detail lower.\n",
    "  - `CLASSIFICATION_JOB`: First annotation task, as defined in the interface builder.\n",
    "    - `categories`: Category the Asset belongs to.\n",
    "      - `name`: Name of the category.\n",
    "      - `confidence`: Category Confidence Index. The value is between 0 and 100 for a PREDICTION type Label (produced by a model). The value is always 100 for a Label created by a human.\n",
    "\n",
    "For other types of tasks the fields will be the same except for the `jsonResponse` for which we follow more or less the data model of the Google APIs.\n",
    "\n",
    "## 3. Pushing predictions to Kili\n",
    "To make a prediction in Kili, you need 4 pieces of information:\n",
    "\n",
    "- A project ID\n",
    "- An external asset ID\n",
    "- A model name (arbitrary)\n",
    "- A jsonResponse, in the same format as the labels `jsonResponse` (see above)\n",
    "\n",
    "We are going to present an example for each category of project, with an interface of project, one or two assets and the form of the associated `jsonResponse` for one prediction for one of the assets.\n",
    "\n",
    "We'll also recall the procedure to get to this point, including the creation of a project, the importation of assets into those projects, and, finally, the importation of predictions. This process will be triggered for every example at the end of the notebook."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "project_examples = []"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### a) Classification examples"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "heading_collapsed": true
   },
   "source": [
    "#### - Single-class classification"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "project_examples.append(\n",
    "    {\n",
    "        'title': 'Spam classification',\n",
    "        'description': 'Classify text as spam or not',\n",
    "        'input_type': 'TEXT',\n",
    "        'json_interface': {\n",
    "            \"jobs\": {\n",
    "                \"JOB_0\": {\n",
    "                    \"mlTask\": \"CLASSIFICATION\",\n",
    "                    \"instruction\": \"Is it a spam?\",\n",
    "                    \"required\": 1,\n",
    "                    \"isChild\": False,\n",
    "                    \"isVisible\": True,\n",
    "                    \"content\": {\n",
    "                        \"categories\": {\n",
    "                            \"YES_IT_IS_SPAM\": { \"name\": \"Yes, it is spam\", \"children\": [] },\n",
    "                            \"NO\": { \"name\": \"No\", \"children\": []}\n",
    "                        },\n",
    "                        \"input\": \"radio\"\n",
    "                    }\n",
    "                }\n",
    "            }\n",
    "        },\n",
    "        'assets_to_import': [\n",
    "            'Lorem ipsum dolor sit amet, consectetur adipiscing elit.',\n",
    "        ],\n",
    "        'json_response': {\n",
    "            \"JOB_0\": {\n",
    "                \"categories\": [{\"name\": \"YES_IT_IS_SPAM\", \"confidence\": 100 }]\n",
    "            }\n",
    "        },\n",
    "        'model_name': 'spam-classification-v0.0.1'\n",
    "    }\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### - Multi-class classification"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "project_examples.append(\n",
    "    {\n",
    "        'title': 'Delivery issue classification',\n",
    "        'description': 'Classify the problems encountered by the users',\n",
    "        'input_type': 'TEXT',\n",
    "        'json_interface': {\n",
    "            \"jobs\": {\n",
    "                \"JOB_0\": {\n",
    "                    \"mlTask\": \"CLASSIFICATION\",\n",
    "                    \"instruction\": \"What was the problem encountered?\",\n",
    "                    \"required\": 1,\n",
    "                    \"isChild\": False,\n",
    "                    \"isVisible\": True,\n",
    "                    \"content\": {\n",
    "                        \"categories\": {\n",
    "                            \"DELIVERY\": { \"name\": \"Delivery\", \"children\": [] },\n",
    "                            \"BAD_PRODUCT\": { \"name\": \"Bad product\", \"children\": [] },\n",
    "                            \"OPINION_CHANGED\": { \"name\": \"Opinion changed\", \"children\": [] },\n",
    "                            \"ILLEGAL_PRODUCT\": { \"name\": \"Illegal product\", \"children\": [] }\n",
    "                        },\n",
    "                        \"input\": \"checkbox\"\n",
    "                    }\n",
    "                }\n",
    "            }\n",
    "        },\n",
    "        'assets_to_import': [\n",
    "            'Good morning, I wanted to contact you about my delivery, that is not what was supposed to be', \n",
    "            'NOT THE GOOD DELIVERY AND LATE'\n",
    "        ],\n",
    "        'json_response': {\n",
    "            \"JOB_0\": {\n",
    "                \"categories\": [\n",
    "                    { \"name\": \"BAD_PRODUCT\", \"confidence\": 100 },\n",
    "                    { \"name\": \"ILLEGAL_PRODUCT\", \"confidence\": 100 }\n",
    "                ]\n",
    "            }\n",
    "        },\n",
    "        'model_name' : 'delivery-problem-classification-v0.0.1'\n",
    "    }\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### - Single-class classification, with 2 different jobs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "project_examples.append(\n",
    "    {\n",
    "        'title': 'News articles',\n",
    "        'description': 'Classify text as a news article and describe the type of language',\n",
    "        'input_type': 'TEXT',\n",
    "        'json_interface': {\n",
    "            \"jobs\": {\n",
    "                \"JOB_0\": {\n",
    "                    \"mlTask\": \"CLASSIFICATION\",\n",
    "                    \"instruction\": \"Is it a news article?\",\n",
    "                    \"required\": 1,\n",
    "                    \"isChild\": False,\n",
    "                    \"isVisible\": True,\n",
    "                    \"content\": {\n",
    "                        \"categories\": {\n",
    "                            \"YES_IT_IS_A_NEWS_ARTICLE\": { \"name\": \"Yes, it is a news article\", \"children\": [] },\n",
    "                            \"NO\": { \"name\": \"No.\", \"children\": [] }\n",
    "                        },\n",
    "                        \"input\": \"radio\"\n",
    "                    }\n",
    "                },\n",
    "                \"JOB_1\": {\n",
    "                    \"mlTask\": \"CLASSIFICATION\",\n",
    "                    \"instruction\": \"What type of language is used?\",\n",
    "                    \"required\": 1,\n",
    "                    \"isChild\": False,\n",
    "                    \"isVisible\": True,\n",
    "                    \"content\": {\n",
    "                        \"categories\": {\n",
    "                            \"FORMAL\": { \"name\": \"Formal\", \"children\": [] },\n",
    "                            \"COMMON\": { \"name\": \"Common\", \"children\": [] }\n",
    "                        },\n",
    "                        \"input\": \"radio\"\n",
    "                    }\n",
    "                }\n",
    "            }\n",
    "        },\n",
    "        'assets_to_import': [\n",
    "            'Lorem ipsum dolor sit amet, consectetur adipiscing elit.', \n",
    "            'Vestibulum in elit sit amet turpis sagittis venenatis ac in nisl.'\n",
    "        ],\n",
    "        'json_response': {\n",
    "            \"JOB_0\": {\n",
    "                \"categories\": [{ \"name\": \"YES_IT_IS_A_NEWS_ARTICLE\", \"confidence\": 100 }]\n",
    "            },\n",
    "            \"JOB_1\": {\n",
    "                \"categories\": [{ \"name\": \"COMMON\", \"confidence\": 100 }]\n",
    "            }\n",
    "        },\n",
    "        'model_name': 'news-article-classification-v0.0.1'\n",
    "    }\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### - Single-class classification with nested classification"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "project_examples.append(\n",
    "    {\n",
    "        'title': 'News articles about sports',\n",
    "        'description': 'Classify text as a news article dealing with sports',\n",
    "        'input_type': 'TEXT',\n",
    "        'json_interface': {\n",
    "            \"jobs\": {\n",
    "                \"JOB_0\": {\n",
    "                    \"mlTask\": \"CLASSIFICATION\",\n",
    "                    \"instruction\": \"Is it a news article?\",\n",
    "                    \"required\": 1,\n",
    "                    \"isChild\": False,\n",
    "                    \"isVisible\": True,\n",
    "                    \"content\": {\n",
    "                        \"categories\": {\n",
    "                            \"YES_IT_IS_A_NEWS_ARTICLE\": {\n",
    "                                \"name\": \"Yes, it is a news article.\",\n",
    "                                \"children\": [\"NESTED_JOB\"]\n",
    "                            },\n",
    "                            \"NO\": {\n",
    "                                \"name\": \"No.\",\n",
    "                                \"children\": []\n",
    "                            }\n",
    "                        },\n",
    "                        \"input\": \"radio\"\n",
    "                    }\n",
    "                },\n",
    "                \"NESTED_JOB\": {\n",
    "                    \"mlTask\": \"CLASSIFICATION\",\n",
    "                    \"instruction\": \"What is the article about?\",\n",
    "                    \"required\": 1,\n",
    "                    \"isChild\": True,\n",
    "                    \"isVisible\": True,\n",
    "                    \"content\": {\n",
    "                        \"categories\": {\n",
    "                            \"SPORTS\": { \"name\": \"Sports\", \"children\": [] },\n",
    "                            \"OTHERS\": { \"name\": \"Others\", \"children\": [] }\n",
    "                        },\n",
    "                        \"input\": \"radio\"\n",
    "                    }\n",
    "                }\n",
    "            }\n",
    "        },\n",
    "        'assets_to_import': [\n",
    "            'Lorem ipsum dolor sit amet, consectetur adipiscing elit.', \n",
    "            'Vestibulum in elit sit amet turpis sagittis venenatis ac in nisl.'\n",
    "        ],\n",
    "        'json_response': {\n",
    "            \"JOB_0\": {\n",
    "                \"categories\": [{\"name\": \"YES_IT_IS_A_NEWS_ARTICLE\", \"confidence\": 100 }],\n",
    "                \"children\": {\n",
    "                    \"NESTED_JOB\": {\n",
    "                        \"categories\": [{ \"name\": \"SPORTS\", \"confidence\": 100 }]\n",
    "                    }\n",
    "                }\n",
    "            }\n",
    "        },\n",
    "        'model_name': 'news-article-classification-v0.0.2'\n",
    "    }\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "heading_collapsed": true
   },
   "source": [
    "### b) Object detection examples"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "hidden": true
   },
   "source": [
    "#### - Bounding box object"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "project_examples.append(\n",
    "    {\n",
    "        'title': 'Car brand recognition',\n",
    "        'description': 'Identify and locate cars',\n",
    "        'input_type': 'IMAGE',\n",
    "        'json_interface': {\n",
    "            \"jobs\": {\n",
    "                \"JOB_0\": {\n",
    "                    \"mlTask\": \"OBJECT_DETECTION\",\n",
    "                    \"tools\": [\n",
    "                        \"rectangle\"\n",
    "                    ],\n",
    "                    \"instruction\": \"What car brand?\",\n",
    "                    \"required\": 1,\n",
    "                    \"isChild\": False,\n",
    "                    \"content\": {\n",
    "                        \"categories\": {\n",
    "                            \"TESLA\": { \"name\": \"Tesla\", \"children\": [] },\n",
    "                            \"FERRARI\": { \"name\": \"Ferrari\", \"children\": [] }\n",
    "                        },\n",
    "                        \"input\": \"radio\"\n",
    "                    }\n",
    "                }\n",
    "            }\n",
    "        },\n",
    "        'assets_to_import': [\n",
    "            \"https://images.caradisiac.com/logos/3/8/6/7/253867/S0-tesla-enregistre-d-importantes-pertes-au-premier-trimestre-175948.jpg\", \n",
    "            \"https://img.sportauto.fr/news/2018/11/28/1533574/1920%7C1280%7Cc096243e5460db3e5e70c773.jpg\"\n",
    "        ],\n",
    "        'json_response': {\n",
    "            \"JOB_0\": {\n",
    "                \"annotations\": [{\n",
    "                    \"boundingPoly\": [{\n",
    "                        \"normalizedVertices\": [\n",
    "                            { \"x\": 0.16, \"y\": 0.82},\n",
    "                            { \"x\": 0.16, \"y\": 0.32 },\n",
    "                            { \"x\": 0.82, \"y\": 0.32 },\n",
    "                            { \"x\": 0.82, \"y\": 0.82 }\n",
    "                        ]}\n",
    "                    ],\n",
    "                    \"categories\": [{ \"name\": \"TESLA\", \"confidence\": 100 }],\n",
    "                    \"mid\": \"unique-tesla\",\n",
    "                    \"type\": \"rectangle\",\n",
    "                }]\n",
    "            }\n",
    "        },\n",
    "        'model_name': 'car-brand-localisation-v0.0.1'\n",
    "    }\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "hidden": true
   },
   "source": [
    "#### - Bounding box with nested classification"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "project_examples.append(\n",
    "    {\n",
    "        'title': 'Car brand & color recognition',\n",
    "        'description': 'Identify brand and color',\n",
    "        'input_type': 'IMAGE',\n",
    "        'json_interface': {\n",
    "            \"jobs\": {\n",
    "                \"CLASSIFICATION_JOB\": {\n",
    "                    \"mlTask\": \"CLASSIFICATION\",\n",
    "                    \"instruction\": \"What color?\",\n",
    "                    \"required\": 0,\n",
    "                    \"isChild\": True,\n",
    "                    \"isVisible\": True,\n",
    "                    \"content\": {\n",
    "                        \"categories\": {\n",
    "                            \"RED\": { \"name\": \"Red\", \"children\": [] },\n",
    "                            \"BLACK\": { \"name\": \"Black\", \"children\": [] },\n",
    "                            \"WHITE\": { \"name\": \"White\", \"children\": [] },\n",
    "                            \"GREY\": { \"name\": \"Grey\", \"children\": [] }\n",
    "                        },\n",
    "                        \"input\": \"checkbox\"\n",
    "                    },\n",
    "                },\n",
    "                \"JOB\": {\n",
    "                    \"mlTask\": \"OBJECT_DETECTION\",\n",
    "                    \"tools\": [\n",
    "                        \"rectangle\"\n",
    "                    ],\n",
    "                    \"instruction\": \"What car brand?\",\n",
    "                    \"required\": 1,\n",
    "                    \"isChild\": False,\n",
    "                    \"content\": {\n",
    "                        \"categories\": {\n",
    "                            \"TESLA\": {\n",
    "                                \"name\": \"Tesla\",\n",
    "                                \"children\": [\"CLASSIFICATION_JOB\"]\n",
    "                            },\n",
    "                            \"FERRARI\": {\n",
    "                                \"name\": \"Ferrari\",\n",
    "                                \"children\": [\"CLASSIFICATION_JOB\"]\n",
    "                            }\n",
    "                        },\n",
    "                        \"input\": \"radio\"\n",
    "                    }\n",
    "                }\n",
    "            }\n",
    "        },\n",
    "        'assets_to_import': [\n",
    "            \"https://img.sportauto.fr/news/2018/11/28/1533574/1920%7C1280%7Cc096243e5460db3e5e70c773.jpg\",\n",
    "            \"https://images.caradisiac.com/logos/3/8/6/7/253867/S0-tesla-enregistre-d-importantes-pertes-au-premier-trimestre-175948.jpg\"\n",
    "        ],\n",
    "        'json_response': {\n",
    "            \"JOB\": {\n",
    "                \"annotations\": [{\n",
    "                    \"boundingPoly\": [{\n",
    "                        \"normalizedVertices\": [\n",
    "                            { \"x\": 0.09, \"y\": 0.84 },\n",
    "                            { \"x\": 0.09, \"y\": 0.36 },\n",
    "                            { \"x\": 0.92, \"y\": 0.36 },\n",
    "                            { \"x\": 0.92, \"y\": 0.84 }\n",
    "                        ]\n",
    "                    }],\n",
    "                    \"categories\": [{ \"name\": \"FERRARI\", \"confidence\": 100 }],\n",
    "                    \"mid\": \"unique-ferrari\",\n",
    "                    \"type\": \"rectangle\",\n",
    "                    \"children\": {\n",
    "                        \"CLASSIFICATION_JOB\": {\n",
    "                            \"categories\": [{ \"name\": \"GREY\", \"confidence\": 100 }]\n",
    "                        }\n",
    "                    }\n",
    "                }]\n",
    "            }\n",
    "        },\n",
    "        'model_name': 'car-brand-color-v0.0.1'\n",
    "    }\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "hidden": true
   },
   "source": [
    "#### - Bounding boxes with relations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "project_examples.append(\n",
    "    {\n",
    "        'title': 'Car and wheels recognition',\n",
    "        'description': 'Identify and locate cars and their wheels',\n",
    "        'input_type': 'IMAGE',\n",
    "        'json_interface': {\n",
    "            \"jobs\": {\n",
    "                \"JOB_0\": {\n",
    "                    \"mlTask\": \"OBJECT_DETECTION\",\n",
    "                    \"tools\": [\n",
    "                        \"rectangle\"\n",
    "                    ],\n",
    "                    \"instruction\": \"What part of the car can you see?\",\n",
    "                    \"required\": 1,\n",
    "                    \"isChild\": False,\n",
    "                    \"content\": {\n",
    "                        \"categories\": {\n",
    "                            \"WHOLE_CAR\": { \"name\": \"Whole car\", \"children\": [] },\n",
    "                            \"WHEELS\": { \"name\": \"Wheels\", \"children\": [] }\n",
    "                        },\n",
    "                        \"input\": \"radio\"\n",
    "                    }\n",
    "                },\n",
    "                \"RELATION_JOB\": {\n",
    "                    \"mlTask\": \"OBJECT_RELATION\",\n",
    "                    \"instruction\": \"Car relations\",\n",
    "                    \"required\": 0,\n",
    "                    \"isChild\": False,\n",
    "                    \"content\": {\n",
    "                        \"categories\": {\n",
    "                            \"WHOLE_CAR_AND_WHEELS\": {\n",
    "                                \"name\": \"Whole car and wheels\",\n",
    "                                \"children\": [],\n",
    "                                \"startObjects\": [\"WHOLE_CAR\"],\n",
    "                                \"endObjects\": [\"WHEELS\"]\n",
    "                            },\n",
    "                        },\n",
    "                        \"input\": \"radio\"\n",
    "                    },\n",
    "                }\n",
    "            }\n",
    "        },\n",
    "        'assets_to_import': [\n",
    "            \"https://images.caradisiac.com/logos/3/8/6/7/253867/S0-tesla-enregistre-d-importantes-pertes-au-premier-trimestre-175948.jpg\", \n",
    "            \"https://img.sportauto.fr/news/2018/11/28/1533574/1920%7C1280%7Cc096243e5460db3e5e70c773.jpg\",\n",
    "        ],\n",
    "        'json_response': {\n",
    "            \"JOB_0\": {\n",
    "                \"annotations\": [{\n",
    "                    \"boundingPoly\": [{\n",
    "                        \"normalizedVertices\": [\n",
    "                            { \"x\": 0.16, \"y\": 0.82},\n",
    "                            { \"x\": 0.16, \"y\": 0.32 },\n",
    "                            { \"x\": 0.82, \"y\": 0.32 },\n",
    "                            { \"x\": 0.82, \"y\": 0.82 }\n",
    "                        ]}\n",
    "                    ],\n",
    "                    \"mid\": \"car\",\n",
    "                    \"type\": \"rectangle\",\n",
    "                    \"categories\": [{ \"name\": \"WHOLE_CAR\", \"confidence\": 100 }],\n",
    "                },\n",
    "                {\n",
    "                    \"boundingPoly\": [{\n",
    "                        \"normalizedVertices\": [\n",
    "                            { \"x\": 0.54, \"y\": 0.59 },\n",
    "                            { \"x\": 0.43, \"y\": 0.59 },\n",
    "                            { \"x\": 0.43, \"y\": 0.83 },\n",
    "                            { \"x\": 0.54, \"y\": 0.83 }\n",
    "                        ]}\n",
    "                    ],\n",
    "                    \"mid\": \"left-front-wheel\",\n",
    "                    \"type\": \"rectangle\",\n",
    "                    \"categories\": [{ \"name\": \"WHEELS\", \"confidence\": 100 }],\n",
    "                },\n",
    "                {\n",
    "                    \"boundingPoly\": [{\n",
    "                        \"normalizedVertices\": [\n",
    "                            { \"x\": 0.81, \"y\": 0.57},\n",
    "                            { \"x\": 0.74, \"y\": 0.57 },\n",
    "                            { \"x\": 0.74, \"y\": 0.77 },\n",
    "                            { \"x\": 0.81, \"y\": 0.77 }\n",
    "                        ]}\n",
    "                    ],\n",
    "                    \"mid\": \"left-back-wheel\",\n",
    "                    \"type\": \"rectangle\",\n",
    "                    \"categories\": [{ \"name\": \"WHEELS\", \"confidence\": 100 }],\n",
    "                }]\n",
    "            },\n",
    "            'RELATION_JOB': {\n",
    "                'annotations': [\n",
    "                    {\n",
    "                        'categories': [{'name': 'WHOLE_CAR_AND_WHEELS', 'confidence': 100}],\n",
    "                        'startObjects': [{'mid': 'car'}],\n",
    "                        'endObjects': [{'mid': 'left-front-wheel'}, {'mid': 'left-back-wheel'}],\n",
    "                    },\n",
    "                ]\n",
    "            },\n",
    "        },\n",
    "        'model_name': 'car-wheels-localisation-v0.0.1'\n",
    "    }\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "hidden": true
   },
   "source": [
    "#### - Polygon object\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "project_examples.append(\n",
    "    {\n",
    "        'title': 'Car brand recognition - Polygon',\n",
    "        'description': 'Identify and locate cars',\n",
    "        'input_type': 'IMAGE',\n",
    "        'json_interface': {\n",
    "            \"jobs\": {\n",
    "                \"JOB_0\": {\n",
    "                    \"mlTask\": \"OBJECT_DETECTION\",\n",
    "                    \"tools\": [\n",
    "                        \"polygon\"\n",
    "                    ],\n",
    "                    \"instruction\": \"What car brand?\",\n",
    "                    \"required\": 1,\n",
    "                    \"isChild\": False,\n",
    "                    \"content\": {\n",
    "                        \"categories\": {\n",
    "                            \"TESLA\": { \"name\": \"Tesla\", \"children\": [] },\n",
    "                            \"FERRARI\": { \"name\": \"Ferrari\", \"children\": [] }\n",
    "                        },\n",
    "                        \"input\": \"radio\"\n",
    "                    }\n",
    "                }\n",
    "            }\n",
    "        },\n",
    "        'assets_to_import': [\n",
    "            \"https://images.caradisiac.com/logos/3/8/6/7/253867/S0-tesla-enregistre-d-importantes-pertes-au-premier-trimestre-175948.jpg\", \n",
    "            \"https://img.sportauto.fr/news/2018/11/28/1533574/1920%7C1280%7Cc096243e5460db3e5e70c773.jpg\"\n",
    "        ],\n",
    "        'json_response': {\n",
    "            \"JOB_0\": {\n",
    "                \"annotations\": [{\n",
    "                    \"boundingPoly\": [{\n",
    "                        \"normalizedVertices\": [\n",
    "                            { \"x\": 0.16, \"y\": 0.52},\n",
    "                            { \"x\": 0.16, \"y\": 0.76 },\n",
    "                            { \"x\": 0.49, \"y\": 0.83 },\n",
    "                            { \"x\": 0.82, \"y\": 0.76 },\n",
    "                            { \"x\": 0.82, \"y\": 0.49 },\n",
    "                            { \"x\": 0.70, \"y\": 0.32 },\n",
    "                            { \"x\": 0.48, \"y\": 0.32 },\n",
    "                        ]}\n",
    "                    ],\n",
    "                    \"mid\": \"unique-tesla\",\n",
    "                    \"type\": \"polygon\",\n",
    "                    \"categories\": [{ \"name\": \"TESLA\", \"confidence\": 100 }],\n",
    "                }]\n",
    "            }\n",
    "        },\n",
    "        'model_name': 'car-brand-localisation-v0.0.1'\n",
    "    }\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "heading_collapsed": true
   },
   "source": [
    "### c) Named Entities Recognition examples"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "hidden": true
   },
   "source": [
    "#### - Simple text asset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "project_examples.append(\n",
    "    {\n",
    "        'title': 'Grammatical categories',\n",
    "        'description': 'Identify grammatical categories',\n",
    "        'input_type': 'TEXT',\n",
    "        'json_interface': {\n",
    "            \"jobs\": {\n",
    "                \"JOB\": {\n",
    "                    \"mlTask\": \"NAMED_ENTITIES_RECOGNITION\",\n",
    "                    \"instruction\": \"Grammatical categories\",\n",
    "                    \"required\": 1,\n",
    "                    \"isChild\": False,\n",
    "                    \"isVisible\": True,\n",
    "                    \"content\": {\n",
    "                        \"categories\": {\n",
    "                            \"NAME\": { \"name\": \"Name\", \"children\": [] },\n",
    "                            \"NOUN\": { \"name\": \"Noun\", \"children\": [] },\n",
    "                            \"ADJECTIVE\": { \"name\": \"Adjective\", \"children\": [] },\n",
    "                            \"VERB\": { \"name\": \"Verb\", \"children\": [] }\n",
    "                        },\n",
    "                        \"input\": \"radio\"\n",
    "                    }\n",
    "                }\n",
    "            }\n",
    "        },\n",
    "        'assets_to_import': [\n",
    "            \"Chicago Bulls General Manager Jerry Krause was standing near a Gatorade cooler with medicine in hand as players and coaches milled around nearby.\", \n",
    "            \"Jordan, handsome and cool in a Nike sweatsuit, peered down at the hefty Krause, who was wearing a blue sweater tucked into high-rise pants.\"\n",
    "        ],\n",
    "        'json_response': {\n",
    "            \"JOB\": {\n",
    "                \"annotations\": [\n",
    "                    {\"categories\": [{ \"name\": \"NAME\", \"confidence\": 100 }],\n",
    "                    \"beginOffset\": 0,\n",
    "                    \"content\": \"Chicago Bulls\",\n",
    "                    \"mid\": \"chicago\"},\n",
    "                    {\"categories\": [{ \"name\": \"NAME\", \"confidence\": 100 }],\n",
    "                    \"beginOffset\": 30,\n",
    "                    \"content\": \"Jerry Krause\",\n",
    "                    \"mid\": \"krause\"},\n",
    "                    {\"categories\": [{ \"name\": \"NAME\", \"confidence\": 100 }],\n",
    "                    \"beginOffset\": 63,\n",
    "                    \"content\": \"Gatorade\",\n",
    "                    \"mid\": \"gatorade\"},\n",
    "                    {\"categories\": [{ \"name\": \"NOUN\", \"confidence\": 100 }],\n",
    "                    \"beginOffset\": 22,\n",
    "                    \"content\": \"Manager\",\n",
    "                    \"mid\": \"manager\"},\n",
    "                    {\"categories\": [{ \"name\": \"NOUN\", \"confidence\": 100 }],\n",
    "                    \"beginOffset\": 14,\n",
    "                    \"content\": \"General\",\n",
    "                    \"mid\": \"general\"},\n",
    "                    {\"categories\": [{ \"name\": \"NOUN\", \"confidence\": 100 }],\n",
    "                    \"beginOffset\": 84,\n",
    "                    \"content\": \"medicine\",\n",
    "                    \"mid\": \"medicine\"},\n",
    "                    {\"categories\": [{ \"name\": \"NOUN\", \"confidence\": 100 }],\n",
    "                    \"beginOffset\": 104,\n",
    "                    \"content\": \"players\",\n",
    "                    \"mid\": \"players\"},\n",
    "                    {\"categories\": [{ \"name\": \"NOUN\", \"confidence\": 100 }],\n",
    "                    \"beginOffset\": 116,\n",
    "                    \"content\": \"coaches\",\n",
    "                    \"mid\": \"coaches\"},\n",
    "                    {\"categories\": [{ \"name\": \"VERB\", \"confidence\": 100 }],\n",
    "                    \"beginOffset\": 124,\n",
    "                    \"content\": \"milled\",\n",
    "                    \"mid\": \"milled\"},\n",
    "                    {\"categories\": [{ \"name\": \"VERB\", \"confidence\": 100 }],\n",
    "                    \"beginOffset\": 43,\n",
    "                    \"content\": \"was standing\",\n",
    "                    \"mid\": \"standing\"},\n",
    "                    {\"categories\": [{ \"name\": \"NOUN\", \"confidence\": 100 }],\n",
    "                    \"beginOffset\": 96,\n",
    "                    \"content\": \"hand\",\n",
    "                    \"mid\": \"hand\"},\n",
    "                    {\"categories\": [{ \"name\": \"NOUN\", \"confidence\": 100 }],\n",
    "                    \"beginOffset\": 72,\n",
    "                    \"content\": \"cooler\",\n",
    "                    \"mid\": \"cooler\"}\n",
    "                ]\n",
    "            }\n",
    "        },\n",
    "        'model_name': 'ner-model-v0.0.1'\n",
    "    }\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "heading_collapsed": true,
    "hidden": true
   },
   "source": [
    "#### - Rich text asset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "project_examples.append(\n",
    "    {\n",
    "        'title': 'Grammatical categories on law rich texts',\n",
    "        'description': 'Identify grammatical categories',\n",
    "        'input_type': 'TEXT',\n",
    "        'json_interface':  {\n",
    "            \"jobs\": {\n",
    "                \"JOB\": {\n",
    "                    \"mlTask\": \"NAMED_ENTITIES_RECOGNITION\",\n",
    "                    \"instruction\": \"Grammatical categories\",\n",
    "                    \"required\": 1,\n",
    "                    \"isChild\": False,\n",
    "                    \"isVisible\": True,\n",
    "                    \"content\": {\n",
    "                        \"categories\": {\n",
    "                            \"NOMINAL_GROUP\": { \"name\": \"Nominal group\", \"children\": [] },\n",
    "                            \"ADJECTIVE\": {\"name\": \"Adjective\", \"children\": [] },\n",
    "                            \"VERB\": {\"name\": \"Verb\", \"children\": [] }\n",
    "                        },\n",
    "                        \"input\": \"radio\"\n",
    "                    }\n",
    "                }\n",
    "            }\n",
    "        },\n",
    "        'assets_to_import': [[\n",
    "            {\n",
    "                'children': [\n",
    "                    {\n",
    "                        'type': 'p',\n",
    "                        'children': [\n",
    "                            {\n",
    "                                'id': 'PART1',\n",
    "                                'bold': True,\n",
    "                                'underline': True,\n",
    "                                'text': 'The unanimous Declaration',\n",
    "                            },\n",
    "                            {\n",
    "                                'id': 'PART2',\n",
    "                                'bold': True,\n",
    "                                'text': ' of the thirteen United States of America.',\n",
    "                            },\n",
    "                            {\n",
    "                                'id': 'PART3',\n",
    "                                'text':\n",
    "                                \"When in the Course of human events, it becomes necessary for one people to dissolve the political bands which have connected them with another, and to assume among the powers of the earth, the separate and equal station to which the Laws of Nature and of Nature's God entitle them, a decent respect to the opinions of mankind requires that they should declare the causes which impel them to the separation.\",\n",
    "                            }\n",
    "                        ]\n",
    "                    }\n",
    "                ]\n",
    "            }\n",
    "        ]],\n",
    "        'json_response': {\n",
    "            \"JOB\": {\n",
    "                \"annotations\": [\n",
    "                    {\n",
    "                        \"beginId\": 'PART1',\n",
    "                        \"beginOffset\": 14,\n",
    "                        \"categories\": [{ \"name\": \"NOMINAL_GROUP\", \"confidence\": 100 }],\n",
    "                        \"content\": \"Declaration of the thirteen United States of America\",\n",
    "                        \"endId\": 'PART2',\n",
    "                        \"endOffset\": 41,\n",
    "                        \"mid\": \"declaration\",\n",
    "                    },\n",
    "                ]\n",
    "            }\n",
    "        },\n",
    "        'model_name': 'ner-model-v0.0.2'\n",
    "    }\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "heading_collapsed": true,
    "hidden": true
   },
   "source": [
    "#### - Text asset with named-entities relations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "project_examples.append(\n",
    "    {\n",
    "        'title': 'Named entities relations',\n",
    "        'description': 'Subject verb complement',\n",
    "        'input_type': 'TEXT',\n",
    "        'json_interface': {\n",
    "            \"jobs\": {\n",
    "                \"NAMED_ENTITIES_RECOGNITION_JOB\": {\n",
    "                    \"mlTask\": \"NAMED_ENTITIES_RECOGNITION\",\n",
    "                    \"instruction\": \"Grammatical categories\",\n",
    "                    \"required\": 1,\n",
    "                    \"isChild\": False,\n",
    "                    \"isVisible\": True,\n",
    "                    \"content\": {\n",
    "                        \"categories\": {\n",
    "                            \"SUBJECT\": { \"name\": \"Subject\", \"children\": [] },\n",
    "                            \"VERB\": { \"name\": \"Verb\", \"children\": [] },\n",
    "                            \"COMPLEMENT\": { \"name\": \"Complement\", \"children\": [] }\n",
    "                        },\n",
    "                        \"input\": \"radio\"\n",
    "                    },\n",
    "                },\n",
    "                \"NAMED_ENTITIES_RELATION_JOB\": {\n",
    "                    \"mlTask\": \"NAMED_ENTITIES_RELATION\",\n",
    "                    \"instruction\": \"Grammatical relations\",\n",
    "                    \"required\": 0,\n",
    "                    \"isChild\": False,\n",
    "                    \"content\": {\n",
    "                        \"categories\": {\n",
    "                            \"VERB_AND_SUBJECT_S\": {\n",
    "                                \"name\": \"Verb and subject(s)\",\n",
    "                                \"children\": [],\n",
    "                                \"startEntities\": [\"VERB\"],\n",
    "                                \"endEntities\": [\"SUBJECT\"]\n",
    "                            },\n",
    "                            \"VERB_AND_COMPLEMENT_S\": {\n",
    "                                \"name\": \"Verb and complement(s)\",\n",
    "                                \"children\": [],\n",
    "                                \"startEntities\": [\"VERB\"],\n",
    "                                \"endEntities\": [\"COMPLEMENT\"]\n",
    "                            }\n",
    "                        },\n",
    "                        \"input\": \"radio\"\n",
    "                    },\n",
    "                }\n",
    "            }\n",
    "        },\n",
    "        'assets_to_import': [\n",
    "            \"Jordan, handsome and cool in a Nike sweatsuit, peered down at the hefty Krause, who was wearing a blue sweater tucked into high-rise pants.\",\n",
    "            \"Chicago Bulls General Manager Jerry Krause was standing near a Gatorade cooler with medicine in hand as players and coaches milled around nearby.\"\n",
    "        ],\n",
    "        'json_response': {\n",
    "            \"NAMED_ENTITIES_RECOGNITION_JOB\": {\n",
    "                \"annotations\": [\n",
    "                    {\"categories\": [{ \"name\": \"SUBJECT\", \"confidence\": 100 }],\n",
    "                    \"beginOffset\": 0,\n",
    "                    \"content\": \"Jordan\",\n",
    "                    \"mid\": \"Jordan\"},\n",
    "                    {\"categories\": [{ \"name\": \"VERB\", \"confidence\": 100 }],\n",
    "                    \"beginOffset\": 84,\n",
    "                    \"content\": \"was wearing\",\n",
    "                    \"mid\": \"wearing\"},\n",
    "                    {\"categories\": [{ \"name\": \"VERB\", \"confidence\": 100 }],\n",
    "                    \"beginOffset\": 111,\n",
    "                    \"content\": \"tucked\",\n",
    "                    \"mid\": \"tucked verb\"},\n",
    "                    {\"categories\": [{ \"name\": \"COMPLEMENT\", \"confidence\": 100 }],\n",
    "                    \"beginOffset\": 96,\n",
    "                    \"content\": \"a blue sweater tucked into high-rise pants\",\n",
    "                    \"mid\": \"blue sweater complement\"},\n",
    "                    {\"categories\": [{ \"name\": \"VERB\", \"confidence\": 100 }],\n",
    "                    \"beginOffset\": 47,\n",
    "                    \"content\": \"peered down\",\n",
    "                    \"mid\": \"peered\"},\n",
    "                    {\"categories\": [{ \"name\": \"COMPLEMENT\", \"confidence\": 100 }],\n",
    "                    \"beginOffset\": 62,\n",
    "                    \"content\": \"the hefty Krause\",\n",
    "                    \"mid\": \"Krause complement\"},\n",
    "                    {\"categories\": [{ \"name\": \"SUBJECT\", \"confidence\": 100 }],\n",
    "                    \"beginOffset\": 62,\n",
    "                    \"content\": \"the hefty Krause\",\n",
    "                    \"mid\": \"Krause subject\"}\n",
    "                ]\n",
    "            },\n",
    "            \"NAMED_ENTITIES_RELATION_JOB\": {\n",
    "                \"annotations\": [\n",
    "                    {\"categories\": [{ \"name\": \"VERB_AND_SUBJECT_S\", \"confidence\": 100 }],\n",
    "                    \"startEntities\": [{ \"mid\": \"peered\" }],\n",
    "                    \"endEntities\": [{ \"mid\": \"Jordan\" }]},\n",
    "                    {\"categories\": [{ \"name\": \"VERB_AND_COMPLEMENT_S\", \"confidence\": 100 }],\n",
    "                    \"startEntities\": [{ \"mid\": \"peered\" }],\n",
    "                    \"endEntities\": [{ \"mid\": \"Krause complement\" }]},\n",
    "                    {\"categories\": [{ \"name\": \"VERB_AND_SUBJECT_S\", \"confidence\": 100 }],\n",
    "                    \"startEntities\": [{ \"mid\": \"wearing\" }],\n",
    "                    \"endEntities\": [{ \"mid\": \"Krause subject\" }]},\n",
    "                    {\"categories\": [{ \"name\": \"VERB_AND_COMPLEMENT_S\", \"confidence\": 100 }],\n",
    "                    \"startEntities\": [{ \"mid\": \"wearing\" }],\n",
    "                    \"endEntities\": [{ \"mid\": \"blue sweater complement\" }]}\n",
    "                ]\n",
    "            }\n",
    "        },\n",
    "        'model_name': 'relation-model-v0.0.1'\n",
    "    }\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### d) Optical Character Recognition examples"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### - OCR (object detection + nested transcription)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "project_examples.append(\n",
    "    {\n",
    "        'title': 'OCR - ID cards',\n",
    "        'description': 'Identify name and nationality',\n",
    "        'input_type': 'IMAGE',\n",
    "        'json_interface' : {\n",
    "            \"jobs\": {\n",
    "                \"JOB_0\": {\n",
    "                    \"mlTask\": \"OBJECT_DETECTION\",\n",
    "                    \"tools\": [\n",
    "                        \"rectangle\"\n",
    "                    ],\n",
    "                    \"instruction\": \"Categories\",\n",
    "                    \"required\": 1,\n",
    "                    \"isChild\": False,\n",
    "                    \"content\": {\n",
    "                        \"categories\": {\n",
    "                            \"NATIONALITY\": {\n",
    "                                \"name\": \"Nationality\",\n",
    "                                \"children\": [\n",
    "                                    \"JOB_1\"\n",
    "                                ],\n",
    "                            },\n",
    "                            \"NAME\": {\n",
    "                                \"name\": \"Name\",\n",
    "                                \"children\": [\n",
    "                                    \"JOB_2\"\n",
    "                                ],\n",
    "                            }\n",
    "                        },\n",
    "                        \"input\": \"radio\"\n",
    "                    }\n",
    "                },\n",
    "                \"JOB_1\": {\n",
    "                    \"mlTask\": \"TRANSCRIPTION\",\n",
    "                    \"instruction\": \"Transcription of Nationality\",\n",
    "                    \"required\": 1,\n",
    "                    \"isChild\": True,\n",
    "                    \"content\": {\n",
    "                        \"input\": \"radio\"\n",
    "                    }\n",
    "                },\n",
    "                \"JOB_2\": {\n",
    "                    \"mlTask\": \"TRANSCRIPTION\",\n",
    "                    \"instruction\": \"Transcription of Name\",\n",
    "                    \"required\": 1,\n",
    "                    \"isChild\": True,\n",
    "                    \"content\": {\n",
    "                        \"input\": \"radio\"\n",
    "                    }\n",
    "                }\n",
    "            }\n",
    "        },\n",
    "        'assets_to_import' : [\n",
    "            \"https://upload.wikimedia.org/wikipedia/commons/3/3a/Dutch_identity_card_front_specimen_issued_9_March_2014.jpg\",\n",
    "        ],\n",
    "        'json_response': {\n",
    "            'JOB_0': {\n",
    "                'annotations': [{\n",
    "                    'boundingPoly': [{\n",
    "                        'normalizedVertices': [\n",
    "                            {'x': 0.47, 'y': 0.53},\n",
    "                            {'x': 0.47, 'y': 0.48},\n",
    "                            {'x': 0.65, 'y': 0.48},\n",
    "                            {'x': 0.65, 'y': 0.53}\n",
    "                        ]\n",
    "                    }],\n",
    "                    'categories': [{'name': 'NATIONALITY', 'confidence': 100}],\n",
    "                    'mid': 'nationality',\n",
    "                    'type': 'rectangle',\n",
    "                    'children': {'JOB_1': {'text': 'Nederlandse'}}\n",
    "                },\n",
    "                {\n",
    "                    'boundingPoly': [{\n",
    "                        'normalizedVertices': [\n",
    "                            {'x': 0.36, 'y': 0.37},\n",
    "                            {'x': 0.36, 'y': 0.32},\n",
    "                            {'x': 0.51, 'y': 0.32},\n",
    "                            {'x': 0.51, 'y': 0.37}\n",
    "                        ]\n",
    "                    }],\n",
    "                    'categories': [{'name': 'NAME', 'confidence': 100}],\n",
    "                    'mid': 'name',\n",
    "                    'type': 'rectangle',\n",
    "                    'children': {'JOB_2': {'text': 'De Bruijn'}}\n",
    "                }]\n",
    "            }\n",
    "        },\n",
    "        'model_name' : 'transcription-model-v0.0.1'\n",
    "    }\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### - OCR with relations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "project_examples.append(\n",
    "    {\n",
    "        'title': 'OCR - ID cards with relations',\n",
    "        'description': 'Identify name, nationality and birth date and add relations',\n",
    "        'input_type': 'IMAGE',\n",
    "        'json_interface': {\n",
    "            \"jobs\": {\n",
    "                \"JOB_0\": {\n",
    "                    \"mlTask\": \"OBJECT_DETECTION\",\n",
    "                    \"tools\": [\n",
    "                        \"rectangle\"\n",
    "                    ],\n",
    "                    \"instruction\": \"Categories\",\n",
    "                    \"required\": 1,\n",
    "                    \"isChild\": False,\n",
    "                    \"content\": {\n",
    "                        \"categories\": {\n",
    "                            \"NATIONALITY\": {\n",
    "                                \"name\": \"Nationality\",\n",
    "                                \"children\": [\n",
    "                                    \"TRANSCRIPTION_JOB_1\"\n",
    "                                ],\n",
    "                            },\n",
    "                            \"NAME\": {\n",
    "                                \"name\": \"Name\",\n",
    "                                \"children\": [\n",
    "                                    \"TRANSCRIPTION_JOB_2\"\n",
    "                                ],\n",
    "                            },\n",
    "                            \"BIRTH_DATE\": {\n",
    "                                \"name\": \"Birth date\",\n",
    "                                \"children\": [\n",
    "                                    \"TRANSCRIPTION_JOB_3\"\n",
    "                                ],\n",
    "                            }\n",
    "                        },\n",
    "                        \"input\": \"radio\"\n",
    "                    }\n",
    "                },\n",
    "                \"TRANSCRIPTION_JOB_1\": {\n",
    "                    \"mlTask\": \"TRANSCRIPTION\",\n",
    "                    \"instruction\": \"Transcription of Nationality\",\n",
    "                    \"required\": 1,\n",
    "                    \"isChild\": True,\n",
    "                    \"content\": {\n",
    "                        \"input\": \"radio\"\n",
    "                    }\n",
    "                },\n",
    "                \"TRANSCRIPTION_JOB_2\": {\n",
    "                    \"mlTask\": \"TRANSCRIPTION\",\n",
    "                    \"instruction\": \"Transcription of Name\",\n",
    "                    \"required\": 1,\n",
    "                    \"isChild\": True,\n",
    "                    \"content\": {\n",
    "                        \"input\": \"radio\"\n",
    "                    }\n",
    "                },\n",
    "                \"TRANSCRIPTION_JOB_3\": {\n",
    "                    \"mlTask\": \"TRANSCRIPTION\",\n",
    "                    \"instruction\": \"Transcription of Birth date\",\n",
    "                    \"required\": 1,\n",
    "                    \"isChild\": True,\n",
    "                    \"content\": {\n",
    "                        \"input\": \"radio\"\n",
    "                    }\n",
    "                },\n",
    "                \"OCR_RELATION_JOB\": {\n",
    "                    \"mlTask\": \"OBJECT_RELATION\",\n",
    "                    \"content\": {\n",
    "                        \"categories\": {\n",
    "                            \"NAME_AND_NATIONALITY\": {\n",
    "                                \"name\": \"Name and nationality\",\n",
    "                                \"startObjects\": [\"NAME\"],\n",
    "                                \"endObjects\": [\"NATIONALITY\"]\n",
    "                            },\n",
    "                            \"NAME_AND_BIRTH_DATE\": {\n",
    "                                \"name\": \"Name and birth date\",\n",
    "                                \"startObjects\": [\"NAME\"],\n",
    "                                \"endObjects\": [\"BIRTH_DATE\"]\n",
    "                            }\n",
    "                        },\n",
    "                        \"input\": \"radio\"\n",
    "                    },\n",
    "                    \"required\": 0,\n",
    "                    \"isChild\": False,\n",
    "                    \"instruction\": \"Relations\"\n",
    "                },\n",
    "            },\n",
    "        },\n",
    "        'assets_to_import': [\n",
    "            \"https://upload.wikimedia.org/wikipedia/commons/3/3a/Dutch_identity_card_front_specimen_issued_9_March_2014.jpg\",\n",
    "        ],\n",
    "        'json_response': {\n",
    "            'JOB_0': {\n",
    "                'annotations': [{\n",
    "                    'boundingPoly': [{\n",
    "                        'normalizedVertices': [\n",
    "                            {'x': 0.47, 'y': 0.53},\n",
    "                            {'x': 0.47, 'y': 0.48},\n",
    "                            {'x': 0.65, 'y': 0.48},\n",
    "                            {'x': 0.65, 'y': 0.53}\n",
    "                        ]\n",
    "                    }],\n",
    "                    'categories': [{'name': 'NATIONALITY', 'confidence': 100}],\n",
    "                    'type': 'rectangle',\n",
    "                    'mid': 'netherlands',\n",
    "                    'children': {'TRANSCRIPTION_JOB_1': {'text': 'Nederlandse'}}\n",
    "                },\n",
    "                {\n",
    "                    'boundingPoly': [{\n",
    "                        'normalizedVertices': [\n",
    "                            {'x': 0.36, 'y': 0.37},\n",
    "                            {'x': 0.36, 'y': 0.32},\n",
    "                            {'x': 0.51, 'y': 0.32},\n",
    "                            {'x': 0.51, 'y': 0.37}\n",
    "                        ]\n",
    "                    }],\n",
    "                    'categories': [{'name': 'NAME', 'confidence': 100}],\n",
    "                    'type': 'rectangle',\n",
    "                    'mid': 'bruijn',\n",
    "                    'children': {'TRANSCRIPTION_JOB_2': {'text': 'De Bruijn'}}\n",
    "                },\n",
    "                {\n",
    "                    'boundingPoly': [{\n",
    "                        'normalizedVertices': [\n",
    "                            {'x': 0.36, 'y': 0.61},\n",
    "                            {'x': 0.36, 'y': 0.56},\n",
    "                            {'x': 0.63, 'y': 0.56},\n",
    "                            {'x': 0.63, 'y': 0.61}\n",
    "                        ]\n",
    "                    }],\n",
    "                    'categories': [{'name': 'BIRTH_DATE', 'confidence': 100}],\n",
    "                    'type': 'rectangle',\n",
    "                    'mid': 'date',\n",
    "                    'children': {'TRANSCRIPTION_JOB_3': {'text': '10 MAA/MAR 1965'}}\n",
    "                }]\n",
    "            },\n",
    "            \"OCR_RELATION_JOB\": {\n",
    "                \"annotations\": [\n",
    "                    {\"categories\": [{ \"name\": \"NAME_AND_NATIONALITY\", \"confidence\": 100 }],\n",
    "                    \"startObjects\": [{ \"mid\": \"bruijn\" }],\n",
    "                    \"endObjects\": [{ \"mid\": \"netherlands\" }]},\n",
    "                    {\"categories\": [{ \"name\": \"NAME_AND_BIRTH_DATE\", \"confidence\": 100 }],\n",
    "                    \"startObjects\": [{ \"mid\": \"bruijn\" }],\n",
    "                    \"endObjects\": [{ \"mid\": \"date\" }]}\n",
    "                ]\n",
    "            }\n",
    "        },\n",
    "        'model_name': 'transcription-model-v0.0.1'\n",
    "    }\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### e) Speech-to-text example"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "project_examples.append(\n",
    "    {\n",
    "        'title' : 'Kate Darling - TedX',\n",
    "        'description' : 'Write down the speakers speeches',\n",
    "        'input_type' : 'AUDIO',\n",
    "        'json_interface' : {\n",
    "            \"jobs\": {\n",
    "                'SPEECH_TO_TEXT_JOB': {\n",
    "                    \"mlTask\": \"SPEECH_TO_TEXT\",\n",
    "                    \"instruction\": \"\",\n",
    "                    \"required\": False,\n",
    "                    \"isChild\": False,\n",
    "                    \"isVisible\": True,\n",
    "                    \"content\": {\n",
    "                        \"categories\": {\n",
    "                            \"MUSIC\": {\n",
    "                                \"name\": \"\",\n",
    "                                \"children\": []\n",
    "                            },\n",
    "                            \"INAUDIBLE\": {\n",
    "                                \"name\": \"[INAUDIBLE]\",\n",
    "                                \"children\": []\n",
    "                            }\n",
    "                        },\n",
    "                        \"input\": \"radio\"\n",
    "                    },\n",
    "                },\n",
    "                'diarization-job': {\n",
    "                    \"mlTask\": \"CLASSIFICATION\",\n",
    "                    \"instruction\": \"\",\n",
    "                    \"required\": False,\n",
    "                    \"isChild\": False,\n",
    "                    \"isVisible\": True,\n",
    "                    \"content\": {\n",
    "                        \"categories\": {\n",
    "                            \"SPEAKER 1\": {\n",
    "                                \"name\": \"SPEAKER 1\",\n",
    "                                \"children\": []\n",
    "                            },\n",
    "                            \"SPEAKER 2\": {\n",
    "                                \"name\": \"SPEAKER 2\",\n",
    "                                \"children\": []\n",
    "                            }\n",
    "                        },\n",
    "                        \"input\": \"radio\"\n",
    "                    },\n",
    "                  },\n",
    "            }\n",
    "        },\n",
    "        'assets_to_import' : [\n",
    "             'https://download.ted.com/talks/KateDarling_2018S-950k.mp4',\n",
    "        ],\n",
    "        'json_response' : {\n",
    "            \"SPEECH_TO_TEXT_JOB\": {\n",
    "                \"annotations\": [\n",
    "                    {\n",
    "                        \"beginOffset\": 13.02,\n",
    "                        \"categories\": [\n",
    "                            {\n",
    "                                \"name\": \"SPEAKER 1\",\n",
    "                                \"confidence\": 100\n",
    "                            }\n",
    "                        ],\n",
    "                        \"children\": {\n",
    "                            \"speech_to_text_job\": {\n",
    "                                \"annotations\": [\n",
    "                                  {\n",
    "                                    \"beginOffset\": 13.02,\n",
    "                                    \"content\": \"There\",\n",
    "                                    \"mid\": \"2020102114124590-18412-0\"\n",
    "                                  },\n",
    "                                  {\n",
    "                                    \"beginOffset\": 13.419285714285714,\n",
    "                                    \"content\": \"is\",\n",
    "                                    \"mid\": \"2020102114124590-18412-1\"\n",
    "                                  },\n",
    "                                  {\n",
    "                                    \"beginOffset\": 13.818571428571428,\n",
    "                                    \"content\": \"a\",\n",
    "                                    \"mid\": \"2020102114124590-18412-2\"\n",
    "                                  },\n",
    "                                  {\n",
    "                                    \"beginOffset\": 14.217857142857142,\n",
    "                                    \"content\": \"day.\",\n",
    "                                    \"mid\": \"2020102114124590-18412-3\"\n",
    "                                  },\n",
    "                                  {\n",
    "                                    \"beginOffset\": 14.617142857142857,\n",
    "                                    \"content\": \"About\",\n",
    "                                    \"mid\": \"2020102114124590-18412-4\"\n",
    "                                  },\n",
    "                                  {\n",
    "                                    \"beginOffset\": 15.016428571428571,\n",
    "                                    \"content\": \"ten\",\n",
    "                                    \"mid\": \"2020102114124590-18412-5\"\n",
    "                                  },\n",
    "                                  {\n",
    "                                    \"beginOffset\": 15.415714285714285,\n",
    "                                    \"content\": \"years\",\n",
    "                                    \"mid\": \"2020102114124590-18412-6\"\n",
    "                                  },\n",
    "                                  {\n",
    "                                    \"beginOffset\": 15.815,\n",
    "                                    \"content\": \"ago\",\n",
    "                                    \"mid\": \"2020102114124590-18412-7\"\n",
    "                                  },\n",
    "                                  {\n",
    "                                    \"beginOffset\": 16.214285714285715,\n",
    "                                    \"content\": \"when\",\n",
    "                                    \"mid\": \"2020102114124590-18412-8\"\n",
    "                                  },\n",
    "                                  {\n",
    "                                    \"beginOffset\": 16.61357142857143,\n",
    "                                    \"content\": \"I\",\n",
    "                                    \"mid\": \"2020102114124590-18412-9\"\n",
    "                                  },\n",
    "                                  {\n",
    "                                    \"beginOffset\": 17.012857142857143,\n",
    "                                    \"content\": \"asked\",\n",
    "                                    \"mid\": \"2020102114124590-18412-10\"\n",
    "                                  },\n",
    "                                  {\n",
    "                                    \"beginOffset\": 17.412142857142857,\n",
    "                                    \"content\": \"a\",\n",
    "                                    \"mid\": \"2020102114124590-18412-11\"\n",
    "                                  },\n",
    "                                  {\n",
    "                                    \"beginOffset\": 17.81142857142857,\n",
    "                                    \"content\": \"friend\",\n",
    "                                    \"mid\": \"2020102114124590-18412-12\"\n",
    "                                  },\n",
    "                                  {\n",
    "                                    \"beginOffset\": 18.210714285714285,\n",
    "                                    \"content\": \"to\",\n",
    "                                    \"mid\": \"2020102114124590-18412-13\"\n",
    "                                  },\n",
    "                                  {\n",
    "                                    \"beginOffset\": 18.61,\n",
    "                                    \"content\": \"hold\",\n",
    "                                    \"mid\": \"2020102114124590-18412-14\"\n",
    "                                  },\n",
    "                                  {\n",
    "                                    \"beginOffset\": 19.009285714285713,\n",
    "                                    \"content\": \"a\",\n",
    "                                    \"mid\": \"2020102114124590-18412-15\"\n",
    "                                  },\n",
    "                                  {\n",
    "                                    \"beginOffset\": 19.408571428571427,\n",
    "                                    \"content\": \"baby\",\n",
    "                                    \"mid\": \"2020102114124590-18412-16\"\n",
    "                                  },\n",
    "                                  {\n",
    "                                    \"beginOffset\": 19.80785714285714,\n",
    "                                    \"content\": \"dinosaur\",\n",
    "                                    \"mid\": \"2020102114124590-18412-17\"\n",
    "                                  },\n",
    "                                  {\n",
    "                                    \"beginOffset\": 20.207142857142856,\n",
    "                                    \"content\": \"robot\",\n",
    "                                    \"mid\": \"2020102114124590-18412-18\"\n",
    "                                  },\n",
    "                                  {\n",
    "                                    \"beginOffset\": 20.60642857142857,\n",
    "                                    \"content\": \"upside\",\n",
    "                                    \"mid\": \"2020102114124590-18412-19\"\n",
    "                                  },\n",
    "                                  {\n",
    "                                    \"beginOffset\": 21.005714285714284,\n",
    "                                    \"content\": \"down.\",\n",
    "                                    \"mid\": \"2020102114124590-18412-20\"\n",
    "                                  },\n",
    "                                ]\n",
    "                            }\n",
    "                        },\n",
    "                        \"content\": \"There is a day. About ten years ago when I asked a friend to hold a baby dinosaur robot upside down.\",\n",
    "                        \"mid\": \"2020102114124590-18412\"\n",
    "                    },\n",
    "                    \n",
    "                ]\n",
    "            },\n",
    "        },\n",
    "        'model_name' : 'tedx-speech-v0.0.1'\n",
    "    }\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### f) PDF predictions"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "On PDF assets, you can use the same tasks as on text assets, which are:\n",
    "- Classification (single-class, multi-class and nested),\n",
    "- Named Entities Recognition,\n",
    "- Transcription,\n",
    "- Named entities relations.\n",
    "\n",
    "All of these tasks have been introduced in previous steps.\n",
    "\n",
    "However, you should notice that the form of the annotation for NER is different. Indeed, whereas an offset is used in texts, here the annotations work with the coordinates of the polygon the data belongs to and the page number."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "project_examples.append(\n",
    "    {\n",
    "        'title': 'Article titles and writers',\n",
    "        'description': 'Identify the title and the writer of the article',\n",
    "        'input_type': 'PDF',\n",
    "        'json_interface' : {\n",
    "            \"jobs\": {\n",
    "                'NAMED_ENTITIES_RECOGNITION_JOB': {\n",
    "                    \"mlTask\": \"NAMED_ENTITIES_RECOGNITION\",\n",
    "                    \"instruction\": \"Identify the ...\",\n",
    "                    \"required\": 1,\n",
    "                    \"isChild\": False,\n",
    "                    \"content\": {\n",
    "                        \"categories\": {\n",
    "                            \"TITLE\": {\n",
    "                                \"name\": \"Title\",\n",
    "                                \"children\": [],\n",
    "                            },\n",
    "                            \"WRITERS\": {\n",
    "                                \"name\": \"Writers\",\n",
    "                                \"children\": [],\n",
    "                            }\n",
    "                        },\n",
    "                        \"input\": \"radio\"\n",
    "                    },\n",
    "\n",
    "                },\n",
    "            }\n",
    "        },\n",
    "        'assets_to_import': [\n",
    "             'https://arxiv.org/pdf/1703.03365.pdf',\n",
    "        ],\n",
    "        'json_response': {\n",
    "            'NAMED_ENTITIES_RECOGNITION_JOB': {\n",
    "                'annotations': [{\n",
    "                    'annotations': [{\n",
    "                        'boundingPoly': [{\n",
    "                            'normalizedVertices': [[\n",
    "                                {'x': 0.28, 'y': 0.12},\n",
    "                                {'x': 0.28, 'y': 0.15},\n",
    "                                {'x': 0.72, 'y': 0.12},\n",
    "                                {'x': 0.72, 'y': 0.15}\n",
    "                            ]]\n",
    "                        }],\n",
    "                        'polys': [{\n",
    "                            'normalizedVertices': [[\n",
    "                                {'x': 0.28, 'y': 0.12},\n",
    "                                {'x': 0.28, 'y': 0.15},\n",
    "                                {'x': 0.72, 'y': 0.12},\n",
    "                                {'x': 0.72, 'y': 0.15}\n",
    "                            ]]\n",
    "                        }],\n",
    "                        'pageNumber': 1\n",
    "                    }],\n",
    "                    'categories': [{'name': 'TITLE', 'confidence': 100}],\n",
    "                    'content': 'Learning Active Learning from Data',\n",
    "                    'mid': 'article-title'\n",
    "                }],\n",
    "            }\n",
    "        },\n",
    "        'model_name': 'title-identify-v0.0.1'\n",
    "    }\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### g) Video frame projects"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Frame projects are very similar to image ones as, in a frame project, each image is annotated independently.\n",
    "\n",
    "As a result, the `jsonResponse` takes the shape of a dictionnary where each frame's annotations are linked to the index of this frame in the asset.\n",
    "Here is an example with a 5 images Frame asset:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Frames classification"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "project_examples.append(\n",
    "    {\n",
    "        'title' : 'Car classification video',\n",
    "        'description' : 'Indicate if there is a vehicle close to the camera',\n",
    "        'input_type' : 'FRAME',\n",
    "        'json_interface' : {\n",
    "            \"jobs\": {\n",
    "                \"FRAME_CLASSIFICATION_JOB\": {\n",
    "                    \"mlTask\": \"CLASSIFICATION\",\n",
    "                    \"instruction\": \"Is there at least one vehicle close to me?\",\n",
    "                    \"required\": 1,\n",
    "                    \"isChild\": False,\n",
    "                    \"isVisible\": True,\n",
    "                    \"content\": {\n",
    "                        \"categories\": {\n",
    "                            \"YES_THERE_IS\": { \"name\": \"Yes, there is\", \"children\": [] },\n",
    "                            \"NO\": { \"name\": \"No\", \"children\": [] }\n",
    "                        },\n",
    "                        \"input\": \"radio\"\n",
    "                    }\n",
    "                }\n",
    "            }\n",
    "        },\n",
    "        'assets_to_import' : [\n",
    "             ['https://storage.googleapis.com/label-public-staging/video1/video1-img000001.jpg',\n",
    "              'https://storage.googleapis.com/label-public-staging/video1/video1-img000002.jpg',\n",
    "              'https://storage.googleapis.com/label-public-staging/video1/video1-img000003.jpg',\n",
    "              'https://storage.googleapis.com/label-public-staging/video1/video1-img000004.jpg',\n",
    "              'https://storage.googleapis.com/label-public-staging/video1/video1-img000005.jpg']\n",
    "        ],\n",
    "        'json_response' : {\n",
    "            \"0\": {\n",
    "                \"FRAME_CLASSIFICATION_JOB\": {\n",
    "                    'categories': [{'name': 'YES_THERE_IS', 'confidence': 100}],\n",
    "                    'isKeyFrame': True\n",
    "                }\n",
    "            },\n",
    "            \"1\": {\n",
    "                \"FRAME_CLASSIFICATION_JOB\": {\n",
    "                    'categories': [{'name': 'YES_THERE_IS', 'confidence': 100}],\n",
    "                    'isKeyFrame': False\n",
    "                }\n",
    "            },\n",
    "            \"2\": {\n",
    "                \"FRAME_CLASSIFICATION_JOB\": {\n",
    "                    'categories': [{'name': 'YES_THERE_IS', 'confidence': 100}],\n",
    "                    'isKeyFrame': False\n",
    "                }\n",
    "            },\n",
    "            \"3\": {\n",
    "                \"FRAME_CLASSIFICATION_JOB\": {\n",
    "                    'categories': [{'name': 'NO', 'confidence': 100}],\n",
    "                    'isKeyFrame': True\n",
    "                }\n",
    "            },\n",
    "            \"4\": {\n",
    "                \"FRAME_CLASSIFICATION_JOB\": {\n",
    "                    'categories': [{'name': 'NO', 'confidence': 100}],\n",
    "                    'isKeyFrame': False\n",
    "                }\n",
    "            }\n",
    "        },\n",
    "        'model_name' : 'close-vehicle-identification-v0.0.1'\n",
    "    }\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Object detection (bounding boxes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "project_examples.append(\n",
    "    {\n",
    "        'title' : 'Car tracking',\n",
    "        'description' : 'Identify cars',\n",
    "        'input_type' : 'FRAME',\n",
    "        'json_interface' : {\n",
    "            \"jobs\": {\n",
    "                \"JOB\": {\n",
    "                    \"mlTask\": \"OBJECT_DETECTION\",\n",
    "                    \"tools\": [\n",
    "                        \"rectangle\"\n",
    "                    ],\n",
    "                    \"required\": 1,\n",
    "                    \"isChild\": False,\n",
    "                    \"content\": {\n",
    "                        \"categories\": {\n",
    "                            \"TESLA\": {\n",
    "                                \"name\": \"Tesla\",\n",
    "                                \"children\": []\n",
    "                            },\n",
    "                            \"FERRARI\": {\n",
    "                                \"name\": \"Ferrari\",\n",
    "                                \"children\": []\n",
    "                            }\n",
    "                        },\n",
    "                        \"input\": \"radio\"\n",
    "                    }\n",
    "                }\n",
    "            }\n",
    "        },\n",
    "        'assets_to_import' : [\n",
    "             ['https://storage.googleapis.com/label-public-staging/video1/video1-img000001.jpg',\n",
    "              'https://storage.googleapis.com/label-public-staging/video1/video1-img000002.jpg',\n",
    "              'https://storage.googleapis.com/label-public-staging/video1/video1-img000003.jpg',\n",
    "              'https://storage.googleapis.com/label-public-staging/video1/video1-img000004.jpg',\n",
    "              'https://storage.googleapis.com/label-public-staging/video1/video1-img000005.jpg']\n",
    "        ],\n",
    "        'json_response' : {\n",
    "          \"0\": {\n",
    "            \"JOB\": {\n",
    "              \"annotations\": [\n",
    "                {\n",
    "                  \"boundingPoly\": [\n",
    "                    {\n",
    "                      \"normalizedVertices\": [\n",
    "                        { \"x\": 0.57, \"y\": 0.59 },\n",
    "                        { \"x\": 0.57, \"y\": 0.73 },\n",
    "                        { \"x\": 0.68, \"y\": 0.73 },\n",
    "                        { \"x\": 0.68, \"y\": 0.59 }\n",
    "                      ]\n",
    "                    }\n",
    "                  ],\n",
    "                  \"categories\": [{ \"name\": \"TESLA\", \"confidence\": 100 }],\n",
    "                  \"mid\": \"frame1-tesla\",\n",
    "                  \"type\": \"rectangle\",\n",
    "                  \"isKeyFrame\": True\n",
    "                }\n",
    "              ]\n",
    "            }\n",
    "          },\n",
    "          \"1\": {\n",
    "            \"JOB\": {\n",
    "              \"annotations\": [\n",
    "                {\n",
    "                  \"boundingPoly\": [\n",
    "                    {\n",
    "                      \"normalizedVertices\": [\n",
    "                        { \"x\": 0.56, \"y\": 0.58 },\n",
    "                        { \"x\": 0.56, \"y\": 0.74 },\n",
    "                        { \"x\": 0.68, \"y\": 0.74 },\n",
    "                        { \"x\": 0.68, \"y\": 0.58 }\n",
    "                      ]\n",
    "                    }\n",
    "                  ],\n",
    "                  \"categories\": [{ \"name\": \"TESLA\", \"confidence\": 100 }],\n",
    "                  \"mid\": \"frame2-tesla\",\n",
    "                  \"type\": \"rectangle\",\n",
    "                  \"isKeyFrame\": False\n",
    "                }\n",
    "              ]\n",
    "            }\n",
    "          },\n",
    "          \"2\": {\n",
    "            \"JOB\": {\n",
    "              \"annotations\": [\n",
    "                {\n",
    "                  \"boundingPoly\": [\n",
    "                    {\n",
    "                      \"normalizedVertices\": [\n",
    "                        { \"x\": 0.55, \"y\": 0.58 },\n",
    "                        { \"x\": 0.55, \"y\": 0.73 },\n",
    "                        { \"x\": 0.67, \"y\": 0.73 },\n",
    "                        { \"x\": 0.67, \"y\": 0.58 }\n",
    "                      ]\n",
    "                    }\n",
    "                  ],\n",
    "                  \"categories\": [{ \"name\": \"TESLA\", \"confidence\": 100 }],\n",
    "                  \"mid\": \"frame3-tesla\",\n",
    "                  \"type\": \"rectangle\",\n",
    "                  \"isKeyFrame\": False\n",
    "                }\n",
    "              ]\n",
    "            }\n",
    "          },\n",
    "          \"3\": {\n",
    "            \"JOB\": {\n",
    "              \"annotations\": [\n",
    "                {\n",
    "                  \"boundingPoly\": [\n",
    "                    {\n",
    "                      \"normalizedVertices\": [\n",
    "                        { \"x\": 0.55, \"y\": 0.58 },\n",
    "                        { \"x\": 0.55, \"y\": 0.72 },\n",
    "                        { \"x\": 0.67, \"y\": 0.72 },\n",
    "                        { \"x\": 0.67, \"y\": 0.58 }\n",
    "                      ]\n",
    "                    }\n",
    "                  ],\n",
    "                  \"categories\": [{ \"name\": \"TESLA\", \"confidence\": 100 }],\n",
    "                  \"mid\": \"frame4-tesla\",\n",
    "                  \"type\": \"rectangle\",\n",
    "                  \"isKeyFrame\": False\n",
    "                }\n",
    "              ]\n",
    "            }\n",
    "          },\n",
    "          \"4\": {\n",
    "            \"JOB\": {\n",
    "              \"annotations\": [\n",
    "                {\n",
    "                  \"boundingPoly\": [\n",
    "                    {\n",
    "                      \"normalizedVertices\": [\n",
    "                        { \"x\": 0.54, \"y\": 0.58 },\n",
    "                        { \"x\": 0.54, \"y\": 0.72 },\n",
    "                        { \"x\": 0.66, \"y\": 0.72 },\n",
    "                        { \"x\": 0.66, \"y\": 0.58 }\n",
    "                      ]\n",
    "                    }\n",
    "                  ],\n",
    "                  \"categories\": [{ \"name\": \"TESLA\", \"confidence\": 100 }],\n",
    "                  \"mid\": \"frame5-tesla\",\n",
    "                  \"type\": \"rectangle\",\n",
    "                  \"isKeyFrame\": False\n",
    "                }\n",
    "              ]\n",
    "            }\n",
    "          }\n",
    "        },\n",
    "        'model_name' : 'car-tracker-v0.0.1'\n",
    "    }\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Object detection with nested classification"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "project_examples.append(\n",
    "    {\n",
    "        'title' : 'Car tracking + Nested',\n",
    "        'description' : 'Identify cars',\n",
    "        'input_type' : 'FRAME',\n",
    "        'json_interface' : {\n",
    "            \"jobs\": {\n",
    "                \"DETECTION_JOB\": {\n",
    "                    \"mlTask\": \"OBJECT_DETECTION\",\n",
    "                    \"tools\": [\n",
    "                        \"rectangle\"\n",
    "                    ],\n",
    "                    \"required\": 1,\n",
    "                    \"isChild\": False,\n",
    "                    \"content\": {\n",
    "                        \"categories\": {\n",
    "                            \"TESLA\": {\n",
    "                                \"name\": \"Tesla\",\n",
    "                                \"children\": [\"CLASSIFICATION_JOB_1\"]\n",
    "                            },\n",
    "                            \"FERRARI\": {\n",
    "                                \"name\": \"Ferrari\",\n",
    "                                \"children\": [\"CLASSIFICATION_JOB_2\"]\n",
    "                            }\n",
    "                        },\n",
    "                        \"input\": \"radio\"\n",
    "                    }\n",
    "                },\n",
    "                \"CLASSIFICATION_JOB_1\": {\n",
    "                    \"mlTask\": \"CLASSIFICATION\",\n",
    "                    \"isChild\": True,\n",
    "                    \"content\": {\n",
    "                        \"categories\": {\n",
    "                            \"IS_THE_WHOLE_CAR_VISIBLE\": {\n",
    "                                \"name\": \"Is the whole car visible?\",\n",
    "                                \"children\": []\n",
    "                            }\n",
    "                        },\n",
    "                        \"input\": \"checkbox\"\n",
    "                    }\n",
    "                },\n",
    "                \"CLASSIFICATION_JOB_2\": {\n",
    "                    \"mlTask\": \"CLASSIFICATION\",\n",
    "                    \"isChild\": True,\n",
    "                    \"content\": {\n",
    "                        \"categories\": {\n",
    "                            \"IS_THE_WHOLE_CAR_VISIBLE\": {\n",
    "                                \"name\": \"Is the whole car visible?\",\n",
    "                                \"children\": []\n",
    "                            }\n",
    "                        },\n",
    "                        \"input\": \"checkbox\"\n",
    "                    }\n",
    "                }\n",
    "            }\n",
    "        },\n",
    "        'assets_to_import' : [\n",
    "             ['https://storage.googleapis.com/label-public-staging/video1/video1-img000001.jpg',\n",
    "              'https://storage.googleapis.com/label-public-staging/video1/video1-img000002.jpg',\n",
    "              'https://storage.googleapis.com/label-public-staging/video1/video1-img000003.jpg',\n",
    "              'https://storage.googleapis.com/label-public-staging/video1/video1-img000004.jpg',\n",
    "              'https://storage.googleapis.com/label-public-staging/video1/video1-img000005.jpg']\n",
    "        ],\n",
    "        'json_response' : {\n",
    "            \"0\": {\n",
    "                \"DETECTION_JOB\": {\n",
    "                    \"annotations\": [{\n",
    "                        \"boundingPoly\": [{\n",
    "                            \"normalizedVertices\": [\n",
    "                                { \"x\": 0.57, \"y\": 0.59 },\n",
    "                                { \"x\": 0.57, \"y\": 0.73 },\n",
    "                                { \"x\": 0.68, \"y\": 0.73 },\n",
    "                                { \"x\": 0.68, \"y\": 0.59 }\n",
    "                            ]\n",
    "                        }],\n",
    "                        \"categories\": [{ \"name\": \"TESLA\", \"confidence\": 100 }],\n",
    "                        \"children\": {\n",
    "                            \"CLASSIFICATION_JOB_1\": {\n",
    "                                \"categories\": [{ \"name\": \"IS_THE_WHOLE_CAR_VISIBLE\", \"confidence\": 100 }],\n",
    "                                'isKeyFrame': True\n",
    "                            }\n",
    "                        },\n",
    "                        \"mid\": \"frame1-tesla\",\n",
    "                        \"type\": \"rectangle\",\n",
    "                        \"isKeyFrame\": True\n",
    "                    }]\n",
    "                },\n",
    "            },\n",
    "            \"1\": {\n",
    "                \"DETECTION_JOB\": {\n",
    "                    \"annotations\": [{\n",
    "                        \"boundingPoly\": [{\n",
    "                            \"normalizedVertices\": [\n",
    "                                { \"x\": 0.56, \"y\": 0.58 },\n",
    "                                { \"x\": 0.56, \"y\": 0.74 },\n",
    "                                { \"x\": 0.68, \"y\": 0.74 },\n",
    "                                { \"x\": 0.68, \"y\": 0.58 }\n",
    "                            ]\n",
    "                        }],\n",
    "                        \"categories\": [{ \"name\": \"TESLA\", \"confidence\": 100 }],\n",
    "                        \"children\": {\n",
    "                            \"CLASSIFICATION_JOB_1\": {\n",
    "                                \"categories\": [{ \"name\": \"IS_THE_WHOLE_CAR_VISIBLE\", \"confidence\": 100 }],\n",
    "                                'isKeyFrame': False\n",
    "                            }\n",
    "                        },\n",
    "                        \"mid\": \"frame2-tesla\",\n",
    "                        \"type\": \"rectangle\",\n",
    "                        \"isKeyFrame\": False\n",
    "                    }]\n",
    "                }\n",
    "            },\n",
    "            \"2\": {\n",
    "                \"DETECTION_JOB\": {\n",
    "                    \"annotations\": [{\n",
    "                        \"boundingPoly\": [{\n",
    "                            \"normalizedVertices\": [\n",
    "                                { \"x\": 0.55, \"y\": 0.58 },\n",
    "                                { \"x\": 0.55, \"y\": 0.73 },\n",
    "                                { \"x\": 0.67, \"y\": 0.73 },\n",
    "                                { \"x\": 0.67, \"y\": 0.58 }\n",
    "                            ]\n",
    "                        }],\n",
    "                        \"categories\": [{ \"name\": \"TESLA\", \"confidence\": 100 }],\n",
    "                        \"children\": {\n",
    "                            \"CLASSIFICATION_JOB_1\": {\n",
    "                                \"categories\": [{ \"name\": \"IS_THE_WHOLE_CAR_VISIBLE\", \"confidence\": 100 }],\n",
    "                                'isKeyFrame': False\n",
    "                            }\n",
    "                        },\n",
    "                        \"mid\": \"frame3-tesla\",\n",
    "                        \"type\": \"rectangle\",\n",
    "                        \"isKeyFrame\": False\n",
    "                    }]\n",
    "                }\n",
    "            },\n",
    "            \"3\": {\n",
    "                \"DETECTION_JOB\": {\n",
    "                    \"annotations\": [{\n",
    "                        \"boundingPoly\": [{\n",
    "                            \"normalizedVertices\": [\n",
    "                                { \"x\": 0.55, \"y\": 0.58 },\n",
    "                                { \"x\": 0.55, \"y\": 0.72 },\n",
    "                                { \"x\": 0.67, \"y\": 0.72 },\n",
    "                                { \"x\": 0.67, \"y\": 0.58 }\n",
    "                            ]\n",
    "                        }],\n",
    "                        \"categories\": [{ \"name\": \"TESLA\", \"confidence\": 100 }],\n",
    "                        \"children\": {\n",
    "                            \"CLASSIFICATION_JOB_1\": {\n",
    "                                \"categories\": [{ \"name\": \"IS_THE_WHOLE_CAR_VISIBLE\", \"confidence\": 100 }],\n",
    "                                'isKeyFrame': False\n",
    "                            }\n",
    "                        },\n",
    "                        \"mid\": \"frame4-tesla\",\n",
    "                        \"type\": \"rectangle\",\n",
    "                        \"isKeyFrame\": False\n",
    "                    }]\n",
    "                }\n",
    "            },\n",
    "            \"4\": {\n",
    "                \"DETECTION_JOB\": {\n",
    "                    \"annotations\": [{\n",
    "                        \"boundingPoly\": [{\n",
    "                            \"normalizedVertices\": [\n",
    "                                { \"x\": 0.54, \"y\": 0.58 },\n",
    "                                { \"x\": 0.54, \"y\": 0.72 },\n",
    "                                { \"x\": 0.66, \"y\": 0.72 },\n",
    "                                { \"x\": 0.66, \"y\": 0.58 }\n",
    "                            ]\n",
    "                        }],\n",
    "                        \"categories\": [{ \"name\": \"TESLA\", \"confidence\": 100 }],\n",
    "                        \"children\": {\n",
    "                            \"CLASSIFICATION_JOB_1\": {\n",
    "                                \"categories\": [{ \"name\": \"IS_THE_WHOLE_CAR_VISIBLE\", \"confidence\": 100 }],\n",
    "                                'isKeyFrame': False\n",
    "                            }\n",
    "                        },\n",
    "                        \"mid\": \"frame5-tesla\",\n",
    "                        \"type\": \"rectangle\",\n",
    "                        \"isKeyFrame\": False\n",
    "                    }]\n",
    "                }\n",
    "            }\n",
    "        },\n",
    "        'model_name' : 'car-tracker-v0.0.2'\n",
    "    }\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Finally, with the following code snipet and the various examples above, you can set up an example for each project live on your account Kili:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "import time\n",
    "\n",
    "for project_example in project_examples:\n",
    "    project = kili.create_project(title=project_example['title'],\n",
    "                                  description=project_example['description'],\n",
    "                                  input_type=project_example['input_type'],\n",
    "                                  json_interface=project_example['json_interface'])\n",
    "    \n",
    "    assets_to_import = project_example['assets_to_import']\n",
    "    if len(assets_to_import) == 0:\n",
    "        continue\n",
    "    if isinstance(assets_to_import[0], dict) or isinstance(assets_to_import[0], list):\n",
    "        content_array = ['']*len(assets_to_import)\n",
    "        json_content_array = assets_to_import\n",
    "    else:\n",
    "        content_array = assets_to_import\n",
    "        json_content_array = None\n",
    "    kili.append_many_to_dataset(\n",
    "        project_id=project['id'], \n",
    "        content_array=content_array,\n",
    "        external_id_array=['ex1','ex2'],\n",
    "        json_content_array=json_content_array)\n",
    "    \n",
    "    id_check = kili.create_predictions(\n",
    "        project_id=project['id'],\n",
    "        external_id_array=['ex1'],\n",
    "        model_name_array=[project_example['model_name']],\n",
    "        json_response_array=[project_example['json_response']])\n",
    "    \n",
    "    assert(id_check['id']== project['id']) # just a check to assert that everything is running"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "## 4. Visualizing predictions in Kili\n",
    "To verify that the prediction in question was indeed pushed in Kili, you can go to https://cloud.kili-technology.com/label/projects/[PROJECT_ID]/dataset/?view=table&currentPage=1&pageSize=20. You should get a new `PREDICTION` line like this:\n",
    "\n",
    "![update settings](img/import_predictions-visualize_prediction.png)\n",
    "\n",
    "## Summary\n",
    "In this tutorial, we accomplished the following:\n",
    "- We introduced the concept of Kili interface settings and the 4 different kind of labels (`DEFAULT`, `PREDICTION`, `AUTOSAVE`, `REVIEW`).\n",
    "- We demonstrated how to retrieve a `DEFAULT` label.\n",
    "- We discussed all the possible `PREDICTION` labels that can be imported on the platform.\n",
    " \n",
    "If you enjoyed this tutorial, check out the other Recipes for other tutorials that you may find interesting, including demonstrations of how to use Kili.\n",
    "\n",
    "You can also visit the Kili website or Kili documentation for more info!\n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
