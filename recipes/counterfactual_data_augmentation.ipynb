{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Kili Tutorial: How to leverage Counterfactually augmented data to have a more robust model\n",
    "\n",
    "This recipe is inspired by the paper *Learning the Difference that Makes a Difference with Counterfactually-Augmented Data*, that you can find here on [arXiv](https://arxiv.org/abs/1909.12434)\n",
    "\n",
    "In this study, the authors point out the difficulty for machine learning models to generalize the classification rules learned, because their decision rules, described as 'spurious patterns', often miss the key elements that affect most the class of a text. They thus decided to delete what can be considered a confusion factor, by changing the label of an asset at the same time as changing the minimum amount of words so those **key-words** would be much easier for the model to spot.\n",
    "\n",
    "In this tutorial, we'll:\n",
    "1. Create projects in Kili, both for [IMDB](##Data-Augmentation-on-IMDB-dataset) and [SNLI](##Data-Augmentation-on-SNLI-dataset) datasets, to reproduce such a data-augmentation task, in order to improve our model and decrease its variance when used in production with unseen data.\n",
    "2. Try to [reproduce the results of the paper](##Reproducing-the-results), by using similar models, to show how such a technique can be of key interest while working on a text-classification task.\n",
    "We'll use the [publicly available data of the study](https://github.com/acmi-lab/counterfactually-augmented-data) for both IMDB and Stanford NLI.\n",
    "\n",
    "For an overview of Kili, visit our [website](https://kili-technology.com) or check out the Kili [documentation](https://docs.kili-technology.com).\n",
    "For a more on-hands experience, you can run some of the other recipes.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![data augmentation](https://raw.githubusercontent.com/acmi-lab/counterfactually-augmented-data/master/data_collection_pipeline.png)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: kili in /Library/Frameworks/Python.framework/Versions/3.10/lib/python3.10/site-packages (2.116.0)\n",
      "Requirement already satisfied: requests in /Library/Frameworks/Python.framework/Versions/3.10/lib/python3.10/site-packages (from kili) (2.27.1)\n",
      "Requirement already satisfied: websocket-client in /Library/Frameworks/Python.framework/Versions/3.10/lib/python3.10/site-packages (from kili) (1.3.2)\n",
      "Requirement already satisfied: six in /Library/Frameworks/Python.framework/Versions/3.10/lib/python3.10/site-packages (from kili) (1.16.0)\n",
      "Requirement already satisfied: click in /Library/Frameworks/Python.framework/Versions/3.10/lib/python3.10/site-packages (from kili) (8.1.3)\n",
      "Requirement already satisfied: tabulate in /Library/Frameworks/Python.framework/Versions/3.10/lib/python3.10/site-packages (from kili) (0.8.10)\n",
      "Requirement already satisfied: pandas in /Library/Frameworks/Python.framework/Versions/3.10/lib/python3.10/site-packages (from kili) (1.4.1)\n",
      "Requirement already satisfied: typeguard in /Library/Frameworks/Python.framework/Versions/3.10/lib/python3.10/site-packages (from kili) (2.13.3)\n",
      "Requirement already satisfied: pyparsing in /Library/Frameworks/Python.framework/Versions/3.10/lib/python3.10/site-packages (from kili) (3.0.7)\n",
      "Requirement already satisfied: tqdm in /Library/Frameworks/Python.framework/Versions/3.10/lib/python3.10/site-packages (from kili) (4.63.1)\n",
      "Requirement already satisfied: pytz>=2020.1 in /Library/Frameworks/Python.framework/Versions/3.10/lib/python3.10/site-packages (from pandas->kili) (2022.1)\n",
      "Requirement already satisfied: python-dateutil>=2.8.1 in /Library/Frameworks/Python.framework/Versions/3.10/lib/python3.10/site-packages (from pandas->kili) (2.8.2)\n",
      "Requirement already satisfied: numpy>=1.21.0 in /Library/Frameworks/Python.framework/Versions/3.10/lib/python3.10/site-packages (from pandas->kili) (1.22.3)\n",
      "Requirement already satisfied: charset-normalizer~=2.0.0 in /Library/Frameworks/Python.framework/Versions/3.10/lib/python3.10/site-packages (from requests->kili) (2.0.12)\n",
      "Requirement already satisfied: idna<4,>=2.5 in /Library/Frameworks/Python.framework/Versions/3.10/lib/python3.10/site-packages (from requests->kili) (3.3)\n",
      "Requirement already satisfied: urllib3<1.27,>=1.21.1 in /Library/Frameworks/Python.framework/Versions/3.10/lib/python3.10/site-packages (from requests->kili) (1.26.9)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /Library/Frameworks/Python.framework/Versions/3.10/lib/python3.10/site-packages (from requests->kili) (2022.6.15)\n",
      "\u001b[33mWARNING: You are using pip version 22.0.4; however, version 22.2 is available.\n",
      "You should consider upgrading via the '/Library/Frameworks/Python.framework/Versions/3.10/bin/python3.10 -m pip install --upgrade pip' command.\u001b[0m\u001b[33m\n",
      "\u001b[0m"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Library/Frameworks/Python.framework/Versions/3.10/lib/python3.10/site-packages/kili/authentication.py:92: UserWarning: Kili Python SDK version should match with Kili API version.\n",
      "Please install version: \"pip install kili==2.116.0\"\n",
      "  warnings.warn(message, UserWarning)\n"
     ]
    }
   ],
   "source": [
    "# Authentication\n",
    "import os\n",
    "\n",
    "!pip install --upgrade kili # uncomment if you don't have kili installed already\n",
    "from kili.client import Kili\n",
    "\n",
    "# api_endpoint = os.getenv('KILI_API_ENDPOINT') \n",
    "# If you use Kili SaaS, use the url 'https://cloud.kili-technology.com/api/label/v2/graphql'\n",
    "api_endpoint = \"https://cloud.kili-technology.com/api/label/v2/graphql\"\n",
    "\n",
    "kili = Kili(api_endpoint=api_endpoint, api_key=\"6dc85cf3-3bbd-47db-bb26-1915f459489d\")\n",
    "user_id = kili.auth.user_id"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data Augmentation on IMDB dataset\n",
    "\n",
    "The data consists of film reviews that are classified as positives or negatives. State-of-the-art model performance is often measured against this reference dataset. \n",
    "\n",
    "In Kili, we'll use 2 different projects; one for each task:\n",
    "- Negative to Positive\n",
    "- Positive to Negative"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Creating the projects"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "taskname = \"NEW_REVIEW\"\n",
    "project_imdb_negative_to_positive = {\n",
    "'title': 'Counterfactual data-augmentation - Negative to Positive',\n",
    "'description': 'IMDB Sentiment Analysis',\n",
    "'input_type': 'TEXT',\n",
    "'json_interface':{\n",
    "    \"filetype\": \"TEXT\",\n",
    "    \"jobs\": {\n",
    "        taskname : {\n",
    "            \"mlTask\": \"TRANSCRIPTION\",\n",
    "            \"content\": {\n",
    "                \"input\": None\n",
    "            },\n",
    "            \"required\": 1,\n",
    "            \"isChild\": False,\n",
    "            \"instruction\": \"Write here the new review modified to be POSITIVE. Please refer to the instructions above before starting\"\n",
    "        }\n",
    "    }\n",
    "}\n",
    "}\n",
    "project_imdb_positive_to_negative = {\n",
    "'title': 'Counterfactual data-augmentation - Positive to Negative',\n",
    "'description': 'IMDB Sentiment Analysis',\n",
    "'input_type': 'TEXT',\n",
    "'json_interface':{\n",
    "    \"jobs\": {\n",
    "        taskname : {\n",
    "            \"mlTask\": \"TRANSCRIPTION\",\n",
    "            \"content\": {\n",
    "                \"input\": None\n",
    "            },\n",
    "            \"required\": 1,\n",
    "            \"isChild\": False,\n",
    "            \"instruction\": \"Write here the new review modified to be NEGATIVE. Please refer to the instructions above before starting\"\n",
    "        }\n",
    "    }\n",
    "}\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "for project_imdb in [project_imdb_positive_to_negative,project_imdb_negative_to_positive]:\n",
    "    project_imdb['id'] = kili.create_project(title=project_imdb['title'],\n",
    "                                                   description=project_imdb['description'],\n",
    "                                                   input_type=project_imdb['input_type'],\n",
    "                                                   json_interface=project_imdb['json_interface'])['id']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now, let's add instructions to our newly-created projects"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "for project_imdb in [project_imdb_positive_to_negative,project_imdb_negative_to_positive]:\n",
    "    kili.update_properties_in_project(project_id=project_imdb['id'], instructions=\"https://docs.google.com/document/d/1zhNaQrncBKc3aPKcnNa_mNpXlria28Ij7bfgUvJbyfw/edit?usp=sharing\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now, we'll create some useful functions, for improved readability:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_assets(dataframe, intro, objective, instructions, truth_label, target_label) :\n",
    "    return((intro + dataframe[truth_label] + objective + dataframe[target_label] + instructions + dataframe['Text']).tolist())\n",
    "\n",
    "def create_json_responses(taskname,df,field=\"Text\") :\n",
    "    return( [{taskname: { \"text\": df[field].iloc[k] }\n",
    "          } for k in range(df.shape[0]) ])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Importing the data into Kili"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "datasets = ['dev','train','test']\n",
    "\n",
    "for dataset in datasets :\n",
    "    url = f'https://raw.githubusercontent.com/acmi-lab/counterfactually-augmented-data/master/sentiment/combined/paired/{dataset}_paired.tsv'\n",
    "    df = pd.read_csv(url, on_bad_lines='skip', sep='\\t')\n",
    "    df = df[df.index%2 == 0] # keep only the original reviews as assets\n",
    "    \n",
    "    for review_type,project_imdb in zip(['Positive','Negative'],[project_imdb_positive_to_negative,project_imdb_negative_to_positive]) :\n",
    "        dataframe = df[df['Sentiment']==review_type]\n",
    "        reviews_to_import = dataframe['Text'].tolist()\n",
    "        external_id_array = ('IMDB ' + review_type +' review ' + dataset + dataframe['batch_id'].astype('str')).tolist()\n",
    "    \n",
    "        kili.append_many_to_dataset(\n",
    "            project_id=project_imdb['id'],\n",
    "            content_array=reviews_to_import,\n",
    "            external_id_array=external_id_array)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Importing the labels into Kili \n",
    "We will use the results of the study as if they were predictions. In a real annotation project, we could use the review contents as well, so the labeler just would just have to enter the changes."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_name = 'results-arxiv:1909.12434'\n",
    "\n",
    "for dataset in datasets :\n",
    "    url = f'https://raw.githubusercontent.com/acmi-lab/counterfactually-augmented-data/master/sentiment/combined/paired/{dataset}_paired.tsv'\n",
    "    df = pd.read_csv(url, on_bad_lines='skip', sep='\\t')\n",
    "    df = df[df.index%2 == 1] # keep only the modified reviews as predictions\n",
    "    \n",
    "    for review_type,project_imdb in zip(['Positive','Negative'],[project_imdb_positive_to_negative,project_imdb_negative_to_positive]) :\n",
    "        dataframe = df[df['Sentiment']!=review_type]\n",
    "\n",
    "        external_id_array = ('IMDB ' + review_type +' review ' + dataset + dataframe['batch_id'].astype('str')).tolist()\n",
    "        json_response_array = create_json_responses(taskname,dataframe)\n",
    "    \n",
    "        kili.create_predictions(project_id=project_imdb['id'],\n",
    "            external_id_array=external_id_array,\n",
    "            model_name_array=[model_name]*len(external_id_array),\n",
    "            json_response_array=json_response_array)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This is how our interface looks in the end. This will allow us to quickly perform the task at hand.\n",
    "\n",
    "![IMDB](./img/imdb_review_new.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data Augmentation on SNLI dataset\n",
    "\n",
    "The data consists of a 3-class dataset. Provided with two phrases (a **premise** and a **hypothesis**) the machine learning model's task is to find the correct relation between those two sentences. The relation can be either \"entailment\", \"contradiction\" or \"neutral\".\n",
    "\n",
    "Here is an example of a premise, and three sentences that could be the hypothesis for the three categories:\n",
    "![examples](https://licor.me/post/img/robust-nlu/SNLI_annotation.png)\n",
    "\n",
    "This time we'll keep it as a single project."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Creating the project"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "taskname = \"SENTENCE_MODIFIED\"\n",
    "project_snli={\n",
    "'title': 'Counterfactual data-augmentation NLI',\n",
    "'description': 'Stanford Natural language Inference',\n",
    "'input_type': 'TEXT',\n",
    "'json_interface':{\n",
    "    \"jobs\": {\n",
    "        taskname: {\n",
    "            \"mlTask\": \"TRANSCRIPTION\",\n",
    "            \"content\": {\n",
    "                \"input\": None\n",
    "            },\n",
    "            \"required\": 1,\n",
    "            \"isChild\": False,\n",
    "            \"instruction\": \"Write here the modified sentence. Please refer to the instructions above before starting\"\n",
    "        }\n",
    "    }\n",
    "}\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Created project cl5wkwwm43n9f0qwt9l0xchfr\n"
     ]
    }
   ],
   "source": [
    "project_snli['id'] = kili.create_project(title=project_snli['title'],\n",
    "                                                     description=project_snli['description'],\n",
    "                                                     input_type=project_snli['input_type'],\n",
    "                                                     json_interface=project_snli['json_interface'])['id']\n",
    "print(f'Created project {project_snli[\"id\"]}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Again, we'll factorize our code a little, to merge datasets and properly differentiate all the cases of sentences: "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [],
   "source": [
    "def merge_datasets(dataset, sentence_modified) :\n",
    "    url_original = f'https://raw.githubusercontent.com/acmi-lab/counterfactually-augmented-data/master/NLI/original/{dataset}.tsv'\n",
    "    url_revised = f'https://raw.githubusercontent.com/acmi-lab/counterfactually-augmented-data/master/NLI/revised_{sentence_modified}/{dataset}.tsv'\n",
    "    df_original = pd.read_csv(url_original, on_bad_lines='skip', sep='\\t')\n",
    "    df_original = df_original[df_original.duplicated(keep='first')== False]\n",
    "    df_original['id'] = df_original.index.astype(str)\n",
    "    \n",
    "    df_revised = pd.read_csv(url_revised, on_bad_lines='skip', sep='\\t')\n",
    "    axis_merge = 'sentence2' if sentence_modified=='premise' else 'sentence1'\n",
    "    # keep only one label per set of sentences\n",
    "    df_revised = df_revised[df_revised[[axis_merge,'gold_label']].duplicated(keep='first')== False]\n",
    "\n",
    "    df_merged = df_original.merge(df_revised, how='inner', left_on=axis_merge, right_on=axis_merge)\n",
    "    \n",
    "    if sentence_modified ==  'premise' :\n",
    "        df_merged['Text'] = df_merged['sentence1_x'] + '\\nSENTENCE 2:\\n' + df_merged['sentence2']\n",
    "        instructions = \" relation, by making a small number of changes in the FIRST SENTENCE.\\\n",
    "        \\nMake sure that the document remains coherent and the new label accurately describes the revised passage:\\n\\n\\n\\\n",
    "        \\nSENTENCE 1:\\n\"\n",
    "    else : \n",
    "        df_merged['Text'] = df_merged['sentence1'] + '\\nSENTENCE 2:\\n' + df_merged['sentence2_x']\n",
    "        instructions = \" relation, by making a small number of changes in the SECOND SENTENCE.\\\n",
    "        \\nMake sure that the document remains coherent and the new label accurately describes the revised passage:\\n\\n\\n\\\n",
    "        \\nSENTENCE 1: \\n\"\n",
    "    return(df_merged, instructions)\n",
    "\n",
    "def create_external_ids(dataset,dataframe, sentence_modified):\n",
    "    return(('NLI ' + dataset + ' ' + dataframe['gold_label_x'] + ' to ' + dataframe['gold_label_y'] + ' ' + sentence_modified + ' modified ' + dataframe['id']).tolist())\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Importing the data into Kili\n",
    "Before each set of sentences, we'll add extra information for the labeler:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [],
   "source": [
    "datasets = ['dev','train','test']\n",
    "sentences_modified = ['premise', 'hypothesis']\n",
    "intro = \"The relation of these two sentences is classified as \"\n",
    "objective = \" to convert to a \"\n",
    "\n",
    "for dataset in datasets :\n",
    "    for sentence_modified in sentences_modified :\n",
    "        df,instructions = merge_datasets(dataset, sentence_modified)\n",
    "\n",
    "        sentences_to_import = create_assets(df, intro, objective, instructions, 'gold_label_x', 'gold_label_y')\n",
    "        external_id_array = create_external_ids(dataset, df, sentence_modified)\n",
    "    \n",
    "        kili.append_many_to_dataset(project_id=project_snli['id'],\n",
    "            content_array=sentences_to_import,\n",
    "            external_id_array=external_id_array)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Importing the labels into Kili \n",
    "We will use the results of the study, as if they were predictions."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_name = 'results-arxiv:1909.12434'\n",
    "\n",
    "for dataset in datasets :\n",
    "    for sentence_modified in sentences_modified :\n",
    "        axis_changed = 'sentence1_y' if sentence_modified=='premise' else 'sentence2_y'\n",
    "        df,instructions = merge_datasets(dataset, sentence_modified)\n",
    "\n",
    "        external_id_array = create_external_ids(dataset, df, sentence_modified)\n",
    "        json_response_array = create_json_responses(taskname,df,axis_changed) \n",
    "    \n",
    "        kili.create_predictions(project_id=project_snli['id'],\n",
    "            external_id_array=external_id_array,\n",
    "            model_name_array=[model_name]*len(external_id_array),\n",
    "            json_response_array=json_response_array)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![NLI](./img/snli_ex1_new.png)\n",
    "![NLI](./img/snli_ex2_new.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Cleanup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# for project in [project_imdb_positive_to_negative, project_imdb_negative_to_positive, project_snli]:\n",
    "#     kili.delete_project(project['id'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Conclusion\n",
    "In this tutorial, we learned how adding proper instructions in Kili's simple and easy to use interface can help in your data augmentation task.\n",
    "\n",
    "In the study, the quality of labeling was a very important factor. Luckily, with Kili, you can easily monitor quality. You could set up **consensus** on a portion of or all of the annotations, or even keep a part of the dataset as ground truth (**honeypot**) to measure the performance of every labeler.\n",
    "\n",
    "For an overview of Kili, visit our [website](https://kili-technology.com) or check out the Kili [documentation](https://docs.kili-technology.com).\n",
    "For a more on-hands experience, you can run some of the other recipes."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
