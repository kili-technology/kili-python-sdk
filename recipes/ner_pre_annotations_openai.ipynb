{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "c3bd4272-6236-4301-99e5-1a6da27f103a",
   "metadata": {
    "tags": []
   },
   "source": [
    "<a href=\"https://colab.research.google.com/github/kili-technology/kili-python-sdk/blob/master/recipes/ner_pre_annotations_openai.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d51fd409-fad3-48f3-bf19-087db76b43d6",
   "metadata": {
    "tags": []
   },
   "source": [
    "# Importing OpenAI NER pre-annotations"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "671d3a67-0e74-499c-aaff-666808ce46ef",
   "metadata": {},
   "source": [
    "with OpenAI Davinci 3 (?) model"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3b9e89bb-ebb1-4b09-882d-c0083b7ee223",
   "metadata": {},
   "source": [
    "## Introduction"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d82a6f46-f9b8-4441-a0f1-a23fe2478a96",
   "metadata": {},
   "source": [
    "Open AI Davinci....  zero-shot ... \n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "86a187fc-6225-4c40-8fdb-cf08e31465f2",
   "metadata": {
    "tags": []
   },
   "source": [
    "## Setup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "22df7707-5112-4b01-9877-32097945728c",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "!pip install kili datasets evaluate ipywidgets openai"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1acf5d41-fc12-48d6-8ae0-199f6f886cf0",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import os\n",
    "import getpass\n",
    "import json\n",
    "import requests\n",
    "import uuid\n",
    "import numpy as np\n",
    "import openai\n",
    "from pprint import pprint\n",
    "from tqdm import tqdm\n",
    "from typing import List"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8b98a93b-8abc-42a6-9f3f-305f3ff3d78c",
   "metadata": {},
   "source": [
    "## Data preparation\n",
    "Hugging Face CONNL dataset => filtering? => Open AI prediction with prompt => kili predictions\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0ff431f5-a5ca-418b-9d65-27ffae6da631",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "from datasets import load_dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "35f2e97b-c143-4d5e-99d8-1e09ca027c3e",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "MAX_DATAPOINTS = 5\n",
    "MIN_NB_TOKENS_PER_SENTENCE = 9"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f84416d2-14a7-4254-a67e-d164de5f63dc",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Found cached dataset conll2003 (/Users/jonasm/.cache/huggingface/datasets/conll2003/conll2003/1.0.0/9a4d16a94f8674ba3466315300359b0acd891b68b6c8743ddf60b9c702adce98)\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Filter:   0%|          | 0/14041 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "dataset = load_dataset(\"conll2003\", split=\"train\").filter(\n",
    "    lambda datapoint: int(datapoint[\"id\"]) < MAX_DATAPOINTS\n",
    "    and len(datapoint[\"tokens\"]) >= MIN_NB_TOKENS_PER_SENTENCE\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8318b0dc-471a-4804-b000-95b44d65ff69",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dataset({\n",
      "    features: ['id', 'tokens', 'pos_tags', 'chunk_tags', 'ner_tags'],\n",
      "    num_rows: 3\n",
      "})\n"
     ]
    }
   ],
   "source": [
    "print(dataset)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f2e0512f-cd9c-4442-a915-8367f790ba5b",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'id': '0', 'tokens': ['EU', 'rejects', 'German', 'call', 'to', 'boycott', 'British', 'lamb', '.'], 'pos_tags': [22, 42, 16, 21, 35, 37, 16, 21, 7], 'chunk_tags': [11, 21, 11, 12, 21, 22, 11, 12, 0], 'ner_tags': [3, 0, 7, 0, 0, 0, 7, 0, 0]}\n"
     ]
    }
   ],
   "source": [
    "print(dataset[0])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7575c08b-c8c9-44fb-b72c-7a282d40973e",
   "metadata": {},
   "source": [
    "Here is the meaning of each feature in the dataset:\n",
    "\n",
    "    id: A unique identifier for each token in a sentence.\n",
    "    tokens: The tokens (words or punctuation marks) in a sentence.\n",
    "    pos_tags: Part-of-speech tags for each token in the sentence. Part-of-speech tagging is the process of assigning a tag to each word in a sentence that indicates its part of speech (e.g., noun, verb, adjective, etc.).\n",
    "    chunk_tags: Chunking tags for each token in the sentence. Chunking is the process of grouping words into meaningful phrases based on their syntactic structure.\n",
    "    ner_tags: Named Entity Recognition (NER) tags for each token in the sentence. NER is the task of identifying named entities in text and classifying them into pre-defined categories such as person, organization, location, etc."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "febe548d-47da-476d-86d2-5dece489e4bd",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "NER_TAGS_ONTOLOGY = {\n",
    "    \"O\": 0,\n",
    "    \"B-PER\": 1,\n",
    "    \"I-PER\": 2,\n",
    "    \"B-ORG\": 3,\n",
    "    \"I-ORG\": 4,\n",
    "    \"B-LOC\": 5,\n",
    "    \"I-LOC\": 6,\n",
    "    \"B-MISC\": 7,\n",
    "    \"I-MISC\": 8,\n",
    "}"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cc9ae135-d4ac-40dd-bb8e-c34e0f143db7",
   "metadata": {},
   "source": [
    "NER_TAGS_ONTOLOGY is a dictionary that maps the named entity tags in the CoNLL2003 dataset to integer labels. Here is the meaning of each key-value pair in the dictionary:\n",
    "\n",
    "    \"O\": 0: Represents the tag \"O\" which means that the token is not part of a named entity.\n",
    "    \"B-PER\": 1: Represents the beginning of a person named entity.\n",
    "    \"I-PER\": 2: Represents a token inside a person named entity.\n",
    "    \"B-ORG\": 3: Represents the beginning of an organization named entity.\n",
    "    \"I-ORG\": 4: Represents a token inside an organization named entity.\n",
    "    \"B-LOC\": 5: Represents the beginning of a location named entity.\n",
    "    \"I-LOC\": 6: Represents a token inside a location named entity.\n",
    "    \"B-MISC\": 7: Represents the beginning of a miscellaneous named entity.\n",
    "    \"I-MISC\": 8: Represents a token inside a miscellaneous named entity.\n",
    "\n",
    "During the training of a Named Entity Recognition model, the entity tags are typically converted to integer labels using a dictionary like NER_TAGS_ONTOLOGY. This allows the model to predict the integer labels during training and inference, instead of predicting the string tags directly."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1a481ef4-cd47-4f4a-8f5c-26ff4ef07871",
   "metadata": {
    "tags": []
   },
   "source": [
    "## Connect with ChatGPT API"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6a5941b4-199e-4cd3-80bf-a846f31ca672",
   "metadata": {},
   "outputs": [],
   "source": [
    "if \"OPENAI_API_KEY\" in os.environ:\n",
    "    OPENAI_API_KEY = os.environ[\"OPENAI_API_KEY\"]\n",
    "else:\n",
    "    OPENAI_API_KEY = getpass.getpass(\"Please enter your OpenAI API key: \")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8018e367-8ac4-4400-9a8d-b77d8ebb8bbf",
   "metadata": {},
   "outputs": [],
   "source": [
    "openai.api_key = OPENAI_API_KEY"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cdc6e882-b518-4866-944c-4182f0ae9cc0",
   "metadata": {},
   "source": [
    "What sampling temperature to use, between 0 and 2. Higher values like 0.8 will make the output more random, while lower values like 0.2 will make it more focused and deterministic.\n",
    "\n",
    "The maximum number of tokens to generate in the completion. The token count of your prompt plus max_tokens cannot exceed the model's context length. Most models have a context length of 2048 tokens (except for the newest models, which support 4096)."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "496b6f69-17c6-455d-a030-4f4b4161601e",
   "metadata": {},
   "source": [
    "promt: string or array!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "db6cd52a-5279-4853-88e8-05fb2a660a1e",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "def ask_openai(prompt: str) -> str:\n",
    "    openai_query_params = {\"model\": \"text-davinci-003\", \"temperature\": 0, \"max_tokens\": 1024}\n",
    "    response = openai.Completion.create(\n",
    "        prompt=prompt,\n",
    "        **openai_query_params,\n",
    "    )\n",
    "    return response[\"choices\"][0][\"text\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ea2983cd-e828-4efc-897c-d814e1e219c1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "Yes, I am here. How can I help you?\n"
     ]
    }
   ],
   "source": [
    "print(ask_openai(\"Hello, are you here?\"))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "536a3ca9-0f8a-4084-9e32-2168cb01906b",
   "metadata": {},
   "source": [
    "## Prompt creation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1aed640d-c420-468d-9a3b-7ea4cbeb62d5",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "base_prompt = \"\"\"In the sentence below, give me the list of:\n",
    "- organisation names\n",
    "- for location names\n",
    "- people names\n",
    "- miscellaneous entity names.\n",
    "Format the output in json with the following keys:\n",
    "- ORG for organisation names\n",
    "- LOC for location names\n",
    "- PER for people names\n",
    "- MISC for miscellaneous.\n",
    "Sentence below:\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "656d09ac-68b9-442c-893d-5c759e599743",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "test_sentence = (\n",
    "    \"Elon Musk is the CEO of Tesla and SpaceX. He was born in South Africa and now lives in the\"\n",
    "    \" USA. He is one of the founders of OpenAI.\"\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "890056f6-e403-4ca9-8a1f-068533cf786d",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "{\n",
      "  \"ORG\": [\"Tesla\", \"SpaceX\", \"OpenAI\"],\n",
      "  \"LOC\": [\"South Africa\", \"USA\"],\n",
      "  \"PER\": [\"Elon Musk\"],\n",
      "  \"MISC\": []\n",
      "}\n"
     ]
    }
   ],
   "source": [
    "print(ask_openai(base_prompt + test_sentence))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d1cd460d-5405-4bde-a5a1-a2944c5e2ee9",
   "metadata": {
    "tags": []
   },
   "source": [
    "## Create the pre-annotations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "86c602c9-7fb6-4f64-ac7d-9613bdecdde6",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "openai_answers = []\n",
    "for datapoint in dataset:\n",
    "    sentence = \" \".join(datapoint[\"tokens\"])\n",
    "    answer = ask_openai(base_prompt + sentence)\n",
    "    answer_json = json.loads(answer)\n",
    "    openai_answers.append(answer_json)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ff6ebf46-637b-4b5f-9e33-fdb846fd4adc",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[{'ORG': ['EU', 'German'], 'LOC': ['British'], 'PER': [], 'MISC': ['lamb']},\n",
       " {'ORG': ['European Commission'],\n",
       "  'LOC': ['Germany', 'Britain'],\n",
       "  'PER': [],\n",
       "  'MISC': ['mad cow disease']},\n",
       " {'ORG': ['European Union', 'Britain'],\n",
       "  'LOC': ['Germany'],\n",
       "  'PER': ['Werner Zwingmann'],\n",
       "  'MISC': []}]"
      ]
     },
     "execution_count": null,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "openai_answers"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "24929d90-aea8-4e15-bb91-55a87388fdd7",
   "metadata": {},
   "source": [
    "\n",
    "## Import to Kili\n",
    "Import both assets and predictions and show a few screenshots: a good example and a bad example."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aa81a86c-29a3-40de-9eb8-b3a6b5e427e8",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "if \"KILI_API_KEY\" in os.environ:\n",
    "    KILI_API_KEY = os.environ[\"KILI_API_KEY\"]\n",
    "else:\n",
    "    KILI_API_KEY = getpass.getpass(\"Please enter your Kili API key: \")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3f9339bb-fe2b-49e4-8a0d-412dd4fc20b7",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "from kili.client import Kili"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fc8682c4-2eae-49cc-a7d9-758569c06f03",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/jonasm/kili-python-sdk/src/kili/authentication.py:44: UserWarning: Kili Python SDK version should match with Kili API version.\n",
      "Please install version: \"pip install kili==2.130.0\"\n",
      "  self.endpoint_kili_version = self.check_versions_match()\n"
     ]
    }
   ],
   "source": [
    "kili = Kili(\n",
    "    api_key=KILI_API_KEY,  # no need to pass the API_KEY if it is already in your environment variables\n",
    "    # api_endpoint=\"https://cloud.kili-technology.com/api/label/v2/graphql\",\n",
    "    # the line above can be uncommented and changed if you are working with an on-premise version of Kili\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4757855c-4bf8-432e-aa1d-d1d4e69399fe",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "5c5aa6d1-3a25-4e7f-848c-f79797872c4d",
   "metadata": {},
   "source": [
    "\n",
    "## Evaluation\n",
    "Show that the accuracy of Open AI Da Vinci is good enough to serve as preannotation."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "658b28a9-4a72-49d1-9db3-43632b2bc412",
   "metadata": {},
   "outputs": [],
   "source": [
    "import evaluate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "90918134-b3c7-4ce3-ae4f-5d2987b5a981",
   "metadata": {},
   "outputs": [],
   "source": [
    "accuracy_metric = evaluate.load(\"accuracy\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "44aeb80e-a4a8-456f-bc27-e467e5976666",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "03504b4a-1bd0-4358-8267-3b219ce1f174",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d9f17966-77e4-4f34-b46b-7e87a7fab890",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f54a5f75-9f0d-493d-add1-91ba44e6930b",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bdf04fc8-dc08-4445-95cd-752cfbe7517e",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "8cfe9f99-ac11-4213-a375-a402f728a328",
   "metadata": {},
   "source": [
    "model: choose your model: https://platform.openai.com/docs/models/overview"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "af77d734-0fec-4aaf-bbe1-358d78ce7137",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c40fac8b-6c91-4ceb-8f67-cbe177c62996",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
