{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Fine-tuning OpenAI's base models using Kili-technology"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In this tutorial, we'll learn how to build a model that is able to assign one of 8 predefined categories to short twitter-length news. We'll use one of OpenAI's base models and we'll fine-tune it using our data, with the hope of reaching far superior results that the one-size-fits-all standard models can provide.\n",
    "\n",
    "We'll start by finding and downloading an interesting dataset to train our model with.\n",
    "Next, we'll process the dataset so that it fits our needs and set up our project in the Kili app.\n",
    "Then, we'll use OpenAI's Curie model to generate first model-based, inference labels, which we'll upload to the Kili app.\n",
    "After that, we'll simulate human labeling to benchmark our model against human-generated labels.\n",
    "Having done that, we'll download the *gold standard* labels from Kili and use them to fine-tune Curie, one of OpenAi's base models.\n",
    "Finally, we'll ask the fine-tuned model to generate predictions on a new dataset."
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Finding the dataset to work with"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "After rummaging through Kaggle for some time, we managed to locate something that seems interesting: a dataset listing Huffingpost's articles published over the course of several years, with links to articles, short descriptions, authors, and dates they were published.\n",
    "\n",
    "https://www.kaggle.com/datasets/rmisra/news-category-dataset\n",
    "\n",
    "It's published under a very generous license https://creativecommons.org/licenses/by/4.0/ so we can wring it in any way we want; which we will, because the original file is huuuuuge. Plus, we don't really need most of its contents. What we're interested in is headlines, their respective short descriptions, and assigned categories.\n",
    "\n",
    "To save some time and to eliminate some of the complexity, we've decided to filter the dataset and leave only the data matching 8 most basic categories that should be fairly easy to process by an off-the-shelf, general-purpose model.\n",
    "\n",
    "We ended up removing all the entries with vague categories like `IMPACT` or `PARENTING`. Most of the time they matched other categories, too and we bet that the next time they got tagged by humans, the chosen category would be different. The `WEIRD NEWS` category with summaries like `There is guano on the court,` of course got removed, too. We have to admit we had a moment of hesitation on whether or not we should combine `CRIME` and `POLITICS` into one category, but we ended up not doing that. This is the final list:\n",
    "\n",
    "- MEDIA & ENTERTAINMENT\n",
    "- WORLD NEWS\n",
    "- CULTURE & ARTS\n",
    "- SCIENCE & TECHNOLOGY\n",
    "- SPORTS\n",
    "- POLITICS\n",
    "- MONEY & BUSINESS\n",
    "- STYLE & BEAUTY\n",
    "\n",
    "To make matters as simple as possible, the assumption is that one piece of news can match only one of these categories.\n",
    "\n",
    "Based on OpenAI's recommendations:\n",
    "> The more training examples you have, the better. We recommend having at least a couple hundred examples. In general, we've found that each doubling of the dataset size leads to a linear increase in model quality.\n",
    "\n",
    "So to make sure to match these needs, we've created 4 sample files, each one containing 100 sample labeled examples for each one of the 8 classes. Should this not be enough, you can easily process the original dataset to get more.\n",
    "\n",
    "Let's now download the training and fine-tuning datasets that we created based on the original dataset:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%pip install wget"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!wget https://raw.githubusercontent.com/kili-technology/kili-python-sdk/main/recipes/datasets/curie1.txt https://raw.githubusercontent.com/kili-technology/kili-python-sdk/main/recipes/datasets/curie2.txt https://raw.githubusercontent.com/kili-technology/kili-python-sdk/main/recipes/datasets/curie3.txt https://raw.githubusercontent.com/kili-technology/kili-python-sdk/main/recipes/datasets/curie4.txt"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Setting up a project in the Kili app"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%pip install  kili"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "For the next step, you'll need a Kili API key. Here's how you can create it: https://docs.kili-technology.com/docs/creating-an-api-key"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from kili.client import Kili\n",
    "\n",
    "kili = Kili(\n",
    "    # api_endpoint=\"https://cloud.kili-technology.com/api/label/v2/graphql\",\n",
    "    # the line above can be uncommented and changed if you are working with an on-premise version of Kili\n",
    ")"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This code is basically your Kili project ontology in JSON format. Note all the categories that we listed ealier on plus an additional `UNABLE_TO_CLASSIFY` category for situations when, for whatever reason, the model fails to do the job:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "interface = {\n",
    "    \"jobs\": {\n",
    "        \"CLASSIFICATION_JOB\": {\n",
    "            \"content\": {\n",
    "                \"categories\": {\n",
    "                    \"MEDIA_AND_ENTERTAINMENT\": {\n",
    "                        \"children\": [],\n",
    "                        \"name\": \"MEDIA AND ENTERTAINMENT\",\n",
    "                        \"id\": \"category11\",\n",
    "                    },\n",
    "                    \"WORLD_NEWS\": {\"children\": [], \"name\": \"WORLD NEWS\", \"id\": \"category12\"},\n",
    "                    \"CULTURE_AND_ARTS\": {\n",
    "                        \"children\": [],\n",
    "                        \"name\": \"CULTURE AND ARTS\",\n",
    "                        \"id\": \"category13\",\n",
    "                    },\n",
    "                    \"SCIENCE_AND_TECHNOLOGY\": {\n",
    "                        \"children\": [],\n",
    "                        \"name\": \"SCIENCE AND TECHNOLOGY\",\n",
    "                        \"id\": \"category14\",\n",
    "                    },\n",
    "                    \"SPORTS\": {\"children\": [], \"name\": \"SPORTS\", \"id\": \"category15\"},\n",
    "                    \"POLITICS\": {\"children\": [], \"name\": \"POLITICS\", \"id\": \"category16\"},\n",
    "                    \"MONEY_AND_BUSINESS\": {\n",
    "                        \"children\": [],\n",
    "                        \"name\": \"MONEY AND BUSINESS\",\n",
    "                        \"id\": \"category17\",\n",
    "                    },\n",
    "                    \"STYLE_AND_BEAUTY\": {\n",
    "                        \"children\": [],\n",
    "                        \"name\": \"STYLE AND BEAUTY\",\n",
    "                        \"id\": \"category18\",\n",
    "                    },\n",
    "                    \"UNABLE_TO_CLASSIFY\": {\n",
    "                        \"children\": [],\n",
    "                        \"name\": \"UNABLE TO CLASSIFY\",\n",
    "                        \"id\": \"category19\",\n",
    "                    },\n",
    "                },\n",
    "                \"input\": \"radio\",\n",
    "            },\n",
    "            \"instruction\": \"Select a matching category:\",\n",
    "            \"mlTask\": \"CLASSIFICATION\",\n",
    "            \"required\": 1,\n",
    "            \"isChild\": False,\n",
    "            \"isNew\": False,\n",
    "        }\n",
    "    }\n",
    "}"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We'll now use this ontology as an input parameter to a method that creates an actual Kili project:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "result = kili.create_project(\n",
    "    title=\"[Kili SDK Notebook]: Kili GPT fine-tuning project\",\n",
    "    description=\"Kili GPT fine-tuning project\",\n",
    "    input_type=\"TEXT\",\n",
    "    json_interface=interface,\n",
    ")\n",
    "\n",
    "project_id = result[\"id\"]"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As the next step, we need to extract the data from the curated dataset and upload the news headlines to Kili. Each line of the input file contains the input text and its assigned class, separated by the \"|\" symbol."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "full_content_dict = dict()\n",
    "\n",
    "with open(\"curie1.txt\") as cur:\n",
    "    for e in enumerate(cur):\n",
    "        entry = e[1].split(\"|\")\n",
    "        full_content_dict[e[0]] = (entry[0], entry[1].replace(\"\\n\", \"\"))\n",
    "\n",
    "content_array = [i[0] for i in full_content_dict.values()]\n",
    "categories_array = [i[1] for i in full_content_dict.values()]\n",
    "external_id_array = [f\"text_{i}\" for i in full_content_dict.keys()]"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This code creates the actual assets (in bulk) in our Kili project:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "kili.append_many_to_dataset(\n",
    "    project_id=project_id,\n",
    "    content_array=content_array,\n",
    "    external_id_array=external_id_array,\n",
    ")"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Generating first predictions"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now, let's install and instantiate openai. You'll need your OpenAI organization id and your OpenAI API key to complete these steps."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%pip install --upgrade openai"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import openai\n",
    "\n",
    "openai.api_key = \"<YOUR OPENAI API KEY>\"\n",
    "openai.organization = \"YOUR OPENAI ORGANIZATION ID\""
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Based on OpenAI's documentation, this the list of OpenAI's base models that can be fine-tuned (only GPT3 models can be fine-tuned):\n",
    "\n",
    "- Davinci –  *Most capable GPT-3 model. Can do any task the other models can do, often with higher quality*.\n",
    "- Curie –  *Very capable, but faster and lower cost than Davinci*.\n",
    "- Babbage – *Capable of straightforward tasks, very fast, and lower cost*.\n",
    "- Ada – *Capable of very simple tasks, usually the fastest model in the GPT-3 series, and lowest cost*.\n",
    "\n",
    "The cost is an important factor here. According to OpenAI:\n",
    "\n",
    "> Tokens can be thought of as pieces of words. Before the API processes the prompts, the input is broken down into tokens. These tokens are not cut up exactly where the words start or end - tokens can include trailing spaces and even sub-words. Here are some helpful rules of thumb for understanding tokens in terms of lengths:\n",
    "> - 1 token ~= 4 chars in English\n",
    "> - 1 token ~= ¾ words\n",
    "> - 100 tokens ~= 75 words\n",
    "\n",
    "More information on tokens here: https://help.openai.com/en/articles/4936856-what-are-tokens-and-how-to-count-them.\n",
    "\n",
    "Davinci is the most sophisticated of the lot and seems best fit for our needs, but it's also the most expensive ($0.0200 / 1K tokens) so if we're going to use more-or-less Twitter-length messages to train and test the model, with many fine-tuning iterations, the cost may be significantly higher than expected.\n",
    "\n",
    "OpenAI suggest using Ada for classification:\n",
    "\n",
    "> Classifiers are the easiest models to get started with. For classification problems we suggest using ada, which generally tends to perform only very slightly worse than more capable models once fine-tuned, whilst being significantly faster and cheaper.\n",
    "\n",
    "... but for some reason it kept failing when we were testing it at our end. So we decided to try and use the second-best Curie model, as it seemed best value-for-money for our specific POC-type task.\n",
    "\n",
    "You can, of course, try it out and experiment with it yourself.\n",
    "\n",
    "Right, so with that behind us, let's now try to write some code that gets actual predictions from the base Curie model:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "prompt_text = \"\"\"Classify the text of the following message as exactly one of the following:\n",
    "MEDIA AND ENTERTAINMENT, WORLD NEWS, CULTURE AND ARTS, SCIENCE AND TECHNOLOGY,\n",
    "SPORTS, POLITICS, MONEY AND BUSINESS, STYLE AND BEAUTY.\n",
    "message: <SAMPLE_MESSAGE_TO_CLASSIFY>.\n",
    "text: \"\"\"\n",
    "\n",
    "\n",
    "def classify_text(content, model):\n",
    "    classification = openai.Completion.create(\n",
    "        model=model,\n",
    "        engine=\"text_curie_001\",\n",
    "        prompt=prompt_text.replace(\"<SAMPLE_MESSAGE_TO_CLASSIFY>\", content),\n",
    "        max_tokens=10,\n",
    "        temperature=0,\n",
    "    )\n",
    "\n",
    "    # Based on OpenAI's tokenizer, https://platform.openai.com/tokenizer,\n",
    "    # our longest class is 6-tokens long.\n",
    "    # Just in case, we've set the max_tokens value to 10\n",
    "\n",
    "    returned_value = classification[\"choices\"][0][\"text\"]  # type: ignore\n",
    "\n",
    "    all_predefined_classes = [\n",
    "        \"POLITICS\",\n",
    "        \"MEDIA AND ENTERTAINMENT\",\n",
    "        \"WORLD NEWS\",\n",
    "        \"CULTURE AND ARTS\",\n",
    "        \"SCIENCE AND TECHNOLOGY\",\n",
    "        \"SPORTS\",\n",
    "        \"MONEY AND BUSINESS\",\n",
    "        \"STYLE AND BEAUTY\",\n",
    "    ]\n",
    "\n",
    "    result = \"UNABLE_TO_CLASSIFY\"\n",
    "\n",
    "    # Sometimes the model returns more than one class so let's filter them out:\n",
    "\n",
    "    index = len(returned_value)\n",
    "    for predefined_class in all_predefined_classes:\n",
    "        if (\n",
    "            predefined_class in returned_value.upper()\n",
    "            and returned_value.upper().index(predefined_class) < index\n",
    "        ):\n",
    "            result = predefined_class\n",
    "\n",
    "    return result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.google.colaboratory.intrinsic+json": {
       "type": "string"
      },
      "text/plain": [
       "'CULTURE AND ARTS'"
      ]
     },
     "execution_count": null,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sample_message_to_classify = (\n",
    "    \"Golden Globes Returning To NBC In January After Year Off-Air. For the past 18 months,\"\n",
    "    \" Hollywood has effectively boycotted the Globes after reports that the HFPA's 87 members of\"\n",
    "    \" non-American journalists included no Black members.\"\n",
    ")\n",
    "# sample_message_to_classify_2 = \"Amazon Greenlights 'Blade Runner 2099' Limited Series Produced By Ridley Scott. The director of the original 1982 film joins a writer of the 2017 sequel for the newest installment in the sci-fi franchise.\"\n",
    "# sample_message_to_classify_3 = \"Tips For Hand-Washing Clothes In The Tub. Doing laundry at home during the coronavirus pandemic? Experts share their tried-and-true ways to clean clothing by hand.\"\n",
    "\n",
    "classify_text(content=sample_message_to_classify, model=\"curie\")\n",
    "# classify_text(content=sample_message_to_classify_2, model=\"curie\")\n",
    "# classify_text(content=sample_message_to_classify_3, model=\"curie\")"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "OK, at first glance the base Curie model seems to work fine. Let's now try to create 800 predictions and upload them to Kili"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "predicted_classes_dict = dict()\n",
    "\n",
    "for entry in full_content_dict:\n",
    "    content = full_content_dict[entry][0]\n",
    "\n",
    "    # For some weird reason, the model doesn't want to predict on some of the\n",
    "    # messgages. We'll need to find a way around this limitation:\n",
    "\n",
    "    try:\n",
    "        predicted_class = classify_text(content=content, model=\"curie\")\n",
    "    except Exception as e:\n",
    "        print(f\"getting predictions on entry # {entry} failed.\\nException: {e}\")\n",
    "        predicted_class = \"UNABLE_TO_CLASSIFY\"\n",
    "        print(predicted_class)\n",
    "\n",
    "    predicted_classes_dict[entry] = predicted_class"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As you see in the code above, for some internal reason, trying to assign a class to some of the content fails. We've added an exception to label these as \"UNABLE_TO_CLASSIFY\"."
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now we'll upload the model-generated labels to the assets that we upload to Kili earlier on.\n",
    "For more information on Kili's INFERENCE-type labels, see https://docs.kili-technology.com/reference/label-types#inference."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "inference_cat_array = [\"UNABLE_TO_CLASSIFY\"] * 800\n",
    "# This is just in case, really.\n",
    "# 100% of the UNABLE_TO_CLASSIFY labels should have been handled by the code that queried the model earlier on.\n",
    "# Setting the length of this list to 800, which is the length of the dataset we're working with (8 categories, 100 examples per each category)\n",
    "\n",
    "for i in range(len(predicted_classes_dict)):\n",
    "    inference_cat_array[i] = predicted_classes_dict[i]\n",
    "\n",
    "# Here, we'll dynamically generate an array of labels so that we can upload them to Kili in bulk.\n",
    "kili.append_labels(\n",
    "    json_response_array=[\n",
    "        {\n",
    "            \"CLASSIFICATION_JOB\": {\n",
    "                \"categories\": [\n",
    "                    {\n",
    "                        \"confidence\": 100,\n",
    "                        \"name\": i.replace(\" \", \"_\").replace(\"&\", \"AND\").replace(\"\\n\", \"\"),\n",
    "                    }\n",
    "                ]\n",
    "            }\n",
    "        }\n",
    "        for i in inference_cat_array\n",
    "    ],\n",
    "    model_name=\"Curie\",\n",
    "    label_type=\"INFERENCE\",\n",
    "    project_id=project_id,\n",
    "    asset_external_id_array=external_id_array,\n",
    ")"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Simulating human labeling in a Kili project"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now that we have our assets labeled by the model, we need to ask humans to add their own labels. We'll simulate this here by adding a bunch of labels from our pre-labeled dataset. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "kili.append_labels(\n",
    "    json_response_array=[\n",
    "        {\n",
    "            \"CLASSIFICATION_JOB\": {\n",
    "                \"categories\": [\n",
    "                    {\n",
    "                        \"confidence\": 100,\n",
    "                        \"name\": i.replace(\" \", \"_\").replace(\"&\", \"AND\").replace(\"\\n\", \"\"),\n",
    "                    }\n",
    "                ]\n",
    "            }\n",
    "        }\n",
    "        for i in categories_array\n",
    "    ],\n",
    "    label_type=\"DEFAULT\",\n",
    "    project_id=project_id,\n",
    "    asset_external_id_array=external_id_array,\n",
    ")"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "OK, this is just a simulation. In a real-world project where a lot is at stake and you want to avoid the situation when different labelers assign different classes to ambiguous content, we'd recomment using one of numerous Kili QA settings.\n",
    "\n",
    "You could start off by scrutinizing your dataset and creating very detailed instructions that take into account possible corner cases.\n",
    "Then you'd want to set up and then closely monitor honeypot and consensus metrics to trace how much your labelers agree with each other and how far away from ground truth they can be. If you pair this with Kili's powerful QA plugins, you can even set up a system that automatically adds issues to labels that differ from the *gold standard*.\n",
    "On top of that, you'd want to monitor the questions being asked by your labelers and adjust your instructions accordingly.\n",
    "Kili offers a ton of options and we strongly encourage you to explore them: https://docs.kili-technology.com/docs/best-practices-for-quality-workflow"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's now use Kili's KPIs to check how well the model did when compared to our *ground truth*. This is how it's calculated for single-category classification tasks:\n",
    "\n",
    "1. Take all the selected categories. If the available categories were \"MEDIA AND ENTERTAINMENT\" and \"POLITICS\", and all the labelers selected the same category, this value will be 1. If two different categories were selected, the value will be 2.\n",
    "2. Iterate through the selected categories:\n",
    "For each labeler who selected a category, we calculate 1 / total number of labelers. For 2 labelers who selected \"MEDIA AND ENTERTAINMENT\", this value will be 1/2 for each one of them, which gives us a total score of 1 for this category. If one labeler selected \"MEDIA AND ENTERTAINMENT\" and the model selected \"POLITICS\", both of these categories will have a score of 1/2\n",
    "3. Add all the scores per category and then divide by the number of selected categories. In our case, if the model and our simulated *ground truth* labelers both pointed to the same class, the score will be 1 / 1 = 1 (100%). If two different classes were selected, the score will be 1/2 = 0.5 (50%).\n",
    "\n",
    "So in essence, in our project, there's only two possible IoU scores we can have per asset: either 50% for differing results or 100% for aligned results.\n",
    "\n",
    "Now, let's count how many assets in our dataset have differing results and try and get a percentage score:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "671"
      ]
     },
     "execution_count": null,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# inference_mark_lte (\"lower than or equal to\") is used to filter assets that have an agreement score lower than 51%\n",
    "\n",
    "low_scores = kili.count_assets(project_id=project_id, inference_mark_lte=0.50)\n",
    "low_scores"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "When we ran the test, 671 examples were wrongly classified. This means that  the model was only right 16% of the time.\n",
    "\n",
    "Since we have 8 classes, a random \"dumb\" model would be able to have 1/8 = 12.5% accuracy. This means that our base LLM is just a little bit smarter than a dumb, untrained model.\n",
    "\n",
    "We'll need to fine-tune the model to make this score as low as possible."
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The total number of assets was 800 (100 per category). So the total score is:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.16125"
      ]
     },
     "execution_count": null,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "initial_score = (len(content_array) - low_scores) / len(content_array)\n",
    "initial_score"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "When we ran the test, 671 examples were wrongly classified. This means that  the model was only right 16% of the time.\n",
    "\n",
    "Since we have 8 classes, a random \"dumb\" model would be able to have 1/8 = 12.5% accuracy. This means that our base LLM is just a little bit smarter than a dumb, untrained model.\n",
    "\n",
    "We'll need to fine-tune the model to make this score as high as possible."
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Fine-tuning a base model"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We'll first have to export our labels from the Kili project. As in this case we don't need anything fancy, let's just select the \"raw\" format:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "kili.export_labels(project_id=project_id, filename=\"kili_export.zip\", fmt=\"raw\")"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "For more information on exporting annotations, see: https://python-sdk-docs.kili-technology.com/latest/sdk/label/#kili.entrypoints.queries.label.__init__.QueriesLabel.export_labels. For more information on supported export formats and general info on exporting with Kili, see https://docs.kili-technology.com/docs/exporting-project-data#exported-label-formats\n",
    "\n",
    "To make this a bit simpler, you can also retrieve the assets and labels directly using `kili.assets` or `kili.labels`."
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's now extract all the exported labels:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!unzip kili_export.zip"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To be able to use this data to fine-tune our base model, we'll need to upload it to the OpenAI instance as a JSONL document, where each line is a prompt-completion pair corresponding to a training example, ending with the newline symbol.\n",
    "\n",
    "> To fine-tune a model, you'll need a set of training examples that each consist of a single input (\"prompt\") and its associated output (\"completion\"). This is notably different from using our base models, where you might input detailed instructions or multiple examples in a single prompt.\n",
    "\n",
    "\n",
    "> Each prompt should end with a fixed separator to inform the model when the prompt ends and the completion begins. A simple separator which generally works well is \\n\\n###\\n\\n. The separator should not appear elsewhere in any prompt.\n",
    "\n",
    "\n",
    "> Each completion should start with a whitespace due to our tokenization, which tokenizes most words with a preceding whitespace.\n",
    "\n",
    "\n",
    "> Each completion should end with a fixed stop sequence to inform the model when the completion ends. A stop sequence could be \\n, ###, or any other token that does not appear in any completion.\n",
    "\n",
    "\n",
    "> For inference, you should format your prompts in the same way as you did when creating the training dataset, including the same separator. Also specify the same stop sequence to properly truncate the completion.\n",
    "\n",
    "\n",
    "For more information, see OpenAI's documentation here: https://platform.openai.com/docs/guides/fine-tuning."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "\n",
    "field_path = [\"latestLabel\", \"jsonResponse\", \"CLASSIFICATION_JOB\", \"categories\"]\n",
    "\n",
    "\n",
    "def get_nested_field(json_data, field_path):\n",
    "    current_data = json_data\n",
    "    try:\n",
    "        for field in field_path:\n",
    "            current_data = current_data[field]\n",
    "        return current_data\n",
    "    except (KeyError, TypeError):\n",
    "        return None\n",
    "\n",
    "\n",
    "kc = open(\"kili-fine-tune.jsonl\", \"w\")\n",
    "all_entries_list = []\n",
    "\n",
    "for id in external_id_array:\n",
    "    with open(f\"labels/{id}.json\") as file:\n",
    "        ordinal = int(id.split(\"_\")[1])\n",
    "        json_data = json.load(file)\n",
    "        nested_field = get_nested_field(json_data, field_path)\n",
    "        exported_class = nested_field[0][\"name\"]\n",
    "        prompt = f\"{content_array[ordinal]}[PROMPT_STOP]\"\n",
    "        completion = f\" {exported_class}[END]\"\n",
    "        prompt_j = {}\n",
    "        prompt_j[\"prompt\"] = prompt\n",
    "        prompt_j[\"completion\"] = completion\n",
    "        kc.write(f\"{json.dumps(prompt_j)}\\n\")\n",
    "\n",
    "kc.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fine_tune_file = \"/content/kili-fine-tune.jsonl\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!head /content/kili-fine-tune.jsonl"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now, we'll save this fine to the OpenAI instance so that it can be used for fine-tuning:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<File file id=file-16879c80ed3b4ae3a5fe3932a0c30ff6 at 0x7fb2a0ab58a0> JSON: {\n",
       "  \"bytes\": 196213,\n",
       "  \"created_at\": 1685719658,\n",
       "  \"filename\": \"kili-fine-tune1.jsonl\",\n",
       "  \"id\": \"file-16879c80ed3b4ae3a5fe3932a0c30ff6\",\n",
       "  \"object\": \"file\",\n",
       "  \"purpose\": \"fine-tune\",\n",
       "  \"status\": \"notRunning\",\n",
       "  \"updated_at\": 1685719658\n",
       "}"
      ]
     },
     "execution_count": null,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "openai.File.create(\n",
    "    file=open(fine_tune_file),\n",
    "    purpose=\"fine-tune\",\n",
    "    user_provided_filename=\"kili-fine-tune1.jsonl\",\n",
    ")"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let the fine-tuning begin!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<FineTune fine-tune id=ft-8e922209fe7a4298871a11f26da59ed1 at 0x7fb2a0d23b50> JSON: {\n",
       "  \"created_at\": 1685719688,\n",
       "  \"events\": [\n",
       "    {\n",
       "      \"created_at\": 1685719688,\n",
       "      \"level\": \"info\",\n",
       "      \"message\": \"Job enqueued. Waiting for jobs ahead to complete.\",\n",
       "      \"object\": \"fine-tune-event\"\n",
       "    }\n",
       "  ],\n",
       "  \"hyperparams\": {\n",
       "    \"batch_size\": 1,\n",
       "    \"compute_classification_metrics\": false,\n",
       "    \"learning_rate_multiplier\": 0.2,\n",
       "    \"n_epochs\": 2,\n",
       "    \"prompt_loss_weight\": 0.1\n",
       "  },\n",
       "  \"id\": \"ft-8e922209fe7a4298871a11f26da59ed1\",\n",
       "  \"model\": \"curie\",\n",
       "  \"object\": \"fine-tune\",\n",
       "  \"status\": \"notRunning\",\n",
       "  \"training_files\": [\n",
       "    {\n",
       "      \"created_at\": 1685719658,\n",
       "      \"filename\": \"m+nhs1g1ThJnWJwIlGQgkeEny1cpTnS6IrutA9XJco9xxYg658QM51gbmmgGpAFr\",\n",
       "      \"id\": \"file-16879c80ed3b4ae3a5fe3932a0c30ff6\",\n",
       "      \"object\": \"file\",\n",
       "      \"purpose\": \"fine-tune\",\n",
       "      \"statistics\": {\n",
       "        \"examples\": 800,\n",
       "        \"tokens\": 23835\n",
       "      },\n",
       "      \"status\": \"succeeded\",\n",
       "      \"updated_at\": 1685719672\n",
       "    }\n",
       "  ],\n",
       "  \"updated_at\": 1685719688,\n",
       "  \"validation_files\": []\n",
       "}"
      ]
     },
     "execution_count": null,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "kili_ft = openai.FineTune.create(\n",
    "    training_file=\"file-16879c80ed3b4ae3a5fe3932a0c30ff6\", model=\"curie\"\n",
    ")\n",
    "\n",
    "kili_ft"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Fin-tuning can take a while so you should monitor your fine-tuning training and wait for it to end:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{\n",
      "  \"created_at\": 1685719688,\n",
      "  \"level\": \"info\",\n",
      "  \"message\": \"Job enqueued. Waiting for jobs ahead to complete.\",\n",
      "  \"object\": \"fine-tune-event\"\n",
      "}\n",
      "{\n",
      "  \"created_at\": 1685719767,\n",
      "  \"level\": \"info\",\n",
      "  \"message\": \"Job started.\",\n",
      "  \"object\": \"fine-tune-event\"\n",
      "}\n",
      "{\n",
      "  \"created_at\": 1685719819,\n",
      "  \"level\": \"info\",\n",
      "  \"message\": \"Preprocessing started.\",\n",
      "  \"object\": \"fine-tune-event\"\n",
      "}\n",
      "{\n",
      "  \"created_at\": 1685720229,\n",
      "  \"level\": \"info\",\n",
      "  \"message\": \"Training started.\",\n",
      "  \"object\": \"fine-tune-event\"\n",
      "}\n",
      "{\n",
      "  \"created_at\": 1685720537,\n",
      "  \"level\": \"info\",\n",
      "  \"message\": \"Created results file: file-c0dfab7764ca4963998f16b938f3dfea\",\n",
      "  \"object\": \"fine-tune-event\"\n",
      "}\n",
      "{\n",
      "  \"created_at\": 1685721291,\n",
      "  \"level\": \"info\",\n",
      "  \"message\": \"Postprocessing started.\",\n",
      "  \"object\": \"fine-tune-event\"\n",
      "}\n",
      "{\n",
      "  \"created_at\": 1685722399,\n",
      "  \"level\": \"info\",\n",
      "  \"message\": \"Job succeeded.\",\n",
      "  \"object\": \"fine-tune-event\"\n",
      "}\n",
      "{\n",
      "  \"created_at\": 1685722424,\n",
      "  \"level\": \"info\",\n",
      "  \"message\": \"Completed results file: file-c0dfab7764ca4963998f16b938f3dfea\",\n",
      "  \"object\": \"fine-tune-event\"\n",
      "}\n",
      "{\n",
      "  \"created_at\": 1685722424,\n",
      "  \"level\": \"info\",\n",
      "  \"message\": \"Training hours billed: 0.250\",\n",
      "  \"object\": \"fine-tune-event\"\n",
      "}\n"
     ]
    }
   ],
   "source": [
    "events_gen = openai.FineTune.stream_events(id=\"ft-8e922209fe7a4298871a11f26da59ed1\")\n",
    "\n",
    "import time\n",
    "\n",
    "for i in range(1000):\n",
    "    try:\n",
    "        output = next(events_gen)\n",
    "        print(output)\n",
    "    except StopIteration:\n",
    "        if \"Training hours billed\" in output.__str__():\n",
    "            break\n",
    "        else:\n",
    "            time.sleep(10)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To get our fine-tuned model ID, we'll need to get the full list of models. Our model will be the last one in the models list:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<OpenAIObject list at 0x7fb2a0b7ecf0> JSON: {\n",
       "  \"data\": [\n",
       "    {\n",
       "      \"capabilities\": {\n",
       "        \"completion\": true,\n",
       "        \"embeddings\": false,\n",
       "        \"fine_tune\": true,\n",
       "        \"inference\": false,\n",
       "        \"scale_types\": [\n",
       "          \"manual\"\n",
       "        ]\n",
       "      },\n",
       "      \"created_at\": 1646092800,\n",
       "      \"deprecation\": {\n",
       "        \"fine_tune\": 1709251200,\n",
       "        \"inference\": 1709251200\n",
       "      },\n",
       "      \"id\": \"ada\",\n",
       "      \"lifecycle_status\": \"preview\",\n",
       "      \"object\": \"model\",\n",
       "      \"status\": \"succeeded\",\n",
       "      \"updated_at\": 1646092800\n",
       "    },\n",
       "    {\n",
       "      \"capabilities\": {\n",
       "        \"completion\": true,\n",
       "        \"embeddings\": false,\n",
       "        \"fine_tune\": true,\n",
       "        \"inference\": false,\n",
       "        \"scale_types\": [\n",
       "          \"manual\"\n",
       "        ]\n",
       "      },\n",
       "      \"created_at\": 1646092800,\n",
       "      \"deprecation\": {\n",
       "        \"fine_tune\": 1709251200,\n",
       "        \"inference\": 1709251200\n",
       "      },\n",
       "      \"id\": \"babbage\",\n",
       "      \"lifecycle_status\": \"preview\",\n",
       "      \"object\": \"model\",\n",
       "      \"status\": \"succeeded\",\n",
       "      \"updated_at\": 1646092800\n",
       "    },\n",
       "    {\n",
       "      \"capabilities\": {\n",
       "        \"completion\": true,\n",
       "        \"embeddings\": false,\n",
       "        \"fine_tune\": true,\n",
       "        \"inference\": false,\n",
       "        \"scale_types\": [\n",
       "          \"manual\"\n",
       "        ]\n",
       "      },\n",
       "      \"created_at\": 1646092800,\n",
       "      \"deprecation\": {\n",
       "        \"fine_tune\": 1709251200,\n",
       "        \"inference\": 1709251200\n",
       "      },\n",
       "      \"id\": \"curie\",\n",
       "      \"lifecycle_status\": \"preview\",\n",
       "      \"object\": \"model\",\n",
       "      \"status\": \"succeeded\",\n",
       "      \"updated_at\": 1646092800\n",
       "    },\n",
       "    {\n",
       "      \"capabilities\": {\n",
       "        \"completion\": true,\n",
       "        \"embeddings\": false,\n",
       "        \"fine_tune\": false,\n",
       "        \"inference\": false,\n",
       "        \"scale_types\": [\n",
       "          \"manual\"\n",
       "        ]\n",
       "      },\n",
       "      \"created_at\": 1646092800,\n",
       "      \"deprecation\": {\n",
       "        \"fine_tune\": 1709251200,\n",
       "        \"inference\": 1709251200\n",
       "      },\n",
       "      \"id\": \"davinci\",\n",
       "      \"lifecycle_status\": \"preview\",\n",
       "      \"object\": \"model\",\n",
       "      \"status\": \"succeeded\",\n",
       "      \"updated_at\": 1646092800\n",
       "    },\n",
       "    {\n",
       "      \"capabilities\": {\n",
       "        \"completion\": true,\n",
       "        \"embeddings\": false,\n",
       "        \"fine_tune\": false,\n",
       "        \"inference\": true,\n",
       "        \"scale_types\": [\n",
       "          \"standard\"\n",
       "        ]\n",
       "      },\n",
       "      \"created_at\": 1646092800,\n",
       "      \"deprecation\": {\n",
       "        \"fine_tune\": 1709251200,\n",
       "        \"inference\": 1709251200\n",
       "      },\n",
       "      \"id\": \"text-ada-001\",\n",
       "      \"lifecycle_status\": \"preview\",\n",
       "      \"object\": \"model\",\n",
       "      \"status\": \"succeeded\",\n",
       "      \"updated_at\": 1646092800\n",
       "    },\n",
       "    {\n",
       "      \"capabilities\": {\n",
       "        \"completion\": true,\n",
       "        \"embeddings\": false,\n",
       "        \"fine_tune\": false,\n",
       "        \"inference\": true,\n",
       "        \"scale_types\": [\n",
       "          \"standard\"\n",
       "        ]\n",
       "      },\n",
       "      \"created_at\": 1646092800,\n",
       "      \"deprecation\": {\n",
       "        \"fine_tune\": 1709251200,\n",
       "        \"inference\": 1709251200\n",
       "      },\n",
       "      \"id\": \"text-babbage-001\",\n",
       "      \"lifecycle_status\": \"preview\",\n",
       "      \"object\": \"model\",\n",
       "      \"status\": \"succeeded\",\n",
       "      \"updated_at\": 1646092800\n",
       "    },\n",
       "    {\n",
       "      \"capabilities\": {\n",
       "        \"completion\": true,\n",
       "        \"embeddings\": false,\n",
       "        \"fine_tune\": false,\n",
       "        \"inference\": true,\n",
       "        \"scale_types\": [\n",
       "          \"standard\"\n",
       "        ]\n",
       "      },\n",
       "      \"created_at\": 1646092800,\n",
       "      \"deprecation\": {\n",
       "        \"fine_tune\": 1709251200,\n",
       "        \"inference\": 1709251200\n",
       "      },\n",
       "      \"id\": \"text-curie-001\",\n",
       "      \"lifecycle_status\": \"generally-available\",\n",
       "      \"object\": \"model\",\n",
       "      \"status\": \"succeeded\",\n",
       "      \"updated_at\": 1646092800\n",
       "    },\n",
       "    {\n",
       "      \"capabilities\": {\n",
       "        \"completion\": true,\n",
       "        \"embeddings\": false,\n",
       "        \"fine_tune\": false,\n",
       "        \"inference\": true,\n",
       "        \"scale_types\": [\n",
       "          \"standard\"\n",
       "        ]\n",
       "      },\n",
       "      \"created_at\": 1646092800,\n",
       "      \"deprecation\": {\n",
       "        \"fine_tune\": 1709251200,\n",
       "        \"inference\": 1709251200\n",
       "      },\n",
       "      \"id\": \"text-davinci-001\",\n",
       "      \"lifecycle_status\": \"preview\",\n",
       "      \"object\": \"model\",\n",
       "      \"status\": \"succeeded\",\n",
       "      \"updated_at\": 1646092800\n",
       "    },\n",
       "    {\n",
       "      \"capabilities\": {\n",
       "        \"completion\": true,\n",
       "        \"embeddings\": false,\n",
       "        \"fine_tune\": false,\n",
       "        \"inference\": true,\n",
       "        \"scale_types\": [\n",
       "          \"standard\"\n",
       "        ]\n",
       "      },\n",
       "      \"created_at\": 1642809600,\n",
       "      \"deprecation\": {\n",
       "        \"inference\": 1704067200\n",
       "      },\n",
       "      \"id\": \"text-davinci-002\",\n",
       "      \"lifecycle_status\": \"generally-available\",\n",
       "      \"object\": \"model\",\n",
       "      \"status\": \"succeeded\",\n",
       "      \"updated_at\": 1642809600\n",
       "    },\n",
       "    {\n",
       "      \"capabilities\": {\n",
       "        \"completion\": true,\n",
       "        \"embeddings\": false,\n",
       "        \"fine_tune\": false,\n",
       "        \"inference\": true,\n",
       "        \"scale_types\": [\n",
       "          \"standard\"\n",
       "        ]\n",
       "      },\n",
       "      \"created_at\": 1678320000,\n",
       "      \"deprecation\": {\n",
       "        \"inference\": 1690848000\n",
       "      },\n",
       "      \"id\": \"gpt-35-turbo\",\n",
       "      \"lifecycle_status\": \"preview\",\n",
       "      \"object\": \"model\",\n",
       "      \"status\": \"succeeded\",\n",
       "      \"updated_at\": 1678320000\n",
       "    },\n",
       "    {\n",
       "      \"capabilities\": {\n",
       "        \"completion\": true,\n",
       "        \"embeddings\": false,\n",
       "        \"fine_tune\": false,\n",
       "        \"inference\": true,\n",
       "        \"scale_types\": [\n",
       "          \"standard\"\n",
       "        ]\n",
       "      },\n",
       "      \"created_at\": 1664496000,\n",
       "      \"deprecation\": {\n",
       "        \"inference\": 1727654400\n",
       "      },\n",
       "      \"id\": \"text-davinci-003\",\n",
       "      \"lifecycle_status\": \"preview\",\n",
       "      \"object\": \"model\",\n",
       "      \"status\": \"succeeded\",\n",
       "      \"updated_at\": 1664496000\n",
       "    },\n",
       "    {\n",
       "      \"capabilities\": {\n",
       "        \"completion\": true,\n",
       "        \"embeddings\": false,\n",
       "        \"fine_tune\": false,\n",
       "        \"inference\": false,\n",
       "        \"scale_types\": [\n",
       "          \"standard\"\n",
       "        ]\n",
       "      },\n",
       "      \"created_at\": 1659398400,\n",
       "      \"deprecation\": {\n",
       "        \"fine_tune\": 1709251200,\n",
       "        \"inference\": 1722556800\n",
       "      },\n",
       "      \"id\": \"text-davinci-fine-tune-002\",\n",
       "      \"lifecycle_status\": \"preview\",\n",
       "      \"object\": \"model\",\n",
       "      \"status\": \"succeeded\",\n",
       "      \"updated_at\": 1659398400\n",
       "    },\n",
       "    {\n",
       "      \"capabilities\": {\n",
       "        \"completion\": true,\n",
       "        \"embeddings\": false,\n",
       "        \"fine_tune\": false,\n",
       "        \"inference\": true,\n",
       "        \"scale_types\": [\n",
       "          \"standard\"\n",
       "        ]\n",
       "      },\n",
       "      \"created_at\": 1642809600,\n",
       "      \"deprecation\": {\n",
       "        \"fine_tune\": 1704067200,\n",
       "        \"inference\": 1704067200\n",
       "      },\n",
       "      \"id\": \"code-cushman-001\",\n",
       "      \"lifecycle_status\": \"preview\",\n",
       "      \"object\": \"model\",\n",
       "      \"status\": \"succeeded\",\n",
       "      \"updated_at\": 1642809600\n",
       "    },\n",
       "    {\n",
       "      \"capabilities\": {\n",
       "        \"completion\": true,\n",
       "        \"embeddings\": false,\n",
       "        \"fine_tune\": false,\n",
       "        \"inference\": false,\n",
       "        \"scale_types\": [\n",
       "          \"manual\"\n",
       "        ]\n",
       "      },\n",
       "      \"created_at\": 1677456000,\n",
       "      \"deprecation\": {\n",
       "        \"fine_tune\": 1708992000,\n",
       "        \"inference\": 1740614400\n",
       "      },\n",
       "      \"id\": \"code-cushman-fine-tune-002\",\n",
       "      \"lifecycle_status\": \"preview\",\n",
       "      \"object\": \"model\",\n",
       "      \"status\": \"succeeded\",\n",
       "      \"updated_at\": 1677456000\n",
       "    },\n",
       "    {\n",
       "      \"capabilities\": {\n",
       "        \"completion\": true,\n",
       "        \"embeddings\": false,\n",
       "        \"fine_tune\": false,\n",
       "        \"inference\": true,\n",
       "        \"scale_types\": [\n",
       "          \"standard\"\n",
       "        ]\n",
       "      },\n",
       "      \"created_at\": 1657497600,\n",
       "      \"deprecation\": {\n",
       "        \"inference\": 1720656000\n",
       "      },\n",
       "      \"id\": \"code-davinci-002\",\n",
       "      \"lifecycle_status\": \"preview\",\n",
       "      \"object\": \"model\",\n",
       "      \"status\": \"succeeded\",\n",
       "      \"updated_at\": 1657497600\n",
       "    },\n",
       "    {\n",
       "      \"capabilities\": {\n",
       "        \"completion\": true,\n",
       "        \"embeddings\": false,\n",
       "        \"fine_tune\": false,\n",
       "        \"inference\": false,\n",
       "        \"scale_types\": [\n",
       "          \"standard\"\n",
       "        ]\n",
       "      },\n",
       "      \"created_at\": 1662508800,\n",
       "      \"deprecation\": {\n",
       "        \"fine_tune\": 1694044800,\n",
       "        \"inference\": 1725667200\n",
       "      },\n",
       "      \"id\": \"code-davinci-fine-tune-002\",\n",
       "      \"lifecycle_status\": \"generally-available\",\n",
       "      \"object\": \"model\",\n",
       "      \"status\": \"succeeded\",\n",
       "      \"updated_at\": 1662508800\n",
       "    },\n",
       "    {\n",
       "      \"capabilities\": {\n",
       "        \"completion\": false,\n",
       "        \"embeddings\": true,\n",
       "        \"fine_tune\": false,\n",
       "        \"inference\": true,\n",
       "        \"scale_types\": [\n",
       "          \"standard\"\n",
       "        ]\n",
       "      },\n",
       "      \"created_at\": 1653004800,\n",
       "      \"deprecation\": {\n",
       "        \"inference\": 1716163200\n",
       "      },\n",
       "      \"id\": \"text-similarity-ada-001\",\n",
       "      \"lifecycle_status\": \"preview\",\n",
       "      \"object\": \"model\",\n",
       "      \"status\": \"succeeded\",\n",
       "      \"updated_at\": 1653004800\n",
       "    },\n",
       "    {\n",
       "      \"capabilities\": {\n",
       "        \"completion\": false,\n",
       "        \"embeddings\": true,\n",
       "        \"fine_tune\": false,\n",
       "        \"inference\": true,\n",
       "        \"scale_types\": [\n",
       "          \"standard\"\n",
       "        ]\n",
       "      },\n",
       "      \"created_at\": 1653004800,\n",
       "      \"deprecation\": {\n",
       "        \"inference\": 1716163200\n",
       "      },\n",
       "      \"id\": \"text-similarity-babbage-001\",\n",
       "      \"lifecycle_status\": \"preview\",\n",
       "      \"object\": \"model\",\n",
       "      \"status\": \"succeeded\",\n",
       "      \"updated_at\": 1653004800\n",
       "    },\n",
       "    {\n",
       "      \"capabilities\": {\n",
       "        \"completion\": false,\n",
       "        \"embeddings\": true,\n",
       "        \"fine_tune\": false,\n",
       "        \"inference\": true,\n",
       "        \"scale_types\": [\n",
       "          \"standard\"\n",
       "        ]\n",
       "      },\n",
       "      \"created_at\": 1653004800,\n",
       "      \"deprecation\": {\n",
       "        \"inference\": 1716163200\n",
       "      },\n",
       "      \"id\": \"text-similarity-curie-001\",\n",
       "      \"lifecycle_status\": \"preview\",\n",
       "      \"object\": \"model\",\n",
       "      \"status\": \"succeeded\",\n",
       "      \"updated_at\": 1653004800\n",
       "    },\n",
       "    {\n",
       "      \"capabilities\": {\n",
       "        \"completion\": false,\n",
       "        \"embeddings\": true,\n",
       "        \"fine_tune\": false,\n",
       "        \"inference\": true,\n",
       "        \"scale_types\": [\n",
       "          \"standard\"\n",
       "        ]\n",
       "      },\n",
       "      \"created_at\": 1653004800,\n",
       "      \"deprecation\": {\n",
       "        \"inference\": 1716163200\n",
       "      },\n",
       "      \"id\": \"text-similarity-davinci-001\",\n",
       "      \"lifecycle_status\": \"preview\",\n",
       "      \"object\": \"model\",\n",
       "      \"status\": \"succeeded\",\n",
       "      \"updated_at\": 1653004800\n",
       "    },\n",
       "    {\n",
       "      \"capabilities\": {\n",
       "        \"completion\": false,\n",
       "        \"embeddings\": true,\n",
       "        \"fine_tune\": false,\n",
       "        \"inference\": true,\n",
       "        \"scale_types\": [\n",
       "          \"standard\"\n",
       "        ]\n",
       "      },\n",
       "      \"created_at\": 1653004800,\n",
       "      \"deprecation\": {\n",
       "        \"inference\": 1716163200\n",
       "      },\n",
       "      \"id\": \"text-search-ada-doc-001\",\n",
       "      \"lifecycle_status\": \"preview\",\n",
       "      \"object\": \"model\",\n",
       "      \"status\": \"succeeded\",\n",
       "      \"updated_at\": 1653004800\n",
       "    },\n",
       "    {\n",
       "      \"capabilities\": {\n",
       "        \"completion\": false,\n",
       "        \"embeddings\": true,\n",
       "        \"fine_tune\": false,\n",
       "        \"inference\": true,\n",
       "        \"scale_types\": [\n",
       "          \"standard\"\n",
       "        ]\n",
       "      },\n",
       "      \"created_at\": 1653004800,\n",
       "      \"deprecation\": {\n",
       "        \"inference\": 1716163200\n",
       "      },\n",
       "      \"id\": \"text-search-ada-query-001\",\n",
       "      \"lifecycle_status\": \"preview\",\n",
       "      \"object\": \"model\",\n",
       "      \"status\": \"succeeded\",\n",
       "      \"updated_at\": 1653004800\n",
       "    },\n",
       "    {\n",
       "      \"capabilities\": {\n",
       "        \"completion\": false,\n",
       "        \"embeddings\": true,\n",
       "        \"fine_tune\": false,\n",
       "        \"inference\": true,\n",
       "        \"scale_types\": [\n",
       "          \"standard\"\n",
       "        ]\n",
       "      },\n",
       "      \"created_at\": 1653004800,\n",
       "      \"deprecation\": {\n",
       "        \"inference\": 1716163200\n",
       "      },\n",
       "      \"id\": \"text-search-babbage-doc-001\",\n",
       "      \"lifecycle_status\": \"preview\",\n",
       "      \"object\": \"model\",\n",
       "      \"status\": \"succeeded\",\n",
       "      \"updated_at\": 1653004800\n",
       "    },\n",
       "    {\n",
       "      \"capabilities\": {\n",
       "        \"completion\": false,\n",
       "        \"embeddings\": true,\n",
       "        \"fine_tune\": false,\n",
       "        \"inference\": true,\n",
       "        \"scale_types\": [\n",
       "          \"standard\"\n",
       "        ]\n",
       "      },\n",
       "      \"created_at\": 1653004800,\n",
       "      \"deprecation\": {\n",
       "        \"inference\": 1716163200\n",
       "      },\n",
       "      \"id\": \"text-search-babbage-query-001\",\n",
       "      \"lifecycle_status\": \"preview\",\n",
       "      \"object\": \"model\",\n",
       "      \"status\": \"succeeded\",\n",
       "      \"updated_at\": 1653004800\n",
       "    },\n",
       "    {\n",
       "      \"capabilities\": {\n",
       "        \"completion\": false,\n",
       "        \"embeddings\": true,\n",
       "        \"fine_tune\": false,\n",
       "        \"inference\": true,\n",
       "        \"scale_types\": [\n",
       "          \"standard\"\n",
       "        ]\n",
       "      },\n",
       "      \"created_at\": 1653004800,\n",
       "      \"deprecation\": {\n",
       "        \"inference\": 1716163200\n",
       "      },\n",
       "      \"id\": \"text-search-curie-doc-001\",\n",
       "      \"lifecycle_status\": \"preview\",\n",
       "      \"object\": \"model\",\n",
       "      \"status\": \"succeeded\",\n",
       "      \"updated_at\": 1653004800\n",
       "    },\n",
       "    {\n",
       "      \"capabilities\": {\n",
       "        \"completion\": false,\n",
       "        \"embeddings\": true,\n",
       "        \"fine_tune\": false,\n",
       "        \"inference\": true,\n",
       "        \"scale_types\": [\n",
       "          \"standard\"\n",
       "        ]\n",
       "      },\n",
       "      \"created_at\": 1653004800,\n",
       "      \"deprecation\": {\n",
       "        \"inference\": 1716163200\n",
       "      },\n",
       "      \"id\": \"text-search-curie-query-001\",\n",
       "      \"lifecycle_status\": \"preview\",\n",
       "      \"object\": \"model\",\n",
       "      \"status\": \"succeeded\",\n",
       "      \"updated_at\": 1653004800\n",
       "    },\n",
       "    {\n",
       "      \"capabilities\": {\n",
       "        \"completion\": false,\n",
       "        \"embeddings\": true,\n",
       "        \"fine_tune\": false,\n",
       "        \"inference\": true,\n",
       "        \"scale_types\": [\n",
       "          \"standard\"\n",
       "        ]\n",
       "      },\n",
       "      \"created_at\": 1653004800,\n",
       "      \"deprecation\": {\n",
       "        \"inference\": 1716163200\n",
       "      },\n",
       "      \"id\": \"text-search-davinci-doc-001\",\n",
       "      \"lifecycle_status\": \"preview\",\n",
       "      \"object\": \"model\",\n",
       "      \"status\": \"succeeded\",\n",
       "      \"updated_at\": 1653004800\n",
       "    },\n",
       "    {\n",
       "      \"capabilities\": {\n",
       "        \"completion\": false,\n",
       "        \"embeddings\": true,\n",
       "        \"fine_tune\": false,\n",
       "        \"inference\": true,\n",
       "        \"scale_types\": [\n",
       "          \"standard\"\n",
       "        ]\n",
       "      },\n",
       "      \"created_at\": 1653004800,\n",
       "      \"deprecation\": {\n",
       "        \"inference\": 1716163200\n",
       "      },\n",
       "      \"id\": \"text-search-davinci-query-001\",\n",
       "      \"lifecycle_status\": \"preview\",\n",
       "      \"object\": \"model\",\n",
       "      \"status\": \"succeeded\",\n",
       "      \"updated_at\": 1653004800\n",
       "    },\n",
       "    {\n",
       "      \"capabilities\": {\n",
       "        \"completion\": false,\n",
       "        \"embeddings\": true,\n",
       "        \"fine_tune\": false,\n",
       "        \"inference\": true,\n",
       "        \"scale_types\": [\n",
       "          \"standard\"\n",
       "        ]\n",
       "      },\n",
       "      \"created_at\": 1653004800,\n",
       "      \"deprecation\": {\n",
       "        \"inference\": 1716163200\n",
       "      },\n",
       "      \"id\": \"code-search-ada-code-001\",\n",
       "      \"lifecycle_status\": \"preview\",\n",
       "      \"object\": \"model\",\n",
       "      \"status\": \"succeeded\",\n",
       "      \"updated_at\": 1653004800\n",
       "    },\n",
       "    {\n",
       "      \"capabilities\": {\n",
       "        \"completion\": false,\n",
       "        \"embeddings\": true,\n",
       "        \"fine_tune\": false,\n",
       "        \"inference\": true,\n",
       "        \"scale_types\": [\n",
       "          \"standard\"\n",
       "        ]\n",
       "      },\n",
       "      \"created_at\": 1653004800,\n",
       "      \"deprecation\": {\n",
       "        \"inference\": 1716163200\n",
       "      },\n",
       "      \"id\": \"code-search-ada-text-001\",\n",
       "      \"lifecycle_status\": \"preview\",\n",
       "      \"object\": \"model\",\n",
       "      \"status\": \"succeeded\",\n",
       "      \"updated_at\": 1653004800\n",
       "    },\n",
       "    {\n",
       "      \"capabilities\": {\n",
       "        \"completion\": false,\n",
       "        \"embeddings\": true,\n",
       "        \"fine_tune\": false,\n",
       "        \"inference\": true,\n",
       "        \"scale_types\": [\n",
       "          \"standard\"\n",
       "        ]\n",
       "      },\n",
       "      \"created_at\": 1653004800,\n",
       "      \"deprecation\": {\n",
       "        \"inference\": 1716163200\n",
       "      },\n",
       "      \"id\": \"code-search-babbage-code-001\",\n",
       "      \"lifecycle_status\": \"preview\",\n",
       "      \"object\": \"model\",\n",
       "      \"status\": \"succeeded\",\n",
       "      \"updated_at\": 1653004800\n",
       "    },\n",
       "    {\n",
       "      \"capabilities\": {\n",
       "        \"completion\": false,\n",
       "        \"embeddings\": true,\n",
       "        \"fine_tune\": false,\n",
       "        \"inference\": true,\n",
       "        \"scale_types\": [\n",
       "          \"standard\"\n",
       "        ]\n",
       "      },\n",
       "      \"created_at\": 1653004800,\n",
       "      \"deprecation\": {\n",
       "        \"inference\": 1716163200\n",
       "      },\n",
       "      \"id\": \"code-search-babbage-text-001\",\n",
       "      \"lifecycle_status\": \"preview\",\n",
       "      \"object\": \"model\",\n",
       "      \"status\": \"succeeded\",\n",
       "      \"updated_at\": 1653004800\n",
       "    },\n",
       "    {\n",
       "      \"capabilities\": {\n",
       "        \"completion\": false,\n",
       "        \"embeddings\": true,\n",
       "        \"fine_tune\": false,\n",
       "        \"inference\": true,\n",
       "        \"scale_types\": [\n",
       "          \"standard\"\n",
       "        ]\n",
       "      },\n",
       "      \"created_at\": 1675296000,\n",
       "      \"deprecation\": {\n",
       "        \"inference\": 1738454400\n",
       "      },\n",
       "      \"id\": \"text-embedding-ada-002\",\n",
       "      \"lifecycle_status\": \"preview\",\n",
       "      \"object\": \"model\",\n",
       "      \"status\": \"succeeded\",\n",
       "      \"updated_at\": 1675296000\n",
       "    },\n",
       "    {\n",
       "      \"capabilities\": {\n",
       "        \"completion\": false,\n",
       "        \"embeddings\": true,\n",
       "        \"fine_tune\": false,\n",
       "        \"inference\": true,\n",
       "        \"scale_types\": [\n",
       "          \"standard\"\n",
       "        ]\n",
       "      },\n",
       "      \"created_at\": 1680480000,\n",
       "      \"deprecation\": {\n",
       "        \"inference\": 1743638400\n",
       "      },\n",
       "      \"id\": \"text-embedding-ada-002\",\n",
       "      \"lifecycle_status\": \"preview\",\n",
       "      \"object\": \"model\",\n",
       "      \"status\": \"succeeded\",\n",
       "      \"updated_at\": 1680480000\n",
       "    },\n",
       "    {\n",
       "      \"capabilities\": {\n",
       "        \"completion\": true,\n",
       "        \"embeddings\": false,\n",
       "        \"fine_tune\": false,\n",
       "        \"inference\": true,\n",
       "        \"scale_types\": [\n",
       "          \"standard\"\n",
       "        ]\n",
       "      },\n",
       "      \"created_at\": 1685719688,\n",
       "      \"deprecation\": {\n",
       "        \"inference\": 1748878088\n",
       "      },\n",
       "      \"fine_tune\": \"ft-8e922209fe7a4298871a11f26da59ed1\",\n",
       "      \"id\": \"curie.ft-8e922209fe7a4298871a11f26da59ed1\",\n",
       "      \"lifecycle_status\": \"preview\",\n",
       "      \"model\": \"curie\",\n",
       "      \"object\": \"model\",\n",
       "      \"status\": \"succeeded\",\n",
       "      \"updated_at\": 1685722424\n",
       "    }\n",
       "  ],\n",
       "  \"object\": \"list\"\n",
       "}"
      ]
     },
     "execution_count": null,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "openai.Model.list()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tuned_model_id = \"curie.ft-8e922209fe7a4298871a11f26da59ed1\""
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's now test the newly fine-tuned model. To test the model, we'll use some completely fresh data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.google.colaboratory.intrinsic+json": {
       "type": "string"
      },
      "text/plain": [
       "'CULTURE AND ARTS'"
      ]
     },
     "execution_count": null,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sample_text = (\n",
    "    \"'Lost Daughter,' 'Drive My Car' Win Top Prizes At Independent Spirit Awards. The show's hosts\"\n",
    "    \" and honorary chair also spoke about the war in Ukraine.[PROMPT_STOP].\"\n",
    ")\n",
    "# sample_text2 = \"Most Of Beijing To Be Tested For COVID-19 Amid Lockdown Worry. While only 70 cases have been found since the outbreak surfaced, authorities have followed a “zero-COVID” approach to try to prevent a further spread of the virus.\"\n",
    "\n",
    "tuned_model_class = classify_text(content=sample_text, model=tuned_model_id)\n",
    "tuned_model_class"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's create a new batch of assets in our project and check how well the fine-tuned model is doing against *ground truth*. To make it simpler, we'll take a random set of 100 new assets and we'll try to benchmark it again our *ground truth*.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import random\n",
    "\n",
    "content_dict_new = dict()\n",
    "counter = 801  # Start at 801 to assign new external ids to an existing project\n",
    "\n",
    "with open(\"curie2.txt\") as cur:\n",
    "    for e in enumerate(cur, 801):\n",
    "        entry = e[1].split(\"|\")\n",
    "        content_dict_new[counter] = (entry[0], entry[1].replace(\"\\n\", \"\"))\n",
    "        counter += 1\n",
    "\n",
    "hundred_random_entries = random.sample(range(801, 801 + len(content_dict_new)), 100)\n",
    "\n",
    "content_array_new = [\n",
    "    content_dict_new[i][0] for i in content_dict_new if i in hundred_random_entries\n",
    "]\n",
    "categories_array_new = [\n",
    "    content_dict_new[i][1] for i in content_dict_new if i in hundred_random_entries\n",
    "]\n",
    "external_id_array_new = [f\"text_{i}\" for i in range(801, 901)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "kili.append_many_to_dataset(\n",
    "    project_id=project_id,\n",
    "    content_array=content_array_new,\n",
    "    external_id_array=external_id_array_new,\n",
    ")"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Generating predictions on new assets using the fine-tuned model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "predicted_classes_dict_new = dict()\n",
    "\n",
    "for entry in content_dict_new:\n",
    "    if int(entry) in hundred_random_entries:\n",
    "        content = content_dict_new[entry][0]\n",
    "        try:\n",
    "            predicted_class = classify_text(content=content, model=tuned_model_id)\n",
    "        except Exception as e:\n",
    "            print(f\"getting predictions on entry # {entry} failed.\\nException: {e}\")\n",
    "            predicted_class = \"UNABLE_TO_CLASSIFY\"\n",
    "            print(predicted_class)\n",
    "\n",
    "        predicted_classes_dict_new[entry] = predicted_class"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now we add our predicted assets to our newly-added Kili assets:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "inference_cat_array_new = list()\n",
    "\n",
    "for entry in predicted_classes_dict_new:\n",
    "    inference_cat_array_new.append(predicted_classes_dict_new[entry])\n",
    "\n",
    "kili.append_labels(\n",
    "    json_response_array=[\n",
    "        {\n",
    "            \"CLASSIFICATION_JOB\": {\n",
    "                \"categories\": [\n",
    "                    {\n",
    "                        \"confidence\": 100,\n",
    "                        \"name\": i.replace(\" \", \"_\").replace(\"&\", \"AND\").replace(\"\\n\", \"\"),\n",
    "                    }\n",
    "                ]\n",
    "            }\n",
    "        }\n",
    "        for i in inference_cat_array_new\n",
    "    ],\n",
    "    model_name=\"Curie\",\n",
    "    label_type=\"INFERENCE\",\n",
    "    project_id=project_id,\n",
    "    asset_external_id_array=external_id_array_new,\n",
    ")"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Summary"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's simulate human labeling now, to get ground truth labels:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "kili.append_labels(\n",
    "    json_response_array=[\n",
    "        {\n",
    "            \"CLASSIFICATION_JOB\": {\n",
    "                \"categories\": [\n",
    "                    {\n",
    "                        \"confidence\": 100,\n",
    "                        \"name\": i.replace(\" \", \"_\").replace(\"&\", \"AND\").replace(\"\\n\", \"\"),\n",
    "                    }\n",
    "                ]\n",
    "            }\n",
    "        }\n",
    "        for i in categories_array_new\n",
    "    ],\n",
    "    model_name=\"Ground Truth\",\n",
    "    label_type=\"DEFAULT\",\n",
    "    project_id=project_id,\n",
    "    asset_external_id_array=external_id_array_new,\n",
    ")"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's calculate the IoU score for the new 100 assets:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.19"
      ]
     },
     "execution_count": null,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "low_scores = kili.count_assets(\n",
    "    project_id=project_id, inference_mark_lte=0.51, external_id_strictly_in=external_id_array_new\n",
    ")\n",
    "\n",
    "\n",
    "score_after_finetuning = (len(content_array) - low_scores) / len(content_array)\n",
    "score_after_finetuning"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In our case, the original score used to be ~16, so we may be technically heading in the right direction, but properly fine-tuning the model would probably require more samples and a few more iterations. You'd need to label another ~800 assets, export them from Kili, then save them to the OpenAI instance, fine-tune some more, and see if it helps."
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "if you want to further fine-tune your fine-tuned model model, you need to specify that in code:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "kili_ft = openai.FineTune.create(\n",
    "    training_file=\"file-16879c80ed3b4ae3a5fe3932a0c30ff6\", model=tuned_model_id\n",
    ")\n",
    "\n",
    "kili_ft"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
