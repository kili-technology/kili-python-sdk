{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Kili Tutorial: Import OCR pre-annotations in Kili\n",
    "\n",
    "In this tutorial we will see how to import OCR pre-annotations in Kili using [Google vision API](https://cloud.google.com/vision/docs/ocr). Pre-annotating your data will allow you to gain a significant time when performing [OCR](https://cloud.kili-technology.com/docs/text-pdf-interfaces/image-transcription-ocr/#docsNav) using Kili. \n",
    "\n",
    "The data we use comes from [The Street View Text Dataset](http://www.iapr-tc11.org/mediawiki/index.php?title=The_Street_View_Text_Dataset)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Loading an image from The Street View Dataset in Kili\n",
    "\n",
    "You can obtain the image for this tutorial using the following link (https://drive.google.com/uc?export=view&id=1ceNwCgLwIyyjPwU42xIoz6mMT3enLewW):\n",
    "<img src=\"https://drive.google.com/uc?export=view&id=1ceNwCgLwIyyjPwU42xIoz6mMT3enLewW\" width=\"800\">\n",
    "\n",
    "We will use the Google to perform an optical caracter recognition of the different texts in the image.\n",
    "\n",
    "We can now create the interface we will be using in our project. For OCR, the interface to use is a classification jobs with nested transcriptions for each category."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "json_interface =  {\n",
    "    \"jobs\": {\n",
    "        \"JOB_0\": {\n",
    "            \"mlTask\": \"OBJECT_DETECTION\",\n",
    "            \"tools\": [\n",
    "                \"rectangle\"\n",
    "            ],\n",
    "            \"instruction\": \"Categories\",\n",
    "            \"required\": 1,\n",
    "            \"isChild\": False,\n",
    "            \"content\": {\n",
    "                \"categories\": {\n",
    "                    \"STORE_INFORMATIONS\": {\n",
    "                        \"name\": \"Store informations\",\n",
    "                        \"children\": [\n",
    "                            \"JOB_1\"\n",
    "                        ]\n",
    "                    },\n",
    "                    \"PRODUCTS\": {\n",
    "                        \"name\": \"Products\",\n",
    "                        \"children\": [\n",
    "                            \"JOB_2\"\n",
    "                        ]\n",
    "                    }\n",
    "                },\n",
    "                \"input\": \"radio\"\n",
    "            }\n",
    "        },\n",
    "        \"JOB_1\": {\n",
    "            \"mlTask\": \"TRANSCRIPTION\",\n",
    "            \"instruction\": \"Transcription of store informations\",\n",
    "            \"required\": 1,\n",
    "            \"isChild\": True\n",
    "        },\n",
    "        \"JOB_2\": {\n",
    "            \"mlTask\": \"TRANSCRIPTION\",\n",
    "            \"instruction\": \"Transcription of products\",\n",
    "            \"required\": 1,\n",
    "            \"isChild\": True\n",
    "        }\n",
    "    }\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "from google.oauth2 import service_account\n",
    "from kili.authentication import KiliAuth\n",
    "from kili.playground import Playground"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'id': 'ckhc6pwtr020v0785m7adiare',\n",
       " 'jsonInterface': {'jobs': {'JOB_0': {'mlTask': 'OBJECT_DETECTION',\n",
       "    'tools': ['rectangle'],\n",
       "    'instruction': 'Categories',\n",
       "    'required': 1,\n",
       "    'isChild': False,\n",
       "    'content': {'categories': {'STORE_INFORMATIONS': {'name': 'Store informations',\n",
       "       'children': ['JOB_1']},\n",
       "      'PRODUCTS': {'name': 'Products', 'children': ['JOB_2']}},\n",
       "     'input': 'radio'}},\n",
       "   'JOB_1': {'mlTask': 'TRANSCRIPTION',\n",
       "    'instruction': 'Transcription of store informations',\n",
       "    'required': 1,\n",
       "    'isChild': True},\n",
       "   'JOB_2': {'mlTask': 'TRANSCRIPTION',\n",
       "    'instruction': 'Transcription of products',\n",
       "    'required': 1,\n",
       "    'isChild': True}}},\n",
       " 'title': 'Street text annotation',\n",
       " 'roles': [{'user': {'id': 'ckbglsw2tg6fj08601p961pqj',\n",
       "    'email': 'paul@kili-technology.com'},\n",
       "   'role': 'ADMIN'}]}"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Authenticate to Kili Technology\n",
    "api_key = os.getenv('KILI_USER_API_KEY')\n",
    "api_endpoint = os.getenv('KILI_API_ENDPOINT')\n",
    "kauth = KiliAuth(api_key=api_key, api_endpoint=api_endpoint)\n",
    "playground = Playground(kauth)\n",
    "\n",
    "# Create an OCR project\n",
    "project = playground.create_empty_project(user_id=kauth.user_id)\n",
    "project_id = project['id']\n",
    "\n",
    "playground.update_properties_in_project(\n",
    "    project_id=project_id,\n",
    "    description='OCR street view',\n",
    "    input_type='IMAGE',\n",
    "    json_interface=json_interface,\n",
    "    title='Street text annotation'\n",
    ")\n",
    "users = playground.users(api_key=api_key, fields=['email'])\n",
    "playground.append_to_roles(\n",
    "    project_id=project_id,\n",
    "    user_email=users[0]['email'],\n",
    "    role='ADMIN'\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Creating OCR annotations using Google Vision API\n",
    "\n",
    "We will now see how to perform OCR on our image using Google Vision API.\n",
    "\n",
    "First you will need to create an account on https://cloud.google.com:\n",
    "  - create a project (or use an exesting one)\n",
    "  - then go to  \"API and services\"/library and serach for \"vision API\"\n",
    "  - activate the API for your project (You might need to associate facturation information if you haven't already)\n",
    "  \n",
    "Now that the API is activated we will need to get an API in order to call later in our project:\n",
    "  - go to \"API and services\"/indentification\n",
    "  - create a service account with authorization to use the vision API\n",
    "  \n",
    "On the service account details page:\n",
    "  - click on add a key\n",
    "  - download the key using json format\n",
    "  - place the key in the folder of the project\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Install google cloud api using: `pip install --upgrade google-cloud-storage`\n",
    "\n",
    "We can now start to code to add ocr annotations to the asset metadata !"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Declare the path to your API_KEY\n",
    "PATH_API_KEY ="
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "def implicit():\n",
    "    from google.cloud import storage\n",
    "\n",
    "    # If you don't specify credentials when constructing the client, the\n",
    "    # client library will look for credentials in the environment.\n",
    "    storage_client = storage.Client()\n",
    "\n",
    "    # Make an authenticated API request\n",
    "    buckets = list(storage_client.list_buckets())\n",
    "    print(buckets)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "def detect_text(path):\n",
    "    \"\"\"Detects text in the file.\"\"\"\n",
    "    from google.cloud import vision\n",
    "    import io\n",
    "    credentials = service_account.Credentials.from_service_account_file(PATH_API_KEY)\n",
    "    client = vision.ImageAnnotatorClient(credentials=credentials)\n",
    "\n",
    "    with io.open(path, 'rb') as image_file:\n",
    "        content = image_file.read()\n",
    "\n",
    "    image = vision.types.Image(content=content)\n",
    "\n",
    "    response = client.text_detection(image=image)\n",
    "    texts = response.text_annotations\n",
    "    textAnnotations = []\n",
    "\n",
    "    for text in texts:\n",
    "        \n",
    "        vertices = [{\"x\": vertex.x, \"y\": vertex.y}\n",
    "                    for vertex in text.bounding_poly.vertices]\n",
    "        \n",
    "        tmp = {\"description\": text.description,\n",
    "               \"boundingPoly\": {\n",
    "                      \"vertices\": vertices,\n",
    "                  },\n",
    "              }\n",
    "        \n",
    "        textAnnotations.append(tmp)\n",
    "        \n",
    "    return textAnnotations\n",
    "\n",
    "    if response.error.message:\n",
    "        raise Exception(\n",
    "            '{}\\nFor more info on error messages, check: '\n",
    "            'https://cloud.google.com/apis/design/errors'.format(\n",
    "                response.error.message))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'bytes'>\n"
     ]
    }
   ],
   "source": [
    "textAnnotations = detect_text(PATH_TO_IMG) "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We now need to format the results of the OCR to fit in Kili's asset metadata"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "IMG_WIDTH = 1680\n",
    "IMG_HEIGHT = 1050\n",
    "\n",
    "fullTextAnnotations = {\n",
    "    \"fullTextAnnotation\": {\n",
    "        \"pages\": [{\"height\":IMG_HEIGHT , \"width\": IMG_WIDTH}],}, \"textAnnotations\": textAnnotations\n",
    "    }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'id': 'ckhc6pwtr020v0785m7adiare'}"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Add asset with pre-annotations to project\n",
    "\n",
    "external_id = 'store'\n",
    "content = 'https://drive.google.com/uc?export=view&id=1ceNwCgLwIyyjPwU42xIoz6mMT3enLewW'\n",
    "json_metadata = fullTextAnnotations\n",
    "\n",
    "playground.append_many_to_dataset(\n",
    "    project_id=project_id,\n",
    "    content_array=[content],\n",
    "    external_id_array=[external_id],\n",
    "    json_metadata_array=[json_metadata]\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Annotate in Kili\n",
    "\n",
    "You can now annotate your images and you will se the text automatically extracted.\n",
    "\n",
    "<img src=\"https://raw.githubusercontent.com/kili-technology/kili-playground/master/recipes/img/store_with_ocr.png\" width=800>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python (kili)",
   "language": "python",
   "name": "kili"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
