{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a href=\"https://colab.research.google.com/github/kili-technology/kili-python-sdk/blob/main/recipes/llm_project_setup.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# How to Set Up a Kili Project with an LLM Model and Create a Conversation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In this tutorial, we will learn how to set up a Kili project that uses a Large Language Model (LLM), associate an LLM model with the project, and create a conversation using the Kili Python SDK.\n",
    "\n",
    "Here are the steps we will follow:\n",
    "\n",
    "1. Creating a Kili project with a custom interface\n",
    "2. Creating an LLM model\n",
    "3. Associating the model with the project\n",
    "4. Creating a conversation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Creating a Kili Project with a Custom Interface"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We will create a Kili project with a custom interface that includes a comparison job and a classification job. This interface will be used for labeling and comparing LLM outputs.\n",
    "\n",
    "Here's the JSON interface we will use:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "interface = {\n",
    "    \"jobs\": {\n",
    "        \"COMPARISON_JOB\": {\n",
    "            \"content\": {\n",
    "                \"options\": {\n",
    "                    \"IS_MUCH_BETTER\": {\"children\": [], \"name\": \"Is much better\", \"id\": \"option1\"},\n",
    "                    \"IS_BETTER\": {\"children\": [], \"name\": \"Is better\", \"id\": \"option2\"},\n",
    "                    \"IS_SLIGHTLY_BETTER\": {\n",
    "                        \"children\": [],\n",
    "                        \"name\": \"Is slightly better\",\n",
    "                        \"id\": \"option3\",\n",
    "                    },\n",
    "                    \"TIE\": {\"children\": [], \"name\": \"Tie\", \"id\": \"option4\", \"mutual\": True},\n",
    "                },\n",
    "                \"input\": \"radio\",\n",
    "            },\n",
    "            \"instruction\": \"Pick the best answer\",\n",
    "            \"mlTask\": \"COMPARISON\",\n",
    "            \"required\": 1,\n",
    "            \"isChild\": False,\n",
    "            \"isNew\": False,\n",
    "        },\n",
    "        \"CLASSIFICATION_JOB\": {\n",
    "            \"content\": {\n",
    "                \"categories\": {\n",
    "                    \"BOTH_ARE_GOOD\": {\"children\": [], \"name\": \"Both are good\", \"id\": \"category1\"},\n",
    "                    \"BOTH_ARE_BAD\": {\"children\": [], \"name\": \"Both are bad\", \"id\": \"category2\"},\n",
    "                },\n",
    "                \"input\": \"radio\",\n",
    "            },\n",
    "            \"instruction\": \"Overall quality\",\n",
    "            \"mlTask\": \"CLASSIFICATION\",\n",
    "            \"required\": 0,\n",
    "            \"isChild\": False,\n",
    "            \"isNew\": False,\n",
    "        },\n",
    "    }\n",
    "}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now, we create the project using the `create_project` method:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from kili.client import Kili\n",
    "\n",
    "kili = Kili(\n",
    "    # api_endpoint=\"https://cloud.kili-technology.com/api/label/v2/graphql\",\n",
    ")\n",
    "project = kili.create_project(\n",
    "    title=\"[Kili SDK Notebook]: LLM Project\",\n",
    "    description=\"Project Description\",\n",
    "    input_type=\"LLM_INSTR_FOLLOWING\",\n",
    "    json_interface=interface,\n",
    ")\n",
    "\n",
    "project_id = project[\"id\"]\n",
    "print(f\"Project created with ID: {project_id}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Creating an LLM Model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We will now create an LLM model in Kili. For this, we need to specify the model's credentials, name, and type.\n",
    "\n",
    "**Note**: Replace `'YOUR_MODEL_API_KEY'` and `'YOUR_MODEL_ENDPOINT'` with your model's actual credentials."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_response = kili.llm.create_model(\n",
    "    organization_id=\"your_organization_id\",  # Replace with your organization ID\n",
    "    model={\n",
    "        \"credentials\": {\"api_key\": \"YOUR_MODEL_API_KEY\", \"endpoint\": \"YOUR_MODEL_ENDPOINT\"},\n",
    "        \"name\": \"Your Model Name\",\n",
    "        \"type\": \"OPEN_AI_SDK\",  # Or the appropriate model type\n",
    "    },\n",
    ")\n",
    "\n",
    "model_id = model_response[\"id\"]\n",
    "print(f\"Model created with ID: {model_id}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Associating the Model with the Project"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Next, we will associate the created model with our project by creating project models with different configurations.\n",
    "\n",
    "We will create two project models with different temperature settings."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# First project model with a fixed temperature\n",
    "first_project_model = kili.llm.create_project_model(\n",
    "    project_id=project_id,\n",
    "    model_id=model_id,\n",
    "    configuration={\n",
    "        \"model\": \"Your Model Name\",\n",
    "        \"temperature\": 0.5,\n",
    "    },\n",
    ")\n",
    "\n",
    "first_project_model_id = first_project_model[\"id\"]\n",
    "print(f\"First project model created with ID: {first_project_model_id}\")\n",
    "\n",
    "# Second project model with a temperature range\n",
    "second_project_model = kili.llm.create_project_model(\n",
    "    project_id=project_id,\n",
    "    model_id=model_id,\n",
    "    configuration={\n",
    "        \"model\": \"Your Model Name\",\n",
    "        \"temperature\": {\"min\": 0.2, \"max\": 0.8},\n",
    "    },\n",
    ")\n",
    "\n",
    "second_project_model_id = second_project_model[\"id\"]\n",
    "print(f\"Second project model created with ID: {second_project_model_id}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Creating a Conversation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now, we will create a conversation in the project using a prompt."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "conversation = kili.llm.create_conversation(project_id=project_id, prompt=\"Hello, world!\")\n",
    "\n",
    "print(\"Conversation created.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Summary"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In this tutorial, we've successfully set up a Kili project with a custom interface, created an LLM model, associated the model with the project by creating project models, and created a conversation using the Kili Python SDK."
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
